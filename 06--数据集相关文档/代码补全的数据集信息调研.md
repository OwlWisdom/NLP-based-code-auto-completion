# ‰ª£Á†ÅË°•ÂÖ®ÁöÑÊï∞ÊçÆÈõÜ‰ø°ÊÅØË∞ÉÁ†î

Êó∂Èó¥Ôºö2022-07-20

### ÁõÆÂΩïÔºö

- [1„ÄÅcodeparrot/github-code](https://huggingface.co/datasets/codeparrot/github-code)
- [2„ÄÅcode_contests](https://github.com/deepmind/code_contests)
- [3„ÄÅThe Pile](https://huggingface.co/datasets/the_pile)

- [4„ÄÅcode_search_net](https://huggingface.co/datasets/code_search_net)

- [5„ÄÅAPPS](https://github.com/hendrycks/apps)  (benchmarks )

- [6„ÄÅMBPP](https://github.com/google-research/google-research/tree/master/mbpp)  (benchmarks )

- [7„ÄÅfacebook/incoder-6B](https://huggingface.co/facebook/incoder-6B)

- [8„ÄÅopenai_humanval](https://huggingface.co/datasets/openai_humaneval)

- [9„ÄÅcodeparrot/codeparrot-clean](https://huggingface.co/datasets/codeparrot/codeparrot-clean)



## [1„ÄÅcodeparrot/github-code](https://huggingface.co/datasets/codeparrot/github-code)

- Êï∞ÊçÆÈõÜÊèèËø∞

  GitHub‰ª£Á†ÅÊï∞ÊçÆÈõÜÁî±Êù•Ëá™GitHubÁöÑ1.15‰∫ø‰∏™‰ª£Á†ÅÊñá‰ª∂ÁªÑÊàêÔºåËøô‰∫õÊñá‰ª∂Êúâ32ÁßçÁºñÁ®ãËØ≠Ë®ÄÂíå60‰∏™Êâ©Â±ïÂêçÔºåÊÄªÂÖ±Êúâ1TBÁöÑÊï∞ÊçÆ„ÄÇËØ•Êï∞ÊçÆÈõÜÊòØÁî±Ë∞∑Ê≠åBiqQuery‰∏äÁöÑÂÖ¨ÂÖ±GitHubÊï∞ÊçÆÈõÜÂàõÂª∫ÁöÑ„ÄÇ

- Â¶Ç‰Ωï‰ΩøÁî®ÂÆÉ

  GitHub Code Êï∞ÊçÆÈõÜÊòØ‰∏Ä‰∏™ÈùûÂ∏∏Â§ßÁöÑÊï∞ÊçÆÈõÜÔºåÂõ†Ê≠§ÂØπ‰∫éÂ§ßÂ§öÊï∞Áî®‰æãÔºåÂª∫ËÆÆ‰ΩøÁî®Êï∞ÊçÆÈõÜÁöÑÊµÅÂºè API„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ã‰∏§Ë°å‰ª£Á†ÅÂä†ËΩΩÂíåËø≠‰ª£Êï∞ÊçÆÈõÜÔºö

  ```python
  from datasets import load_dataset
  
  ds = load_dataset("codeparrot/github-code", streaming=True, split='train')
  print(next(iter(ds)))
  
  #OUTPUT:
  {
   'code': "import mod189 from './mod189';\nvar value=mod189+1;\nexport default value;\n",
   'repo_name': 'MirekSz/webpack-es6-ts',
   'path': 'app/mods/mod190.js',
   'language': 'JavaScript',
   'license': 'isc',
   'size': 73
  }
  ```

  ‰Ω†ÂèØ‰ª•ÁúãÂà∞ÔºåÈô§‰∫Ü‰ª£Á†Å„ÄÅ repoÂêçÁß∞ÂíåË∑ØÂæÑ‰πãÂ§ñÔºåÁºñÁ®ãËØ≠Ë®Ä„ÄÅËÆ∏ÂèØËØÅÂíåÊñá‰ª∂ÁöÑÂ§ßÂ∞è‰πüÊòØÊï∞ÊçÆÈõÜÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ‰Ω†‰πüÂèØ‰ª•ËøáÊª§Êï∞ÊçÆÈõÜ‰∏≠ÁöÑ30ÁßçËØ≠Ë®ÄÔºàËßÅ‰∏ãÈù¢ÁöÑÂÆåÊï¥ÂàóË°®ÔºâÁöÑ‰ªª‰ΩïÂ≠êÈõÜ„ÄÇÂè™Ë¶ÅÊääËØ≠Ë®ÄÂàóË°®‰Ωú‰∏∫‰∏Ä‰∏™ÂàóË°®‰º†ËøáÂéª„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûú‰Ω†ÁöÑÊ¢¶ÊÉ≥ÊòØ‰∏∫DockerfilesÂª∫Á´ã‰∏Ä‰∏™CodexÊ®°ÂûãÔºåËØ∑‰ΩøÁî®‰ª•‰∏ãÈÖçÁΩÆ„ÄÇ

  ```python
  ds = load_dataset("codeparrot/github-code", streaming=True, split="train", languages=["Dockerfile"])
  print(next(iter(ds))["code"])
  
  #OUTPUT:
  """\
  FROM rockyluke/ubuntu:precise
  
  ENV DEBIAN_FRONTEND="noninteractive" \
      TZ="Europe/Amsterdam"
  ...
  """
  ```

  Êàë‰ª¨ËøòÂèØ‰ª•ËÆøÈóÆ‰∏Ä‰∏™Êñá‰ª∂ÁöÑÂéüÂßãÁâàÊú¨ÁöÑËÆ∏ÂèØËØÅÔºåÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•Áî®ËøáÊª§ËØ≠Ë®ÄÁöÑÂêåÊ†∑ÊñπÊ≥ïÊù•ËøáÊª§ËÆ∏ÂèØËØÅ„ÄÇ

  ```python
  ds = load_dataset("codeparrot/github-code", streaming=True, split="train", licenses=["mit", "isc"])
  
  licenses = []
  for element in iter(ds).take(10_000):
      licenses.append(element["license"])
  print(Counter(licenses))
  
  #OUTPUT:
  Counter({'mit': 9896, 'isc': 104})
  ```

  ÂΩìÁÑ∂Ôºå‰Ω†‰πüÂèØ‰ª•‰∏ãËΩΩÂÆåÊï¥ÁöÑÊï∞ÊçÆÈõÜ„ÄÇËØ∑Ê≥®ÊÑèÔºåËøôÂ∞Ü‰∏ãËΩΩ~300GBÁöÑÂéãÁº©ÊñáÊú¨Êï∞ÊçÆÔºåÊú™ÂéãÁº©ÁöÑÊï∞ÊçÆÈõÜÂ∞ÜÂç†Áî®~1TBÁöÑÂ≠òÂÇ®Á©∫Èó¥Ôºö

  ```python
  ds = load_dataset("codeparrot/github-code", split="train")
  ```

- Data Structure

  - Data Instances

    ```json
    {
     'code': "import mod189 from './mod189';\nvar value=mod189+1;\nexport default value;\n",
     'repo_name': 'MirekSz/webpack-es6-ts',
     'path': 'app/mods/mod190.js',
     'language': 'JavaScript',
     'license': 'isc',
     'size': 73
    }
    ```

  - Data Fields

    | Field     | Type   | Description                                   |
    | --------- | ------ | --------------------------------------------- |
    | code      | string | content of source file                        |
    | repo_name | string | name of the GitHub repository                 |
    | path      | string | path of file in GitHub repository             |
    | language  | string | programming language as inferred by extension |
    | license   | string | license of GitHub repository                  |
    | size      | int    | size of source file in bytes                  |

  - Data Splits

    ËØ•Êï∞ÊçÆÈõÜÂè™ÂåÖÂê´‰∏Ä‰∏™ËÆ≠ÁªÉÂàÜÂâ≤„ÄÇ

  - Languages

    ËØ•Êï∞ÊçÆÈõÜÂåÖÂê´ 30 ÁßçÁºñÁ®ãËØ≠Ë®ÄÂíå 60 Â§ö‰∏™Êâ©Â±ïÔºö

    ```json
    {
        "Assembly": [".asm"],
        "Batchfile": [".bat", ".cmd"],
        "C": [".c", ".h"],
        "C#": [".cs"],
        "C++": [".cpp", ".hpp", ".c++", ".h++", ".cc", ".hh", ".C", ".H"],
        "CMake": [".cmake"],
        "CSS": [".css"],
        "Dockerfile": [".dockerfile", "Dockerfile"],
        "FORTRAN": ['.f90', '.f', '.f03', '.f08', '.f77', '.f95', '.for', '.fpp'],
        "GO": [".go"],
        "Haskell": [".hs"],
        "HTML":[".html"],
        "Java": [".java"],
        "JavaScript": [".js"],
        "Julia": [".jl"],
        "Lua": [".lua"],
        "Makefile": ["Makefile"],
        "Markdown": [".md", ".markdown"],
        "PHP": [".php", ".php3", ".php4", ".php5", ".phps", ".phpt"],
        "Perl": [".pl", ".pm", ".pod", ".perl"],
        "PowerShell": ['.ps1', '.psd1', '.psm1'],
        "Python": [".py"],
        "Ruby": [".rb"],
        "Rust": [".rs"],
        "SQL": [".sql"],
        "Scala": [".scala"],
        "Shell": [".sh", ".bash", ".command", ".zsh"],
        "TypeScript": [".ts", ".tsx"],
        "TeX": [".tex"],
        "Visual Basic": [".vb"]
    }
    ```

  - Licenses

    ÊØè‰∏™‰æãÂ≠êÈÉΩÊ†áÊòé‰∫ÜÁõ∏ÂÖ≥ËµÑÊ∫êÂ∫ìÁöÑËÆ∏ÂèØËØÅ„ÄÇÊÄªÂÖ±Êúâ15‰∏™ËÆ∏ÂèØËØÅ„ÄÇ

    ```python
    [
      'mit',
      'apache-2.0',
      'gpl-3.0',
      'gpl-2.0',
      'bsd-3-clause',
      'agpl-3.0',
      'lgpl-3.0',
      'lgpl-2.1',
      'bsd-2-clause',
      'cc0-1.0',
      'epl-1.0',
      'mpl-2.0',
      'unlicense',
      'isc',
      'artistic-2.0'
     ]
    
    ```

- Dataset Statistics

  ËØ•Êï∞ÊçÆÈõÜÂåÖÂê´ 115M ‰∏™Êñá‰ª∂ÔºåÊâÄÊúâÊ∫ê‰ª£Á†ÅÊñá‰ª∂Â§ßÂ∞èÁöÑÊÄªÂíå‰∏∫ 873 GBÔºàËØ∑Ê≥®ÊÑèÔºåÁî±‰∫éÈ¢ùÂ§ñÁöÑÂ≠óÊÆµÔºåÊï∞ÊçÆÈõÜÁöÑÂ§ßÂ∞èÊõ¥Â§ßÔºâ„ÄÇ‰∏ãË°®‰∏≠ÁªôÂá∫‰∫ÜÊØèÁßçËØ≠Ë®ÄÁöÑÁªÜÂàÜÔºö

  ![GitHub-code_1](../imgs/GitHub-code_1.png)

  

  |      |   Language   | File Count | **Size (GB)** |
  | :--: | :----------: | :--------: | :-----------: |
  |  0   |     Java     |  19548190  |    107.70     |
  |  1   |      C       |  14143113  |    183.83     |
  |  2   |  JavaScript  |  11839883  |     87.82     |
  |  3   |     HTML     |  11178557  |    118.12     |
  |  4   |     PHP      |  11177610  |     61.41     |
  |  5   |   Markdown   |  8464626   |     23.09     |
  |  6   |     C++      |  7380520   |     87.73     |
  |  7   |    Python    |  7226626   |     52.03     |
  |  8   |      C#      |  6811652   |     36.83     |
  |  9   |     Ruby     |  4473331   |     10.95     |
  |  10  |      GO      |  2265436   |     19.28     |
  |  11  |  TypeScript  |  1940406   |     24.59     |
  |  12  |     CSS      |  1734406   |     22.67     |
  |  13  |    Shell     |  1385648   |     3.01      |
  |  14  |    Scala     |   835755   |     3.87      |
  |  15  |   Makefile   |   679430   |     2.92      |
  |  16  |     SQL      |   656671   |     5.67      |
  |  17  |     Lua      |   578554   |     2.81      |
  |  18  |     Perl     |   497949   |     4.70      |
  |  19  |  Dockerfile  |   366505   |     0.71      |
  |  20  |   Haskell    |   340623   |     1.85      |
  |  21  |     Rust     |   322431   |     2.68      |
  |  22  |     TeX      |   251015   |     2.15      |
  |  23  |  Batchfile   |   236945   |      0.7      |
  |  24  |    CMake     |   175282   |     0.54      |
  |  25  | Visual Basic |   155652   |     1.91      |
  |  26  |   FORTRAN    |   142038   |     1.62      |
  |  27  |  PowerShell  |   136846   |     0.69      |
  |  28  |   Assembly   |   82905    |     0.78      |
  |  29  |    Julia     |   58317    |     0.29      |

- Dataset Creation

  Êï∞ÊçÆÈõÜÁöÑÂàõÂª∫ÂàÜ‰∏§Ê≠•Ôºö

  1. ÂÖ∑Êúâ‰∏äËø∞ÂàóË°®‰∏≠ÁªôÂá∫ÁöÑÊâ©Â±ïÂêçÁöÑÊñá‰ª∂ÊòØ‰ªé BigQuery ‰∏äÁöÑ GitHub Êï∞ÊçÆÈõÜÊ£ÄÁ¥¢ÁöÑÔºàÊ≠§Â§Ñ‰∏∫[ÂÆåÊï¥Êü•ËØ¢](https://huggingface.co/datasets/codeparrot/github-code/blob/main/query.sql)Ôºâ„ÄÇËØ•Êü•ËØ¢‰∫é 2022 Âπ¥ 3 Êúà 16 Êó•‰∏ãÂçà 6:23:39 UTC+1 ÊâßË°å„ÄÇ
  2. Ë°åÊï∞Ë∂ÖËøá1000‰∏™Â≠óÁ¨¶ÁöÑÊñá‰ª∂ÂíåÈáçÂ§çÁöÑÊñá‰ª∂ÔºàÂÆåÂÖ®ÈáçÂ§çÔºåÂøΩÁï•Á©∫ÁôΩÔºâË¢´Âà†Èô§ÔºàÂÆåÊï¥ÁöÑÈ¢ÑÂ§ÑÁêÜËÑöÊú¨Âú®[ËøôÈáå](https://huggingface.co/datasets/codeparrot/github-code/blob/main/github_preprocessing.py)Ôºâ„ÄÇ

- ‰ΩøÁî®Êï∞ÊçÆÁöÑÊ≥®ÊÑè‰∫ãÈ°π

  ËØ•Êï∞ÊçÆÈõÜÁî±Êù•Ëá™ÂêÑÁßçÂ≠òÂÇ®Â∫ìÁöÑÊ∫ê‰ª£Á†ÅÁªÑÊàê„ÄÇÂõ†Ê≠§ÔºåÂÆÉ‰ª¨ÂèØËÉΩÂåÖÂê´ÊúâÂÆ≥ÊàñÊúâÂÅèËßÅÁöÑ‰ª£Á†Å‰ª•ÂèäÂØÜÁ†ÅÊàñÁî®Êà∑ÂêçÁ≠âÊïèÊÑü‰ø°ÊÅØ„ÄÇ

- Releases

  ÊÇ®ÂèØ‰ª•‰ΩøÁî® revision ÂèÇÊï∞Âä†ËΩΩ‰ªª‰ΩïÊóßÁâàÊú¨ÁöÑÊï∞ÊçÆÈõÜÔºö

  ```python
  ds = load_dataset("codeparrot/github-code", revision="v1.0")
  ```

  - v1.0
    - Initial release of dataset
    - The query was executed on *Feb 14, 2022, 12:03:16 PM UTC+1*
  - v1.1
    - Fix missing Scala/TypeScript
    - Fix deduplication issue with inconsistent Python `hash`
    - The query was executed on *Mar 16, 2022, 6:23:39 PM UTC+1*



## 2„ÄÅCode_Contests

ÁªìËÆ∫ÔºöÂºÄÊ∫êÂèØ‰∏ãËΩΩ

Âú∞ÂùÄÔºöhttps://github.com/deepmind/code_contests

CodeContests is a competitive programming dataset for machine-learning. This dataset was used when training [AlphaCode](https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode).

It consists of programming problems, from a variety of sources:

| Site        | URL                                                         | Source                                                       |
| ----------- | ----------------------------------------------------------- | ------------------------------------------------------------ |
| Aizu        | [https://judge.u-aizu.ac.jp](https://judge.u-aizu.ac.jp/)   | [CodeNet](https://github.com/IBM/Project_CodeNet)            |
| AtCoder     | [https://atcoder.jp](https://atcoder.jp/)                   | [CodeNet](https://github.com/IBM/Project_CodeNet)            |
| CodeChef    | [https://www.codechef.com](https://www.codechef.com/)       | [description2code](https://github.com/ethancaballero/description2code) |
| Codeforces  | [https://codeforces.com](https://codeforces.com/)           | [description2code](https://github.com/ethancaballero/description2code) and Codeforces |
| HackerEarth | [https://www.hackerearth.com](https://www.hackerearth.com/) | [description2code](https://github.com/ethancaballero/description2code) |

Problems include test cases in the form of paired inputs and outputs, as well as both correct and incorrect human solutions in a variety of languages.

### **Downloading the dataset**

[Install the Cloud SDK](https://cloud.google.com/sdk/docs/quickstart), which provides the `gsutil` utility. You can then download the full data (~3GiB) with, e.g:

```
gsutil -m cp -r gs://dm-code_contests /tmp
```

The data consists of `ContestProblem` protocol buffers in [Riegeli](https://github.com/google/riegeli) format. See `contest_problem.proto` for the protocol buffer definition and documentation of its fields.

The dataset contains three splits:

| Split      | Filename                                 |
| ---------- | ---------------------------------------- |
| Training   | `code_contests_train.riegeli-*-of-00128` |
| Validation | `code_contests_valid.riegeli`            |
| Test       | `code_contests_test.riegeli`             |

There is example code for iterating over the dataset in C++ (in `print_names.cc`) and Python (in `print_names_and_sources.py`). For example, you can print the source and name of each problem in the validation data by [installing bazel](https://docs.bazel.build/versions/main/install.html) and then running:

```
bazel run -c opt \
  :print_names_and_sources /tmp/dm-code_contests/code_contests_valid.riegeli
```

Or do the same for the training data with the following command (which will print around 13000 lines of output):

```
bazel run -c opt \
  :print_names_and_sources /tmp/dm-code_contests/code_contests_train.riegeli*
```



## 3„ÄÅThe Pile

ÁªìËÆ∫ÔºöÂºÄÊ∫êÂèØ‰∏ãËΩΩ

Âú∞ÂùÄÔºöhttps://github.com/EleutherAI/the-pile

### The official website for the the Pile is [here](http://pile.eleuther.ai/).

The Pile is a large, diverse, open source language modelling data set that consists of many smaller datasets combined together. The objective is to obtain text from as many modalities as possible to ensure that models trained using The Pile will have much broader generalization abilities.

**This repository is for replicating or making variants of the Pile. IF YOU ARE HERE TO USE THE PILE DATASET, THIS REPO IS PROBABLY NOT WHAT YOU ARE LOOKING FOR. A copy of the Pile can be downloaded [here](https://the-eye.eu/public/AI/pile/).**

| Component                                                    | Raw Size   | Weight | Epochs | Effective Size | Mean Document Size |
| ------------------------------------------------------------ | ---------- | ------ | ------ | -------------- | ------------------ |
| [Pile-CC](https://github.com/leogao2/commoncrawl_downloader) | 227.12 GiB | 18.11% | 1.0    | 227.12 GiB     | 4.33 KiB           |
| [PubMed Central](https://github.com/EleutherAI/pile-pubmedcentral) | 90.27 GiB  | 14.40% | 2.0    | 180.55 GiB     | 30.55 KiB          |
| [Books3](https://twitter.com/theshawwn/status/1320282149329784833) | 100.96 GiB | 12.07% | 1.5    | 151.44 GiB     | 538.36 KiB         |
| [OpenWebText2](https://github.com/EleutherAI/openwebtext2)   | 62.77 GiB  | 10.01% | 2.0    | 125.54 GiB     | 3.85 KiB           |
| [ArXiv](https://gist.github.com/leogao2/e09b64eae3b987925ccf3b86401624c6) | 56.21 GiB  | 8.96%  | 2.0    | 112.42 GiB     | 46.61 KiB          |
| [Github](https://github.com/EleutherAI/github-downloader)    | 95.16 GiB  | 7.59%  | 1.0    | 95.16 GiB      | 5.25 KiB           |
| [FreeLaw](https://github.com/thoppe/The-Pile-FreeLaw)        | 51.15 GiB  | 6.12%  | 1.5    | 76.73 GiB      | 15.06 KiB          |
| [StackExchange](https://github.com/EleutherAI/stackexchange-dataset) | 32.20 GiB  | 5.13%  | 2.0    | 64.39 GiB      | 2.16 KiB           |
| [USPTO Backgrounds](https://github.com/EleutherAI/pile-uspto) | 22.90 GiB  | 3.65%  | 2.0    | 45.81 GiB      | 4.08 KiB           |
| [PubMed Abstracts](https://github.com/thoppe/The-Pile-PubMed) | 19.26 GiB  | 3.07%  | 2.0    | 38.53 GiB      | 1.30 KiB           |
| [Gutenberg (PG-19)](https://github.com/deepmind/pg19)        | 10.88 GiB  | 2.17%  | 2.5    | 27.19 GiB      | 398.73 KiB         |
| [OpenSubtitles](https://github.com/sdtblck/Opensubtitles_dataset) | 12.98 GiB  | 1.55%  | 1.5    | 19.47 GiB      | 30.48 KiB          |
| [Wikipedia (en)](https://github.com/noanabeshima/wikipedia-downloader) | 6.38 GiB   | 1.53%  | 3.0    | 19.13 GiB      | 1.11 KiB           |
| [DM Mathematics](https://github.com/deepmind/mathematics_dataset) | 7.75 GiB   | 1.24%  | 2.0    | 15.49 GiB      | 8.00 KiB           |
| [Ubuntu IRC](https://github.com/EleutherAI/pile-ubuntu-irc)  | 5.52 GiB   | 0.88%  | 2.0    | 11.03 GiB      | 545.48 KiB         |
| [BookCorpus2](https://github.com/shawwn/scrap/blob/master/epub2txt-all) | 6.30 GiB   | 0.75%  | 1.5    | 9.45 GiB       | 369.87 KiB         |
| [EuroParl](https://github.com/thoppe/The-Pile-EuroParl)      | 4.59 GiB   | 0.73%  | 2.0    | 9.17 GiB       | 68.87 KiB          |
| [HackerNews](https://github.com/EleutherAI/hn-scraper)       | 3.90 GiB   | 0.62%  | 2.0    | 7.80 GiB       | 4.92 KiB           |
| [YoutubeSubtitles](https://github.com/sdtblck/youtube_subtitle_dataset) | 3.73 GiB   | 0.60%  | 2.0    | 7.47 GiB       | 22.55 KiB          |
| [PhilPapers](https://github.com/thoppe/The-Pile-PhilPapers)  | 2.38 GiB   | 0.38%  | 2.0    | 4.76 GiB       | 73.37 KiB          |
| [NIH ExPorter](https://github.com/thoppe/The-Pile-NIH-ExPORTER) | 1.89 GiB   | 0.30%  | 2.0    | 3.79 GiB       | 2.11 KiB           |
| [Enron Emails](https://github.com/EleutherAI/pile-enron-emails) | 0.88 GiB   | 0.14%  | 2.0    | 1.76 GiB       | 1.78 KiB           |
| **Total**                                                    |            |        |        | 1254.20 GiB    | 5.91 KiB           |

(Epochs refers to the number of epochs elapsed after 1.2TB)

### **Usage**

Install:

```
pip install -e .
```

### To replicate pile

```
python the_pile/pile.py --interleave_output 30 --using pile_reprod
```

Use the pass 2 script [here](https://github.com/EleutherAI/The-Pile/tree/master/processing_scripts) to complete shuffling.

### Other

To force download all data:

```
python the_pile/pile.py --force_download
```

To generate fasttext training data for CC filtering (OWT2 only):

```
sudo apt install build-essential
python the_pile/pile.py --using owt2 --make_fasttext 
```



## 4„ÄÅcode_search_net

ÁªìËÆ∫ÔºöÂèØ‰∏ãËΩΩ

Âú∞ÂùÄÔºöhttps://github.com/github/CodeSearchNet

### **Data Acquisition**

If you have run the [setup steps](https://github.com/github/CodeSearchNet#setup) above you will already have the data, and nothing more needs to be done. The data will be available in the `/resources/data` folder of this repository, with [this directory structure](https://github.com/github/CodeSearchNet/blob/master/resources/README.md).

### **Schema & Format**

Data is stored in [jsonlines](http://jsonlines.org/) format. Each line in the uncompressed file represents one example (usually a function with an associated comment). A prettified example of one row is illustrated below.

- **repo:** the owner/repo
- **path:** the full path to the original file
- **func_name:** the function or method name
- **original_string:** the raw string before tokenization or parsing
- **language:** the programming language
- **code:** the part of the `original_string` that is code
- **code_tokens:** tokenized version of `code`
- **docstring:** the top-level comment or docstring, if it exists in the original string
- **docstring_tokens:** tokenized version of `docstring`
- **sha:** this field is not being used [TODO: add note on where this comes from?]
- **partition:** a flag indicating what partition this datum belongs to of {train, valid, test, etc.} This is not used by the model. Instead we rely on directory structure to denote the partition of the data.
- **url:** the url for the code snippet including the line numbers

Code, comments, and docstrings are extracted in a language-specific manner, removing artifacts of that language.

```
{
  'code': 'def get_vid_from_url(url):\n'
          '        """Extracts video ID from URL.\n'
          '        """\n'
          "        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n"
          "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n"
          "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n"
          "          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n"
          "          parse_query_param(url, 'v') or \\\n"
          "          parse_query_param(parse_query_param(url, 'u'), 'v')",
  'code_tokens': ['def',
                  'get_vid_from_url',
                  '(',
                  'url',
                  ')',
                  ':',
                  'return',
                  'match1',
                  '(',
                  'url',
                  ',',
                  "r'youtu\\.be/([^?/]+)'",
                  ')',
                  'or',
                  'match1',
                  '(',
                  'url',
                  ',',
                  "r'youtube\\.com/embed/([^/?]+)'",
                  ')',
                  'or',
                  'match1',
                  '(',
                  'url',
                  ',',
                  "r'youtube\\.com/v/([^/?]+)'",
                  ')',
                  'or',
                  'match1',
                  '(',
                  'url',
                  ',',
                  "r'youtube\\.com/watch/([^/?]+)'",
                  ')',
                  'or',
                  'parse_query_param',
                  '(',
                  'url',
                  ',',
                  "'v'",
                  ')',
                  'or',
                  'parse_query_param',
                  '(',
                  'parse_query_param',
                  '(',
                  'url',
                  ',',
                  "'u'",
                  ')',
                  ',',
                  "'v'",
                  ')'],
  'docstring': 'Extracts video ID from URL.',
  'docstring_tokens': ['Extracts', 'video', 'ID', 'from', 'URL', '.'],
  'func_name': 'YouTube.get_vid_from_url',
  'language': 'python',
  'original_string': 'def get_vid_from_url(url):\n'
                      '        """Extracts video ID from URL.\n'
                      '        """\n'
                      "        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n"
                      "          match1(url, r'youtube\\.com/embed/([^/?]+)') or "
                      '\\\n'
                      "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n"
                      "          match1(url, r'youtube\\.com/watch/([^/?]+)') or "
                      '\\\n'
                      "          parse_query_param(url, 'v') or \\\n"
                      "          parse_query_param(parse_query_param(url, 'u'), "
                      "'v')",
  'partition': 'test',
  'path': 'src/you_get/extractors/youtube.py',
  'repo': 'soimort/you-get',
  'sha': 'b746ac01c9f39de94cac2d56f665285b0523b974',
  'url': 'https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/youtube.py#L135-L143'
}
```

Summary statistics such as row counts and token length histograms can be found in [this notebook](https://github.com/github/CodeSearchNet/blob/master/notebooks/ExploreData.ipynb)

### **Downloading Data from S3**

The shell script `/script/setup` will automatically download these files into the `/resources/data` directory. Here are the links to the relevant files for visibility:

The s3 links follow this pattern:

> https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/{python,java,go,php,javascript,ruby}.zip

For example, the link for the `java` is:

> https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/java.zip

The size of the dataset is approximately 20 GB. The various files and the directory structure are explained [here](https://github.com/github/CodeSearchNet/blob/master/resources/README.md).



## 5„ÄÅAPPS(Automated Programming Progress Standard --NeurIPS 2021)

ÁªìËÆ∫ÔºöÂèØ‰∏ãËΩΩ

Âú∞ÂùÄÔºöhttps://github.com/hendrycks/apps

### **Measuring Coding Challenge Competence With APPS**

This is the repository for [Measuring Coding Challenge Competence With APPS](https://arxiv.org/pdf/2105.09938) by [Dan Hendrycks*](https://danhendrycks.com/), [Steven Basart*](https://stevenbas.art/), [Saurav Kadavath](http://www.sauravkadavath.com/), Mantas Mazeika, [Akul Arora](https://github.com/akulaarora), Ethan Guo, [Collin Burns](http://collinpburns.com/), Samir Puranik, [Horace He](http://horace.io/), [Dawn Song](https://people.eecs.berkeley.edu/~dawnsong/), and [Jacob Steinhardt](https://www.stat.berkeley.edu/~jsteinhardt/).

Download the [**APPS dataset here**](https://people.eecs.berkeley.edu/~hendrycks/APPS.tar.gz). (~1.3GB)

This repository contains both training and evaluation code.

Fine-tuned GPT-2 1.5B and GPT-Neo 2.7B weights are available [here](https://drive.google.com/file/d/1XW1Od9L-5l9zXl1HUCyER5pS9zQTbIvU/view?usp=sharing).

For other benchmarks of enormous Transformers, see a dataset which tests ability in [competition math](https://github.com/hendrycks/math), a dataset which tests knowledge of [ethics](https://github.com/hendrycks/ethics), and [a dataset spanning 50+ academic subjects](https://github.com/hendrycks/test).

### **How to Use**

The training instructions are specified in [train/README](https://github.com/hendrycks/apps/blob/main/apps/train/README.md) and similarly the evaluation instructions are specified in [eval/README](https://github.com/hendrycks/apps/blob/main/apps/eval/README.md).

### Hugging Face

The dataset is also available in [Hugging Face datasets](https://huggingface.co/datasets/codeparrot/apps) under apps.





## 6„ÄÅMBPP

Âú∞ÂùÄÔºöhttps://github.com/google-research/google-research/tree/master/mbpp

‰∏ãËΩΩÂú∞ÂùÄÔºöhttps://huggingface.co/datasets/mbpp

### **Mostly Basic Python Problems Dataset**

The benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases.

As described in the paper, a subset of the data has been hand-verified by us. This data is `sanitized-mbpp.json`.

The dataset is in a .jsonl format (json per line).

Released as part of Program Synthesis with Large Language Models, Austin et. al., 2021.

### **Evaluation Details**

We specify a train and test split to use for evaluation. Specifically:

- Task IDs 11-510 are used for evaluation.
- Task IDs 1-10 and 511-1000 are used for training and/or prompting. We typically used 1-10 for few-shot prompting, although you can feel free to use any of the training examples.

In the paper "Program Synthesis with Large Language Models", Austin et al. 2021, we used three-shot prompts with task_ids 2, 3, and 4 for few-shot prompts. Our prompts had the formatÔºö

```tex
You are an expert Python programmer, and here is your task: {prompt} Your code should pass these tests:\n\n{tests}\n[BEGIN]\n{code}\n[DONE]
```

where the [BEGIN] and [DONE] tokens were used to delimit the model solution.



## 7„ÄÅfacebook/incoder-6B

Âú∞ÂùÄÔºöhttps://huggingface.co/facebook/incoder-6B

A 6B parameter decoder-only Transformer model trained on code using a causal-masked objective, which allows inserting/infilling code as well as standard left-to-right generation.

The model was trained on public open-source repositories with a permissive, non-copyleft, license (Apache 2.0, MIT, BSD-2 or BSD-3) from GitHub and GitLab, as well as StackOverflow. Repositories primarily contained Python and JavaScript, but also include code from 28 languages, as well as StackOverflow.

For more information, see our:

- [Demo](https://huggingface.co/spaces/facebook/incoder-demo)
- [Project site](https://sites.google.com/view/incoder-code-models)
- [Examples](https://sites.google.com/view/incoder-code-models/home/examples)
- [Paper](https://arxiv.org/abs/2204.05999)

A smaller, 1B, parameter model is also available at [facebook/incoder-1B](https://huggingface.co/facebook/incoder-1B).

### **Requirements**

`pytorch`, `tokenizers`, and `transformers`. Our model requires HF's tokenizers >= 0.12.1, due to changes in the pretokenizer.

```
pip install torch
pip install "tokenizers>=0.12.1"
pip install transformers
```



### **Usage**

See https://github.com/dpfried/incoder for example code.

This 6B model comes in two versions: with weights in full-precision (float32, stored on branch `main`) and weights in half-precision (float16, stored on branch `float16`). The versions can be loaded as follows:

*Full-precision* (float32): This should be used if you are fine-tuning the model (note: this will take a lot of GPU memory, probably multiple GPUs, and we have not tried training the model in `transformers` --- it was trained in Fairseq). Load with:

```
model = AutoModelForCausalLM.from_pretrained("facebook/incoder-6B")
```

*Half-precision* (float16): This can be used if you are only doing inference (i.e. generating from the model). It will use less GPU memory, and less RAM when loading the model. With this version it should be able to perform inference on a 16 GB GPU (with a batch size of 1, to sequence lengths of at least 256). Load with:

```
model = AutoModelForCausalLM.from_pretrained("facebook/incoder-6B", revision="float16", torch_dtype=torch.float16, low_cpu_mem_usage=True)
```

### Tokenizer

```
tokenizer = AutoTokenizer.from_pretrained("facebook/incoder-6B")
```

Note: the incoder-1B and incoder-6B tokenizers are identical, so 'facebook/incoder-1B' could also be used.

When calling `tokenizer.decode`, it's important to pass `clean_up_tokenization_spaces=False` to avoid removing spaces after punctuation:

```
tokenizer.decode(tokenizer.encode("from ."), clean_up_tokenization_spaces=False)
```

(Note: encoding prepends the `<|endoftext|>` token, as this marks the start of a document to our model. This token can be removed from the decoded output by passing `skip_special_tokens=True` to `tokenizer.decode`.)



## 8„ÄÅopenai_humanval -- Dataset Card for OpenAI HumanEval

Âú∞ÂùÄÔºö https://huggingface.co/datasets/openai_humaneval

### Dataset Summary

The HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.

### Supported Tasks and Leaderboards

The programming problems are written in Python and contain English natural text in comments and docstrings.

### Dataset Structure

```python
from datasets import load_dataset
load_dataset("openai_humaneval")

DatasetDict({
    test: Dataset({
        features: ['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'],
        num_rows: 164
    })
})
```



### Data Instances

An example of a dataset instance:

```
{
    "task_id": "test/0",
    "prompt": "def return1():\n",
    "canonical_solution": "    return 1",
    "test": "def check(candidate):\n    assert candidate() == 1",
    "entry_point": "return1"
}
```



### Data Fields

- `task_id`: identifier for the data sample
- `prompt`: input for the model containing function header and docstrings
- `canonical_solution`: solution for the problem in the `prompt`
- `test`: contains function to test generated code for correctness
- `entry_point`: entry point for test

### Data Splits

The dataset only consists of a test split with 164 samples.

### Curation Rationale

Since code generation models are often trained on dumps of GitHub a dataset not included in the dump was necessary to properly evaluate the model. However, since this dataset was published on GitHub it is likely to be included in future dumps.

### Source Data

The dataset was handcrafted by engineers and researchers at OpenAI.



## 9„ÄÅcodeparrot/codeparrot-clean

Âú∞ÂùÄÔºöhttps://huggingface.co/datasets/codeparrot/codeparrot-clean

### CodeParrot ü¶ú Dataset Cleaned

**What is it?**

A dataset of Python files from Github. This is the deduplicated version of the [codeparrot](https://huggingface.co/datasets/transformersbook/codeparrot).

**Processing**

The original dataset contains a lot of duplicated and noisy data. Therefore, the dataset was cleaned with the following steps:

- Deduplication
  - Remove exact matches
- Filtering
  - Average line length < 100
  - Maximum line length < 1000
  - Alpha numeric characters fraction > 0.25
  - Remove auto-generated files (keyword search)

For more details see the preprocessing script in the transformers repository [here](https://github.com/huggingface/transformers/tree/master/examples/research_projects/codeparrot).

**Splits**

The dataset is split in a [train](https://huggingface.co/datasets/codeparrot/codeparrot-clean-train) and [validation](https://huggingface.co/datasets/codeparrot/codeparrot-clean-valid) split used for training and evaluation.

```json
{
    "repo_name": "ahmedbodi\/AutobahnPython",
    "path": "examples\/asyncio\/websocket\/echo\/client_coroutines.py",
    "copies": "13",
    "size": "2044",
    "content": "###############################################################################\n##\n##  Copyright (C) 2013-2014 Tavendo GmbH\n##\n##  Licensed under the Apache License, Version 2.0 (the \"License\");\n##  you may not use this file except in compliance with the License.\n##  You may obtain a copy of the License at\n##\n##      http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n##\n##  Unless required by applicable law or agreed to in writing, software\n##  distributed under the License is distributed on an \"AS IS\" BASIS,\n##  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n##  See the License for the specific language governing permissions and\n##  limitations under the License.\n##\n###############################################################################\n\nfrom autobahn.asyncio.websocket import WebSocketClientProtocol, \\\n                                       WebSocketClientFactory\n\nimport asyncio\n\n\n\nclass MyClientProtocol(WebSocketClientProtocol):\n\n   def onConnect(self, response):\n      print(\"Server connected: {0}\".format(response.peer))\n\n   @asyncio.coroutine\n   def onOpen(self):\n      print(\"WebSocket connection open.\")\n\n      ## start sending messages every second ..\n      while True:\n         self.sendMessage(u\"Hello, world!\".encode('utf8'))\n         self.sendMessage(b\"\\x00\\x01\\x03\\x04\", isBinary = True)\n         yield from asyncio.sleep(1)\n\n   def onMessage(self, payload, isBinary):\n      if isBinary:\n         print(\"Binary message received: {0} bytes\".format(len(payload)))\n      else:\n         print(\"Text message received: {0}\".format(payload.decode('utf8')))\n\n   def onClose(self, wasClean, code, reason):\n      print(\"WebSocket connection closed: {0}\".format(reason))\n\n\n\nif __name__ == '__main__':\n\n   import asyncio\n\n   factory = WebSocketClientFactory(\"ws:\/\/localhost:9000\", debug = False)\n   factory.protocol = MyClientProtocol\n\n   loop = asyncio.get_event_loop()\n   coro = loop.create_connection(factory, '127.0.0.1', 9000)\n   loop.run_until_complete(coro)\n   loop.run_forever()\n   loop.close()\n",
    "license": "apache-2.0",
    "hash": 7822061744094950801,
    "line_mean": 31.4444444444,
    "line_max": 79,
    "alpha_frac": 0.6232876712,
    "autogenerated": false
}

{
    "repo_name": "ifduyue\/django",
    "path": "django\/core\/checks\/registry.py",
    "copies": "13",
    "size": "3108",
    "content": "from itertools import chain\n\nfrom django.utils.itercompat import is_iterable\n\n\nclass Tags:\n    \"\"\"\n    Built-in tags for internal checks.\n    \"\"\"\n    admin = 'admin'\n    caches = 'caches'\n    compatibility = 'compatibility'\n    database = 'database'\n    models = 'models'\n    security = 'security'\n    signals = 'signals'\n    templates = 'templates'\n    urls = 'urls'\n\n\nclass CheckRegistry:\n\n    def __init__(self):\n        self.registered_checks = set()\n        self.deployment_checks = set()\n\n    def register(self, check=None, *tags, **kwargs):\n        \"\"\"\n        Can be used as a function or a decorator. Register given function\n        `f` labeled with given `tags`. The function should receive **kwargs\n        and return list of Errors and Warnings.\n\n        Example::\n\n            registry = CheckRegistry()\n            @registry.register('mytag', 'anothertag')\n            def my_check(apps, **kwargs):\n                # ... perform checks and collect `errors` ...\n                return errors\n            # or\n            registry.register(my_check, 'mytag', 'anothertag')\n        \"\"\"\n        kwargs.setdefault('deploy', False)\n\n        def inner(check):\n            check.tags = tags\n            checks = self.deployment_checks if kwargs['deploy'] else self.registered_checks\n            checks.add(check)\n            return check\n\n        if callable(check):\n            return inner(check)\n        else:\n            if check:\n                tags += (check, )\n            return inner\n\n    def run_checks(self, app_configs=None, tags=None, include_deployment_checks=False):\n        \"\"\"\n        Run all registered checks and return list of Errors and Warnings.\n        \"\"\"\n        errors = []\n        checks = self.get_checks(include_deployment_checks)\n\n        if tags is not None:\n            checks = [check for check in checks if not set(check.tags).isdisjoint(tags)]\n        else:\n            # By default, 'database'-tagged checks are not run as they do more\n            # than mere static code analysis.\n            checks = [check for check in checks if Tags.database not in check.tags]\n\n        for check in checks:\n            new_errors = check(app_configs=app_configs)\n            assert is_iterable(new_errors), (\n                \"The function %r did not return a list. All functions registered \"\n                \"with the checks registry must return a list.\" % check)\n            errors.extend(new_errors)\n        return errors\n\n    def tag_exists(self, tag, include_deployment_checks=False):\n        return tag in self.tags_available(include_deployment_checks)\n\n    def tags_available(self, deployment_checks=False):\n        return set(chain.from_iterable(\n            check.tags for check in self.get_checks(deployment_checks)\n        ))\n\n    def get_checks(self, include_deployment_checks=False):\n        checks = list(self.registered_checks)\n        if include_deployment_checks:\n            checks.extend(self.deployment_checks)\n        return checks\n\n\nregistry = CheckRegistry()\nregister = registry.register\nrun_checks = registry.run_checks\ntag_exists = registry.tag_exists\n",
    "license": "bsd-3-clause",
    "hash": -2035686896372967697,
    "line_mean": 30.7142857143,
    "line_max": 91,
    "alpha_frac": 0.6023166023,
    "autogenerated": false
}
```

ÊãÜËß£ÂÖ∂‰∏≠ÁöÑ‰∏Ä‰∏™pyÊñá‰ª∂ËøõË°åÂàÜÊûêÔºö

```python
from itertools import chain

from django.utils.itercompat import is_iterable


class Tags:
    """
    Built-in tags for internal checks.
    """
    admin = 'admin'
    caches = 'caches'
    compatibility = 'compatibility'
    database = 'database'
    models = 'models'
    security = 'security'
    signals = 'signals'
    templates = 'templates'
    urls = 'urls'


class CheckRegistry:

    def __init__(self):
        self.registered_checks = set()
        self.deployment_checks = set()

    def register(self, check=None, *tags, **kwargs):
        """
        Can be used as a function or a decorator. Register given function
        `f` labeled with given `tags`. The function should receive **kwargs
        and return list of Errors and Warnings.

        Example::

            registry = CheckRegistry()
            @registry.register('mytag', 'anothertag')
            def my_check(apps, **kwargs):
                # ... perform checks and collect `errors` ...
                return errors
            # or
            registry.register(my_check, 'mytag', 'anothertag')
        """
        kwargs.setdefault('deploy', False)

        def inner(check):
            check.tags = tags
            checks = self.deployment_checks if kwargs['deploy'] else self.registered_checks
            checks.add(check)
            return check

        if callable(check):
            return inner(check)
        else:
            if check:
                tags += (check, )
            return inner

    def run_checks(self, app_configs=None, tags=None, include_deployment_checks=False):
        """
        Run all registered checks and return list of Errors and Warnings.
        """
        errors = []
        checks = self.get_checks(include_deployment_checks)

        if tags is not None:
            checks = [check for check in checks if not set(check.tags).isdisjoint(tags)]
        else:
            # By default, 'database'-tagged checks are not run as they do more
            # than mere static code analysis.
            checks = [check for check in checks if Tags.database not in check.tags]

        for check in checks:
            new_errors = check(app_configs=app_configs)
            assert is_iterable(new_errors), (
                "The function %r did not return a list. All functions registered "
                "with the checks registry must return a list." % check)
            errors.extend(new_errors)
        return errors

    def tag_exists(self, tag, include_deployment_checks=False):
        return tag in self.tags_available(include_deployment_checks)

    def tags_available(self, deployment_checks=False):
        return set(chain.from_iterable(
            check.tags for check in self.get_checks(deployment_checks)
        ))

    def get_checks(self, include_deployment_checks=False):
        checks = list(self.registered_checks)
        if include_deployment_checks:
            checks.extend(self.deployment_checks)
        return checks


registry = CheckRegistry()
register = registry.register
run_checks = registry.run_checks
tag_exists = registry.tag_exists
```

