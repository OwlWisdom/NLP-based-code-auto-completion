# B--Pythonå¹¶å‘è®¡ç®—çš„æµ‹è¯•ä»£ç æ„å»º

**å‚è€ƒä¿¡æ¯æºï¼š**

1. [Requests: HTTP for humans](https://requests.readthedocs.io/en/latest/)
2. [GitHub--psf/requests](https://github.com/psf/requests)
3. [æ€æ ·æ‰èƒ½è¿ç»­è¿è¡Œå¤šä¸ªcurlè¯·æ±‚ï¼Ÿ](https://stackoverflow.com/questions/3110444/how-can-i-run-multiple-curl-requests-processed-sequentially)
4. [Make-batch-API-requests-via-Python](https://wenleicao.github.io/Make-batch-API-requests-via-Python/)
5. [how-to-send-concurrent-http-requests-in-python](https://blog.devgenius.io/how-to-send-concurrent-http-requests-in-python-d9cda284c86a)
6. [Software Testing Notes](https://softwaretestingnotes.substack.com/p/issue-40-software-testing-notes)
7. [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)

Youtube è§†é¢‘æºï¼š

- [Python Threading Tutorial: Run Code Concurrently Using the Threading ](https://www.youtube.com/watch?v=IEEhzQoKtQU)
- [Functional Programming in Python: Parallel Processing with "concurrents.futures"](https://www.youtube.com/watch?v=0NNV8FDuck8)

Python--Requestsåº“--Issuesï¼š

- [Document threading contract for Session class](https://github.com/psf/requests/issues/2766)



## Thread v.s. Process

1. Thread v.s. Process

   è¿›ç¨‹ä¸çº¿ç¨‹çš„åŒºåˆ«ï¼š

   ä¸€ä¸ªè¿›ç¨‹æœ‰ä¸€ä¸ªä¸»çº¿ç¨‹ï¼Œå¹¶å¯èƒ½æœ‰å…¶ä»–çº¿ç¨‹ï¼›ä¸€ä¸ªçº¿ç¨‹å±äºä¸€ä¸ªè¿›ç¨‹ï¼›**è¿›ç¨‹å’Œçº¿ç¨‹éƒ½æ˜¯åº•å±‚æ“ä½œç³»ç»Ÿæä¾›çš„ç‰¹æ€§**ã€‚

2. Shared Memory v.s. Inter-Process Communication

   çº¿ç¨‹å¯ä»¥åœ¨è¿›ç¨‹å†…å…±äº«å†…å­˜ã€‚

   è¿›ç¨‹ä¸åƒçº¿ç¨‹é‚£æ ·å…±äº«å†…å­˜ï¼Œç›¸åï¼ŒçŠ¶æ€å¿…é¡»è¢«åºåˆ—åŒ–å¹¶åœ¨è¿›ç¨‹ä¹‹é—´ä¼ è¾“ï¼Œè¿™è¢«ç§°ä¸ºè¿›ç¨‹é—´çš„é€šä¿¡ï¼›å°½ç®¡å®ƒå‘ç”Ÿåœ¨å¹•åï¼Œä½†å®ƒç¡®å®å¯¹å¯ä»¥å…±äº«çš„æ•°æ®å’ŒçŠ¶æ€æ–½åŠ äº†é™åˆ¶ï¼Œå¹¶å¢åŠ äº†å…±äº«æ•°æ®çš„å¼€é”€ã€‚çº¿ç¨‹ä¹‹é—´çš„çŠ¶æ€å…±äº«ç®€å•ä¸”è½»é‡çº§ï¼Œè¿›ç¨‹ä¹‹é—´çš„çŠ¶æ€å…±äº«æ›´éš¾ä¸”é‡é‡çº§ã€‚

3. GIL v.s. no GIL (global  interpreter lock)

   <span style='color:brown'>**GIL æ˜¯ä¸€ç§é”ï¼Œå®ƒä½¿ç”¨åŒæ­¥æ¥ç¡®ä¿åœ¨pythonè¿›ç¨‹ä¸­åªæœ‰ä¸€ä¸ªæ‰§è¡Œçº¿ç¨‹å¯ä»¥æ‰§è¡Œã€‚**</span>

   ThreadPoolExecutorä¸­çš„æ¯ä¸ªçº¿ç¨‹éƒ½å—åˆ°GILçš„çº¦æŸï¼Œè€ŒProcessPoolExecutorä¸­çš„å¤šä¸ªå­è¿›ç¨‹ä¸å—GILçš„çº¦æŸã€‚

   è¿™æ„å‘³ç€è™½ç„¶æˆ‘ä»¬åœ¨ä¸€ä¸ªThreadPoolExecutorä¸­å¯èƒ½æœ‰å¤šä¸ªçº¿ç¨‹ï¼Œä½†æ˜¯ä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªã€‚

   GILåœ¨æ¯ä¸ªPythonè¿›ç¨‹ä¸­ä½¿ç”¨ï¼Œä½†ä¸èƒ½è·¨è¿›ç¨‹ï¼Œè¿™æ„å‘³ç€ä¸€ä¸ªProcessPoolExecutorä¸­çš„å¤šä¸ªå­è¿›ç¨‹å¯ä»¥åŒæ—¶æ‰§è¡Œï¼Œå¹¶ä¸”ä¸å—GILçš„é™åˆ¶ã€‚

#### **Summary of Differences:**

<span style='color:brown'>ThreadPoolExecutor</span>

- Uses Threads, not processes.
- Lightweight workers, not heavyweight workers.
- Shared Memory, not inter-process communication.
- Subject to the GIL, not parallel execution.
- Suited to IO-bound Tasks, not CPU-bound tasks.
- <span style='color:brown'>**Create 10s to 1,000s Workers, not really constrained.**</span>(å—çº¦æŸçš„)

<span style='color:brown'>ProcessPoolExecutor</span>

- Uses Processes, not threads.
- Heavyweight Workers, not lightweight workers.
- Inter-Process Communication, not shared memory.
- Not Subject to the GIL, not constrained to sequential execution.
- Suited to CPU-bound Tasks, probably not IO-bound tasks.
- <span style='color:brown'>**Create 10s of Workers, not 100s or 1,000s of tasks.**</span>.

## æ€§èƒ½æµ‹è¯•æ¡ˆä¾‹

**å‚è€ƒæ¡ˆä¾‹ï¼š**

```python
import sys
from ts.metrics.metrics_store import MetricsStore
from ts.torch_handler.base_handler import BaseHandler
from uuid import uuid4
from pprint import pprint

class ModelContext:
    def __init__(self):
        self.manifest = {
            'model': {
                'modelName': 'ptclassifier',
                'serializedFile': '<ADD MODEL NAME HERE>',
                'modelFile': 'model_ph.py'
            }
        }
        self.system_properties = {
            'model_dir': '<ADD COMPLETE MODEL PATH HERE>'
        }
        self.explain = False
        self.metrics = MetricsStore(uuid4(), self.manifest['model']['modelName'])
    def get_request_header(self, idx, exp):
        if exp == 'explain':
            return self.explain
        return False
    
def main():
    if sys.argv[1] == 'fast':
        from ptclassifier.TransformerSeqClassificationHandler import TransformersSeqClassifierHandler as Classifier
    else:
        from ptclassifiernotr.TransformerSeqClassificationHandler import TransformersSeqClassifierHandler as Classifier
    ctxt = ModelContext()
    handler = Classifier()
    handler.initialize(ctxt)
    data = [{'data': 'To be or not to be, that is the question.'}]
    for i in range(1000):
        processed = handler.handle(data, ctxt)
        #print(processed)
    for m in ctxt.metrics.store:
        print(f'{m.name}: {m.value} {m.unit}')
        
if __name__ == '__main__':
    main()
```

<span style='color:brown'>**ä¸Šè¿°æµ‹è¯•æ–¹æ³•çš„ç¼ºç‚¹ï¼š**</span>

- å°†æ•°æ®çš„æ¨ç†ç›´æ¥å†™å…¥ä¸»ç¨‹åºï¼Œå°†å¿½ç•¥åœ¨å®é™…ä½¿ç”¨ä¸­é¢ä¸´çš„ç½‘ç»œè¿æ¥ç­‰æ–¹é¢çš„çœŸå®è¡¨ç°ï¼Œæ­¤æ—¶æµ‹è¯•å‡ºæ¥çš„æ•°æ®å°†ä¸å®é™…ç›¸åˆ†ç¦»ï¼Œéœ€è¦é¿å…è¿™ç§æµ‹è¯•ä¸­å‡ºç°çš„åå·®ï¼›å› æ­¤æœ¬å®éªŒçš„æµ‹è¯•æ–¹æ³•éœ€è¦å¤ç°äº§å“åœ¨çœŸå®ä½¿ç”¨ä¸­çš„åœºæ™¯ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¾—å‡ºæµ‹è¯•æ•°æ®ï¼Œè¿™æ ·çš„æ•°æ®æ‰å…·æœ‰æ›´å¼ºçš„çœŸå®æ€§ã€‚



### Curl è¿›è¡Œæ‰¹é‡ requests çš„Python è„šæœ¬çš„å®ç°ä»£ç å‚è€ƒ

- [Requests: HTTP for humans](https://requests.readthedocs.io/en/latest/)
- [GitHub--psf/requests](https://github.com/psf/requests)
- [æ€æ ·æ‰èƒ½è¿ç»­è¿è¡Œå¤šä¸ªcurlè¯·æ±‚ï¼Ÿ](https://stackoverflow.com/questions/3110444/how-can-i-run-multiple-curl-requests-processed-sequentially)





åŒæ—¶è¿›è¡Œä¸¤ä¸ªPOSTè¯·æ±‚ï¼š

```python
import requests
res = requests.post("http://localhost:8080/predictions/squeezenet1_1", files={'data': open('docs/images/dogs-before.jpg', 'rb'), 'data': open('docs/images/kitten_small.jpg', 'rb')})
```



```python
import requests
url = 'https://www.example.com/post'
payload = {
'key1': 'value1',
'key2': 'value2'
}

headers = {
'Content-Type': 'application/json'
}

r = requests.post(url, data=payload, headers=headers)
print(r.text)
```



```python
url = 'https://httpbin.org/post'
files = {'file': ('report.csv', 'some,data,to,send\nanother,row,to,send\n')}

r = requests.post(url, files=files)
r.text
{
  ...
  "files": {
    "file": "some,data,to,send\\nanother,row,to,send\\n"
  },
  ...
}
```



### <span style='color:brown'>Example : Batch API Requests via  Pyzillow</span>

- [Make-batch-API-requests-via-Python](https://wenleicao.github.io/Make-batch-API-requests-via-Python/)



```python
# write the results to csv file
with open(r'test.csv', 'w') as outfile:
    writer = csv.writer(outfile)
    with open(r'test2.csv', 'r') as csvfile:
        spamreader = csv.reader(csvfile, delimiter=',')
        next(spamreader)  #skip csv header
        for row in spamreader:
            try:
            	outrow = row+[get_zillowinfo(row[0], row[1])] # merge result of function call to the existing row
            	writer.writerow(outrow)
            except:
                outrow = row+["Data not available"]  # notice data is not available
                writer.writerow(outrow)
                continue
```



### <span style='color:brown'>**Example:  How to Seed Concurrent HTTP Requests in Python**</span>

- [how-to-send-concurrent-http-requests-in-python](https://blog.devgenius.io/how-to-send-concurrent-http-requests-in-python-d9cda284c86a)

#### 1ã€The built-in concurrent library  (<span style='color:brown'>**å·²éªŒè¯æœ‰æ•ˆ**</span>)

ä»æŠ€æœ¯ä¸Šè®²ï¼ŒPython æ˜¯ä¸€ç§å¤šçº¿ç¨‹è¯­è¨€ï¼Œç„¶è€Œï¼Œç”±äº GILï¼ˆå…¨å±€è§£é‡Šå™¨é”ï¼‰çš„å­˜åœ¨ï¼Œåœ¨å®è·µä¸­ï¼Œå®ƒç¡®å®ä¸æ˜¯ã€‚æ‰€ä»¥ï¼ŒPythonä¸­çš„çº¿ç¨‹æ›´å¤šçš„æ˜¯ä¸å¹¶å‘æ€§æœ‰å…³ï¼Œè€Œä¸æ˜¯ä¸å¹¶è¡Œæ€§æœ‰å…³ã€‚ 

å¹¶å‘åº“æœ‰ä¸€ä¸ªå«åšThreadPoolExecutorçš„ç±»ï¼Œæˆ‘ä»¬å°†ç”¨å®ƒæ¥å‘é€å¹¶å‘è¯·æ±‚ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä½¿ç”¨çš„æ˜¯Rick and Morty APIã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è·å¾—Rick and MortyåŠ¨ç”»ç‰‡ä¸­å„ä¸ªè§’è‰²çš„ä¿¡æ¯ï¼Œè€ŒAPIæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å¼€å§‹ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ä¸€äº›ä»£ç ï¼Œæˆ‘å°†é€è¡Œè§£é‡Šã€‚

```python
import requests
import concurrent
from concurrent.futures import ThreadPoolExecutor

characters = range(1, 100)
base_url = 'https://rickandmortyapi.com/api/character'
threads = 20

def get_character_info(character):
    r = requests.get(f'{base_url}/{character}')
    return r.json()

with ThreadPoolExecutor(max_workers=threads) as executor:
    future_to_url = {executor.submit(get_character_info, char) for char in characters}
    for future in concurrent.futures.as_completed(future_to_url):
        try:
            data = future.result()
            print(data)
        except Exception as e:
            print('Looks like something went wrong: ', e)
```



ç¬¬1-3è¡Œæ˜¯æˆ‘ä»¬éœ€è¦çš„å¯¼å…¥åº“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [request](https://docs.python-requests.org/en/latest/) åº“æ¥å‘APIå‘é€HTTPè¯·æ±‚ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [concurrent](https://docs.python.org/3/library/concurrent.futures.html) åº“æ¥å¹¶å‘åœ°æ‰§è¡Œè¿™äº›è¯·æ±‚ã€‚

characters å˜é‡æ˜¯ä» 1 åˆ° 99 çš„æ•´æ•°èŒƒå›´ï¼ˆè¯·æ³¨æ„ï¼Œæˆ‘ä½¿ç”¨èŒƒå›´è€Œä¸æ˜¯åˆ—è¡¨ï¼Œå› ä¸ºè¿™æ ·å˜é‡è¢«å»¶è¿ŸåŠ è½½åˆ°å†…å­˜ä¸­ï¼Œè¿™æ„å‘³ç€å®ƒåœ¨å†…å­˜æ–¹é¢æ›´æœ‰æ•ˆï¼‰ã€‚

base_url æ˜¯æˆ‘ä»¬å°†è°ƒç”¨çš„ç«¯ç‚¹ä»¥åŠå­—ç¬¦ id åç¼€æ¥è·å–æˆ‘ä»¬çš„æ•°æ®ã€‚

çº¿ç¨‹å˜é‡åŸºæœ¬ä¸Šå‘Šè¯‰æˆ‘ä»¬çš„ThreadPoolExecutorï¼Œæˆ‘ä»¬å¸Œæœ›æœ€å¤šæœ‰20ä¸ªçº¿ç¨‹ï¼ˆä½†ä¸æ˜¯æˆ‘è¯´çš„çœŸæ­£çš„æ“ä½œç³»ç»Ÿçº¿ç¨‹ï¼‰è¢«äº§ç”Ÿå‡ºæ¥ã€‚ç¬¬13-20è¡Œè¿›è¡Œå®é™…æ‰§è¡Œã€‚

future_to_url å˜é‡æ˜¯ä¸€ä¸ªå¸¦æœ‰æœ‰è¶£é”®å€¼å¯¹çš„å­—å…¸ã€‚å…³é”®æ˜¯ä¸€ä¸ªæ–¹æ³•â€”â€” executor.submit ã€‚æ›´æœ‰è¶£çš„æ˜¯è¯¥æ–¹æ³•æ¥å—ä¸¤ä¸ªå‚æ•°ã€‚ä¸€ä¸ªæ˜¯å‡½æ•°çš„åç§° (get_character_info)ï¼Œå¦ä¸€ä¸ªæ˜¯ä¼ é€’ç»™è¯¥å‡½æ•°çš„å‚æ•°ã€‚ç¡®ä¿ä¸è¦æ··æ·†ï¼Œé€šè¿‡åœ¨æ‹¬å·ä¸­æ·»åŠ  char å‚æ•°ï¼Œå°±åƒå•ç‹¬è°ƒç”¨ get_character_info å‡½æ•°æ—¶ä¸€æ ·ã€‚å­—å…¸çš„å€¼åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªå…ƒç»„æ¨å¯¼å¼ï¼Œè¿™æ˜¯æˆ‘ä»¬é€šå¸¸ä¸ä¼šç”¨ä½œå­—å…¸å€¼çš„ä¸œè¥¿ã€‚è¿™é‡Œçš„é‡ç‚¹æ˜¯éå†æ‰€æœ‰å­—ç¬¦ idï¼Œå¹¶ä¸ºæ¯ä¸ªå­—ç¬¦è°ƒç”¨å‡½æ•°ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯åŠ¨ä¸€ä¸ª for å¾ªç¯ï¼Œè¯¥å¾ªç¯å°†éå† concurrent.futures.as_completed(future_to_url)ï¼Œç®€å•æ¥è¯´ï¼Œè¿™æ„å‘³ç€ â€” å°†è¿™äº›è°ƒç”¨çš„ç»“æœä½œä¸ºå®Œæˆã€‚

try/except å—ä¼šå°†æ•°æ®å˜é‡å£°æ˜ä¸º HTTP è¯·æ±‚çš„ç»“æœï¼Œå¸Œæœ›ä¸ä¼šå¤±è´¥ã€‚å¦‚æœæ˜¯è¿™æ ·ï¼Œæˆ‘ä»¬å°†æ‰“å°ä¸€æ¡ç®€å•çš„é”™è¯¯æ¶ˆæ¯ï¼Œçœ‹çœ‹å‡ºäº†ä»€ä¹ˆé—®é¢˜ã€‚

å¦‚æœä½ è¿è¡Œè¿™æ®µä»£ç ï¼Œä½ å¯èƒ½å·²ç»çœ‹åˆ°å®ƒçš„æ‰§è¡Œé€Ÿåº¦æœ‰å¤šå¿«ã€‚æˆ‘ä»¬åœ¨ä¸åˆ°ä¸€ç§’é’Ÿçš„æ—¶é—´é‡Œå¾—åˆ°äº†100ä¸ªAPIç»“æœã€‚å¦‚æœæˆ‘ä»¬ä¸€ä¸ªä¸€ä¸ªåœ°åšï¼Œå¯èƒ½è¦èŠ±1åˆ†é’Ÿä»¥ä¸Šã€‚



#### 2ã€The Asyncio library (<span style='color:brown'>**å·²éªŒè¯æœ‰æ•ˆ**</span>)

[Asyncio](https://docs.python.org/3/library/asyncio.html) æ¨¡å—ä¹Ÿæ˜¯å†…ç½®çš„ï¼Œä½†ä¸ºäº†åœ¨ HTTP è°ƒç”¨ä¸­ä½¿ç”¨å®ƒï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…ä¸€ä¸ªå¼‚æ­¥ HTTP åº“ï¼Œç§°ä¸º [aiohttp](https://docs.aiohttp.org/en/stable/)ã€‚åŸå› æ˜¯æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„ requests åº“ä¸æ˜¯å¼‚æ­¥å·¥ä½œçš„ï¼Œæ‰€ä»¥è¿™é‡Œä¸ä¼šæœ‰ä»»ä½•ä½œç”¨ã€‚

Asyncioçš„å·¥ä½œæ–¹å¼ä¸ThreadPoolExecutorä¸åŒï¼Œå®ƒä½¿ç”¨ä¸€ç§å«åšäº‹ä»¶å¾ªç¯çš„ä¸œè¥¿ã€‚è¿™ä¸NodeJsçš„å·¥ä½œæ–¹å¼ç±»ä¼¼ï¼Œæ‰€ä»¥å¦‚æœä½ æ¥è‡ªJavaScriptï¼Œä½ å¯èƒ½å¯¹è¿™ç§æ–¹å¼å¾ˆç†Ÿæ‚‰ã€‚

```python
import aiohttp
import asyncio

characters = range(1, 10)
base_url = 'https://rickandmortyapi.com/api/character'

async def get_character_info(character, session):
    r = await session.request('GET', url=f'{base_url}/{character}')
    data = await r.json()
    return data

async def main(characters):
    async with aiohttp.ClientSession() as session:
        tasks = []
        for char in characters:
            tasks.append(get_character_info(character=char, session=session))
            results = await asyncio.gather(*tasks, return_exceptions=True)
            print('result: ', results)
            print('/n')
    return results

if __name__ == '__main__':
    data = asyncio.run(main(characters))
    # for item in data:
    #     print(item)
```



å‰10è¡Œä»£ç ä¸ThreadPoolExecutorçš„æ–¹æ³•æ¯”è¾ƒç›¸ä¼¼ï¼Œä¸»è¦æœ‰ä¸¤ä¸ªä¸åŒä¹‹å¤„ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯¼å…¥çš„æ˜¯ aiohttp åº“ï¼Œè€Œä¸æ˜¯ requestsã€‚ç¬¬äºŒï¼Œåœ¨æˆ‘ä»¬çš„å‡½æ•°å®šä¹‰ä¸­ï¼Œæˆ‘ä»¬åœ¨æ‰€æœ‰ä¸œè¥¿å‰é¢ä½¿ç”¨äº†asyncå…³é”®å­—ã€‚è¿™æ ·æˆ‘ä»¬å°±å‘Šè¯‰ Python è§£é‡Šå™¨ï¼Œæˆ‘ä»¬å°†åœ¨ä¸€ä¸ªäº‹ä»¶å¾ªç¯ä¸­è¿è¡Œè¿™ä¸ªå‡½æ•°ã€‚

ç¬¬ 12-18 è¡Œæ˜¯å¼€å§‹ä¸ç¬¬ä¸€ç§æ–¹æ³•ä¸åŒçš„åœ°æ–¹ï¼Œä½†æ­£å¦‚æ‚¨å¯èƒ½å¾—å‡ºçš„ç»“è®ºï¼Œæœ€é‡è¦çš„è°ƒç”¨æ˜¯ tasks.append è°ƒç”¨ï¼Œå®ƒç±»ä¼¼äºç¬¬ä¸€ç§æ–¹æ³•çš„ executor.submit è°ƒç”¨ã€‚ä¸‹ä¸€è¡Œçš„ asyncio.gather ç±»ä¼¼äº futures.as_completed æ–¹æ³•ï¼Œå› ä¸ºå®ƒåœ¨å•ä¸ªé›†åˆä¸­æ”¶é›†å¹¶å‘è°ƒç”¨çš„ç»“æœã€‚

æœ€åï¼Œå½“ä½¿ç”¨asyncioæ—¶ï¼Œæˆ‘ä»¬éœ€è¦è°ƒç”¨asyncio.run()ï¼ˆåªæœ‰åœ¨Python 3.7åŠä»¥ä¸Šç‰ˆæœ¬æ‰æœ‰ï¼Œå¦åˆ™éœ€è¦å¤šå†™å‡ è¡Œä»£ç ï¼‰ã€‚è¿™ä¸ªå‡½æ•°æ¥å—ä¸€ä¸ªå‚æ•°ï¼Œå³æˆ‘ä»¬æƒ³æ·»åŠ åˆ°äº‹ä»¶å¾ªç¯ä¸­çš„å¼‚æ­¥å‡½æ•°ã€‚

è¿™ç§æ–¹æ³•ä¹Ÿè®¸æœ‰ç‚¹å¤æ‚ï¼Œä½†å®ƒæ›´å¿«ã€æ›´å¯é ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘æ›´æ¨èè¿™ç§æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½ è¿›è¡Œæ•°ç™¾ç”šè‡³æ•°åƒæ¬¡å¹¶å‘å‘¼å«æ—¶ã€‚

æœ€ç»ˆï¼Œæ— è®ºå“ªç§æ–¹æ³•éƒ½ä¼šåœ¨åŒæ­¥è°ƒç”¨çš„ä¸€å°éƒ¨åˆ†æ—¶é—´å†…å®ŒæˆHTTPè°ƒç”¨ã€‚





## <span style='color:brown'>Issue #40:  Software Testing Notes</span>

åŸæ–‡åœ°å€ï¼š

- [Software Testing Notes](https://softwaretestingnotes.substack.com/p/issue-40-software-testing-notes)



## <span style='color:brown'>Python--concurrent.futures  :  Launching parallel tasks</span>

åŸæ–‡åœ°å€ï¼š

- [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)

concurrent.futuresæ¨¡å—ä¸ºå¼‚æ­¥æ‰§è¡Œçš„å¯è°ƒç”¨ç¨‹åºæä¾›äº†ä¸€ä¸ªé«˜çº§æ¥å£ã€‚

å¼‚æ­¥æ‰§è¡Œå¯ä»¥é€šè¿‡çº¿ç¨‹ï¼ˆä½¿ç”¨ThreadPoolExecutorï¼‰æˆ–å•ç‹¬çš„è¿›ç¨‹ï¼ˆä½¿ç”¨ProcessPoolExecutorï¼‰è¿›è¡Œã€‚ä¸¤è€…éƒ½å®ç°äº†ç›¸åŒçš„æ¥å£ï¼Œè¿™æ˜¯ç”±æŠ½è±¡çš„Executorç±»å®šä¹‰çš„ã€‚

### Executor  Objects

æä¾›å¼‚æ­¥æ‰§è¡Œè°ƒç”¨çš„æ–¹æ³•çš„æŠ½è±¡ç±»ã€‚å®ƒä¸åº”è¯¥ç›´æ¥ä½¿ç”¨ï¼Œè€Œåº”è¯¥é€šè¿‡å®ƒçš„å…·ä½“å­ç±»æ¥ä½¿ç”¨ã€‚

- `submit`(*fn*, */*, **args*, ***kwargs*)[Â¶](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.submit)

  å®‰æ’å¯è°ƒç”¨å¯¹è±¡ fn ä½œä¸º fn(*args, **kwargs) æ‰§è¡Œï¼Œå¹¶è¿”å›è¡¨ç¤ºå¯è°ƒç”¨å¯¹è±¡æ‰§è¡Œçš„ Future å¯¹è±¡ã€‚

  ```python
  with ThreadPoolExecutor(max_workers=1) as executor:
      future = executor.submit(pow, 323, 1235)
      print(future.result())
  ```

- `map`(*func*, **iterables*, *timeout=None*, *chunksize=1*)[Â¶](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map)

  ç±»ä¼¼äº map(func, *iterables) é™¤äº†ï¼š

  - iterables è¢«ç«‹å³æ”¶é›†è€Œä¸æ˜¯æ‡’æƒ°åœ°æ”¶é›†ï¼›
  - funcæ˜¯å¼‚æ­¥æ‰§è¡Œçš„ï¼Œå¯ä»¥åŒæ—¶å¯¹funcè¿›è¡Œå¤šæ¬¡è°ƒç”¨ã€‚

  å½“ä½¿ç”¨ProcessPoolExecutoræ—¶ï¼Œè¯¥æ–¹æ³•ä¼šå°†è¿­ä»£æ•°æ®åˆ‡æˆè‹¥å¹²å—ï¼Œå¹¶ä½œä¸ºç‹¬ç«‹çš„ä»»åŠ¡æäº¤ç»™æ± ã€‚è¿™äº›å—çš„ï¼ˆè¿‘ä¼¼ï¼‰å¤§å°å¯ä»¥é€šè¿‡è®¾ç½®chunksizeä¸ºä¸€ä¸ªæ­£æ•´æ•°æ¥æŒ‡å®šã€‚å¯¹äºéå¸¸é•¿çš„è¿­ä»£å¯¹è±¡ï¼Œä¸é»˜è®¤çš„1å¤§å°ç›¸æ¯”ï¼Œä½¿ç”¨å¤§çš„chunksizeå¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ã€‚ å¯¹äºThreadPoolExecutorï¼Œchunksizeæ²¡æœ‰å½±å“ã€‚
  
- `shutdown`(*wait=True*, ***, *cancel_futures=False*)

  å‘æ‰§è¡Œå™¨å‘å‡ºä¿¡å·ï¼Œå½“å½“å‰æŒ‚èµ·çš„æœŸè´§æ‰§è¡Œå®Œæ¯•æ—¶ï¼Œå®ƒåº”è¯¥é‡Šæ”¾å®ƒæ­£åœ¨ä½¿ç”¨çš„ä»»ä½•èµ„æºã€‚åœ¨å…³é—­åå¯¹Executor.submit()å’ŒExecutor.map()çš„è°ƒç”¨å°†å¼•å‘RuntimeErrorã€‚

  å¦‚æœwaitä¸ºTrueï¼Œé‚£ä¹ˆè¿™ä¸ªæ–¹æ³•å°†ä¸ä¼šè¿”å›ï¼Œç›´åˆ°æ‰€æœ‰çš„å¾…å®šæœŸè´§æ‰§è¡Œå®Œæ¯•ï¼Œå¹¶ä¸”ä¸æ‰§è¡Œè€…ç›¸å…³çš„èµ„æºè¢«é‡Šæ”¾ã€‚å¦‚æœwaitä¸ºFalseï¼Œé‚£ä¹ˆè¿™ä¸ªæ–¹æ³•å°†ç«‹å³è¿”å›ï¼Œå½“æ‰€æœ‰çš„å¾…å®šæœŸè´§æ‰§è¡Œå®Œæ¯•åï¼Œä¸æ‰§è¡Œå™¨ç›¸å…³çš„èµ„æºå°†è¢«é‡Šæ”¾ã€‚æ— è®ºç­‰å¾…çš„å€¼æ˜¯å¤šå°‘ï¼Œæ•´ä¸ªPythonç¨‹åºéƒ½ä¸ä¼šé€€å‡ºï¼Œç›´åˆ°æ‰€æœ‰ç­‰å¾…çš„æœŸè´§æ‰§è¡Œå®Œæ¯•ã€‚

  å¦‚æœcancel_futuresä¸ºTrueï¼Œè¯¥æ–¹æ³•å°†å–æ¶ˆæ‰€æœ‰æ‰§è¡Œè€…å°šæœªå¼€å§‹è¿è¡Œçš„æœªå†³æœŸè´§ã€‚ä»»ä½•å·²ç»å®Œæˆæˆ–æ­£åœ¨è¿è¡Œçš„æœŸè´§éƒ½ä¸ä¼šè¢«å–æ¶ˆï¼Œä¸ç®¡cancel_futuresçš„å€¼å¦‚ä½•ã€‚

  å¦‚æœcancel_futureså’Œwaitéƒ½æ˜¯Trueï¼Œæ‰€æœ‰æ‰§è¡Œå™¨å·²ç»å¼€å§‹è¿è¡Œçš„æœŸè´§å°†åœ¨æ­¤æ–¹æ³•è¿”å›ä¹‹å‰å®Œæˆã€‚å‰©ä½™çš„æœŸè´§å°†è¢«å–æ¶ˆã€‚

  å¦‚æœä½ ä½¿ç”¨withè¯­å¥ï¼Œä½ å¯ä»¥é¿å…æ˜ç¡®åœ°è°ƒç”¨è¿™ä¸ªæ–¹æ³•ï¼Œå®ƒå°†å…³é—­æ‰§è¡Œå™¨ï¼ˆå°±åƒåœ¨è°ƒç”¨Executor.shutdown()æ—¶å°†ç­‰å¾…è®¾ç½®ä¸ºTrueä¸€æ ·ï¼‰ã€‚



### ThreadPoolExecutor

ThreadPoolExecutor æ˜¯ä¸€ä¸ª Executor å­ç±»ï¼Œå®ƒä½¿ç”¨çº¿ç¨‹æ± æ¥å¼‚æ­¥æ‰§è¡Œè°ƒç”¨ã€‚

å½“ä¸ Future å…³è”çš„å¯è°ƒç”¨å¯¹è±¡ç­‰å¾…å¦ä¸€ä¸ª Future çš„ç»“æœæ—¶ï¼Œå¯èƒ½ä¼šå‘ç”Ÿæ­»é”ã€‚ä¾‹å¦‚ï¼š

```python
import time

def wait_on_b():
    time.sleep(5)
    print(b.result())  # b will never complete because it is waiting on a.
    return 5

def wait_on_a():
    time.sleep(5)
    print(a.result())  # a will never complete because it is waiting on b.
    return 6

executor = ThreadPoolExecutor(max_workers=2)
a = executor.submit(wait_on_b)
b = executor.submit(wait_on_a)
```

And:

```python
def wait_on_future():
    f = executor.submit(pow, 5, 2)
    # This will never complete because there is only one worker thread and
    # it is executing this function.
    print(f.result())

executor = ThreadPoolExecutor(max_workers=1)
executor.submit(wait_on_future)
```

ä¸€ä¸ªExecutorå­ç±»ï¼Œä½¿ç”¨ä¸€ä¸ªæœ€å¤šç”±max_workersçº¿ç¨‹ç»„æˆçš„æ± æ¥å¼‚æ­¥æ‰§è¡Œè°ƒç”¨ã€‚

åœ¨è§£é‡Šå™¨é€€å‡ºä¹‹å‰ï¼Œæ‰€æœ‰æ’é˜Ÿåˆ° ThreadPoolExecutor çš„çº¿ç¨‹éƒ½å°†è¢«åŠ å…¥ã€‚è¯·æ³¨æ„ï¼Œæ‰§è¡Œæ­¤æ“ä½œçš„é€€å‡ºå¤„ç†ç¨‹åºåœ¨ä½¿ç”¨ atexit æ·»åŠ çš„ä»»ä½•é€€å‡ºå¤„ç†ç¨‹åºä¹‹å‰æ‰§è¡Œã€‚è¿™æ„å‘³ç€å¿…é¡»æ•è·å¹¶å¤„ç†ä¸»çº¿ç¨‹ä¸­çš„å¼‚å¸¸ï¼Œä»¥ä¾¿é€šçŸ¥çº¿ç¨‹æ­£å¸¸é€€å‡ºã€‚å› æ­¤ï¼Œå»ºè®®ä¸è¦å°† ThreadPoolExecutor ç”¨äºé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ã€‚

initializer æ˜¯ä¸€ä¸ªå¯é€‰çš„å¯è°ƒç”¨å¯¹è±¡ï¼Œåœ¨æ¯ä¸ªå·¥ä½œçº¿ç¨‹å¼€å§‹æ—¶è°ƒç”¨ï¼› initargs æ˜¯ä¼ é€’ç»™åˆå§‹åŒ–ç¨‹åºçš„å‚æ•°å…ƒç»„ã€‚å¦‚æœåˆå§‹åŒ–ç¨‹åºå¼•å‘å¼‚å¸¸ï¼Œæ‰€æœ‰å½“å‰æŒ‚èµ·çš„ä½œä¸šéƒ½å°†å¼•å‘ä¸€ä¸ª BrokenThreadPoolï¼Œä»¥åŠä»»ä½•å‘æ± æäº¤æ›´å¤šä½œä¸šçš„å°è¯•ã€‚

3.5ç‰ˆä¸­çš„ä¿®æ”¹ï¼šå¦‚æœmax_workersä¸ºNoneæˆ–æœªç»™å‡ºï¼Œå°†é»˜è®¤ä¸ºæœºå™¨ä¸Šçš„å¤„ç†å™¨æ•°é‡ï¼Œå†ä¹˜ä»¥5ï¼Œå‡è®¾ThreadPoolExecutorç»å¸¸è¢«ç”¨æ¥é‡å I/Oè€Œä¸æ˜¯CPUå·¥ä½œï¼Œworkersçš„æ•°é‡åº”è¯¥é«˜äºProcessPoolExecutorçš„workersæ•°é‡ã€‚

3.6ç‰ˆçš„æ–°å†…å®¹ã€‚å¢åŠ äº†thread_name_prefixå‚æ•°ï¼Œå…è®¸ç”¨æˆ·æ§åˆ¶ç”±æ± å­åˆ›å»ºçš„å·¥ä½œçº¿ç¨‹çš„çº¿ç¨‹åç§°ï¼Œä»¥æ–¹ä¾¿è°ƒè¯•ã€‚

åœ¨ 3.7 ç‰ˆæ›´æ”¹: æ·»åŠ äº†åˆå§‹åŒ–ç¨‹åºå’Œ initargs å‚æ•°ã€‚

åœ¨3.8ç‰ˆæœ¬ä¸­æœ‰æ‰€æ”¹å˜ã€‚max_workers çš„é»˜è®¤å€¼è¢«æ”¹ä¸º min(32, os.cpu_count() + 4)ã€‚è¿™ä¸ªé»˜è®¤å€¼ä¸ºI/Oç»‘å®šçš„ä»»åŠ¡ä¿ç•™äº†è‡³å°‘5ä¸ªå·¥ä½œè€…ã€‚å¯¹äºé‡Šæ”¾GILçš„CPUç»‘å®šä»»åŠ¡ï¼Œå®ƒæœ€å¤šåˆ©ç”¨32ä¸ªCPUæ ¸ã€‚è€Œä¸”å®ƒé¿å…äº†åœ¨å¤šæ ¸æœºå™¨ä¸Šéšå«åœ°ä½¿ç”¨éå¸¸å¤§çš„èµ„æºã€‚

ThreadPoolExecutorç°åœ¨åœ¨å¯åŠ¨max_workerså·¥ä½œçº¿ç¨‹ä¹‹å‰ä¹Ÿä¼šé‡ç”¨é—²ç½®çš„å·¥ä½œçº¿ç¨‹ã€‚



**ThreadPoolExecutor Example**

```python
import concurrent.futures
import urllib.request

URLS = ['http://www.foxnews.com/',
        'http://www.cnn.com/',
        'http://europe.wsj.com/',
        'http://www.bbc.co.uk/',
        'http://some-made-up-domain.com/']

# Retrieve a single page and report the URL and contents
def load_url(url, timeout):
    with urllib.request.urlopen(url, timeout=timeout) as conn:
        return conn.read()

# We can use a with statement to ensure threads are cleaned up promptly
with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
    # Start the load operations and mark each future with its URL
    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}
    for future in concurrent.futures.as_completed(future_to_url):
        url = future_to_url[future]
        try:
            data = future.result()
        except Exception as exc:
            print('%r generated an exception: %s' % (url, exc))
        else:
            print('%r page is %d bytes' % (url, len(data)))
```



### **ProcessPoolExecutor**

ProcessPoolExecutor ç±»æ˜¯ Executor å­ç±»ï¼Œå®ƒä½¿ç”¨è¿›ç¨‹æ± å¼‚æ­¥æ‰§è¡Œè°ƒç”¨ã€‚ ProcessPoolExecutor ä½¿ç”¨å¤šå¤„ç†æ¨¡å—ï¼Œè¿™å…è®¸å®ƒç»•è¿‡å…¨å±€è§£é‡Šå™¨é”ï¼Œä½†ä¹Ÿæ„å‘³ç€åªèƒ½æ‰§è¡Œå’Œè¿”å›å¯æå–å¯¹è±¡ã€‚

\__main__æ¨¡å—å¿…é¡»å¯ä»¥è¢«å·¥ä½œå­è¿›ç¨‹å¯¼å…¥ã€‚è¿™æ„å‘³ç€ ProcessPoolExecutor ä¸ä¼šåœ¨äº¤äº’å¼è§£é‡Šå™¨ä¸­å·¥ä½œã€‚

ä»æäº¤ç»™ProcessPoolExecutorçš„å¯è°ƒç”¨æ–¹æ³•ä¸­è°ƒç”¨Executoræˆ–Futureæ–¹æ³•å°†å¯¼è‡´æ­»é”ã€‚

ä¸€ä¸ª Executor å­ç±»ï¼Œå®ƒä½¿ç”¨æœ€å¤š max_workers ä¸ªè¿›ç¨‹æ± å¼‚æ­¥æ‰§è¡Œè°ƒç”¨ã€‚å¦‚æœ max_workers ä¸º None æˆ–æœªç»™å‡ºï¼Œå®ƒå°†é»˜è®¤ä¸ºæœºå™¨ä¸Šçš„å¤„ç†å™¨æ•°ã€‚å¦‚æœ max_workers å°äºæˆ–ç­‰äº 0ï¼Œåˆ™ä¼šå¼•å‘ ValueErrorã€‚åœ¨ Windows ä¸Šï¼Œmax_workers å¿…é¡»å°äºæˆ–ç­‰äº 61ã€‚å¦‚æœä¸æ˜¯ï¼Œåˆ™ä¼šå¼•å‘ ValueErrorã€‚å¦‚æœ max_workers ä¸º Noneï¼Œåˆ™é€‰æ‹©çš„é»˜è®¤å€¼æœ€å¤šä¸º 61ï¼Œå³ä½¿æœ‰æ›´å¤šå¤„ç†å™¨å¯ç”¨ã€‚ mp_context å¯ä»¥æ˜¯å¤šå¤„ç†ä¸Šä¸‹æ–‡æˆ–æ— ã€‚å®ƒå°†ç”¨äºå¯åŠ¨å·¥ä½œäººå‘˜ã€‚å¦‚æœ mp_context ä¸º None æˆ–æœªç»™å‡ºï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„å¤šå¤„ç†ä¸Šä¸‹æ–‡ã€‚

initializer æ˜¯ä¸€ä¸ªå¯é€‰çš„å¯è°ƒç”¨å¯¹è±¡ï¼Œåœ¨æ¯ä¸ªå·¥ä½œè¿›ç¨‹å¼€å§‹æ—¶è¢«è°ƒç”¨ï¼› initargs æ˜¯ä¼ é€’ç»™åˆå§‹åŒ–ç¨‹åºçš„å‚æ•°å…ƒç»„ã€‚å¦‚æœåˆå§‹åŒ–ç¨‹åºå¼•å‘å¼‚å¸¸ï¼Œæ‰€æœ‰å½“å‰æŒ‚èµ·çš„ä½œä¸šéƒ½å°†å¼•å‘ä¸€ä¸ª BrokenProcessPoolï¼Œä»¥åŠä»»ä½•å‘æ± æäº¤æ›´å¤šä½œä¸šçš„å°è¯•ã€‚

3.3ç‰ˆä¸­çš„æ”¹å˜ï¼šå½“ä¸€ä¸ªå·¥ä½œè¿›ç¨‹çªç„¶ç»ˆæ­¢æ—¶ï¼Œç°åœ¨ä¼šäº§ç”Ÿä¸€ä¸ªBrokenProcessPoolé”™è¯¯ã€‚ä»¥å‰ï¼Œè¡Œä¸ºæ˜¯æœªå®šä¹‰çš„ï¼Œä½†å¯¹æ‰§è¡Œè€…æˆ–å…¶æœŸè´§çš„æ“ä½œå¾€å¾€ä¼šå†»ç»“æˆ–æ­»é”ã€‚

3.7ç‰ˆä¸­çš„å˜åŒ–ï¼šå¢åŠ äº†mp_contextå‚æ•°ï¼Œå…è®¸ç”¨æˆ·æ§åˆ¶ç”±æ± å­åˆ›å»ºçš„å·¥ä½œè¿›ç¨‹çš„start_methodã€‚



**ProcessPoolExecutor  Example**

```python
import concurrent.futures
import math

PRIMES = [
    112272535095293,
    112582705942171,
    112272535095293,
    115280095190773,
    115797848077099,
    1099726899285419]

def is_prime(n):
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False

    sqrt_n = int(math.floor(math.sqrt(n)))
    for i in range(3, sqrt_n + 1, 2):
        if n % i == 0:
            return False
    return True

def main():
    with concurrent.futures.ProcessPoolExecutor() as executor:
        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):
            print('%d is prime: %s' % (number, prime))

if __name__ == '__main__':
    main()
```



## Requests--Issues

- åŸæ–‡åœ°å€ï¼š[Links](https://github.com/psf/requests/issues/2766)



> 
>
> **from gward:**
>
> Right now, it's quite difficult to figure out if the Session class is threadsafe or not. The docs don't say, apart from a "thread-safe" bullet on the home page. Google led me to http://stackoverflow.com/questions/18188044/is-the-session-object-from-pythons-requests-library-thread-safe, whose first answer boils down to "be very careful".Inspired by that SO author, I've been auditing the code myself, and have come to the conclusion that Session is probably not threadsafe. (The use of `self.redirect_cache` set off red flags for me.) Reading through other requests bug reports, I see maintainers recommending one Session per thread, which implies that it's not threadsafe.The documentation should clarify this and recommend how to use Session in multithreaded programs. Possible text: Session is not threadsafe. If you are using requests with an explicit Session object in a multithreaded program, you should create one Session per thread. If that's accurate, let me know and I'll submit a PR.Also, I think the "thread-safe" bullet should be removed from the home page, or maybe replaced by "thread-safe in certain circumstances".
>
> ğŸ‘55
>
> 





## <span style='color:brown'>Youtube--Python Threading Tutorial</span>

åŸæ–‡åœ°å€ï¼š

- [Run Code Concurrently Using the Threading Module](https://youtu.be/IEEhzQoKtQU)
- [Run Code in Parallel Using the Multiprocessing Module](https://youtu.be/fKl2JW_qrso)



### Run Code Concurrently Using the Threading Module

1ã€

```python
import threading
import time

start = time.perf_counter()

def do_something():
    print('Sleeping 1 second...')
    time.sleep(1)
    print('Done Sleeping...')

threads = []

for _ in range(10):
    t = threading.Thread(target=do_something)
    t.start()
    threads.append(t)
    
for thread in threads:
    thread.join()
    
finish = time.perf_counter()
print(f'Finished in {rount(finish-start, 2)} second(s)')
```



2ã€

```python
import threading
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping {seconds} second(s)...')
    time.sleep(seconds)
    print('Done Sleeping...')

threads = []

for _ in range(10):
    t = threading.Thread(target=do_something, args=[1.5])
    t.start()
    threads.append(t)
    
for thread in threads:
    thread.join()
    
finish = time.perf_counter()
print(f'Finished in {rount(finish-start, 2)} second(s)')
```



3ã€

```python
import concurrent.futures
import time

def do_something(seconds):
    print(f'Sleeping {seconds} second(s)...')
    time.sleep(seconds)
    print('Done Sleeping...')
    
with concurrent.futures.ThreadPoolExecutor() as executor:
    f1 = executor.submit(do_something, 1)
    print(f1.result())
    
finish = time.perf_counter()
print(f'Finished in {rount(finish-start, 2)} second(s)')
```



4ã€

```python
import concurrent.futures
import time

def do_something(seconds):
    print(f'Sleeping {seconds} second(s)...')
    time.sleep(seconds)
    print('Done Sleeping...')
    
with concurrent.futures.ThreadPoolExecutor() as executor:
    f1 = [executor.submit(do_something, 1) for _ in range(10)]
    
    for f in concurrent.futures.as_completed(results):
        print(f.result())
    
finish = time.perf_counter()
print(f'Finished in {rount(finish-start, 2)} second(s)')
```



5ã€

```python
import concurrent.futures
import time

def do_something(seconds):
    print(f'Sleeping {seconds} second(s)...')
    time.sleep(seconds)
    print('Done Sleeping...{seconds}')
    
with concurrent.futures.ThreadPoolExecutor() as executor:
    secs = [5, 4, 3, 2, 1]
    f1 = [executor.submit(do_something, sec) for sec in secs]
    
    for f in concurrent.futures.as_completed(results):
        print(f.result())
    
finish = time.perf_counter()
print(f'Finished in {rount(finish-start, 2)} second(s)')
```



6ã€

```python
import concurrent.futures
import time

def do_something(seconds):
    print(f'Sleeping {seconds} second(s)...')
    time.sleep(seconds)
    print('Done Sleeping...{seconds}')
    
with concurrent.futures.ThreadPoolExecutor() as executor:
    secs = [5, 4, 3, 2, 1]
    results = executor.map(do_something, secs)
    
    for f in concurrent.futures.as_completed(results):
        print(f.result())
    
finish = time.perf_counter()
print(f'Finished in {rount(finish-start, 2)} second(s)')
```



7ã€

```python
import requests
import time

img_urls = [
    'https://images.unspalsh.com/photo-1',
    'https://images.unspalsh.com/photo-2',
    'https://images.unspalsh.com/photo-3',
    'https://images.unspalsh.com/photo-4',
]

t1 = time.perf_counter()

for img_url in img_urls:
    img_bytes = requests.get(img_url).content
    img_name = img_url.split('/')[3]
    img_name = f'{img_name}.jpg'
    with open(img_name, 'wb') as img_file:
        img_file.write(img_bytes)
        print(f'{img_name} was downloaded...')
        
t2 = time.perf_counter()
print(f'Finished in {t2-t1} seconds')
```



```python
import requests
import time
import concurrent.futures

img_urls = [
    'https://images.unspalsh.com/photo-1',
    'https://images.unspalsh.com/photo-2',
    'https://images.unspalsh.com/photo-3',
    'https://images.unspalsh.com/photo-4',
]

t1 = time.perf_counter()

def download_image(img_url):
    img_bytes = requests.get(img_url).content
    img_name = img_url.split('/')[3]
    img_name = f'{img_name}.jpg'
    with open(img_name, 'wb') as img_file:
        img_file.write(img_bytes)
        print(f'{img_name} was downloaded...')
 
with concurrent.futures.ThreadPoolExecutor() as executor:
    executor.map(download_image, img_urls)

t2 = time.perf_counter()
print(f'Finished in {t2-t1} seconds')
```



### <span style='color:brown'>Run Code in Parallel Using the Multiprocessing Module</span>



<img src="imgs/Figure_7.png" alt="Figure_7" style="zoom: 40%;" />

<img src="imgs/Figure_8.png" alt="Figure_8" style="zoom:40%;" />

- æ³¨æ„ï¼š

  CPU bound v.s. I/O bound

1ã€

```python
import multiprocessing
import time

start = time.perf_counter()

def do_something():
    print('Sleeping 1 second...')
    time.sleep(1)
    print('Done Sleeping...')
    
p1 = multiprocessing.Process(target=do_something)
p2 = multiprocessing.Process(target=do_something)

p1.start()
p2.start()

p1.join()
p2.join()

finish = time.perf_counter()

print(f'Finished in {round(finish-start, 2)} second(s)')
```



2ã€

```python
import multiprocessing
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping {seconds} second(s)...')
    time.sleep(seconds)
    print('Done Sleeping...{seconds}')
 
processes = []

for _ in range(10):
    p = multiprocessing.Process(target=do_something, args=[1.5])
    p.start()
    processes.append(p)

for process in processes:
    process.join()
    
finish = time.perf_counter()

print(f'Finished in {round(finish-start, 2)} second(s)')
```



3ã€

**i/o bound:**

```python
import time
import concurrent.futures
from PIL import Image, ImageFilter

img_urls = [
    'photo-1.jpg',
    'photo-2.jpg',
    'photo-3.jpg',
    'photo-4.jpg',
]

t1 = time.perf_counter()
size = (1200, 1200)

for img_name in img_names:
    img = Image.open(img_name)
    img = img.filter(ImageFilter.GaussianBlur(15))
    img.thumbnail(size)
    img.save(f'processed/{img_name}')
    print(f'{img_name} was processed...')

t2 = time.perf_counter()
print(f'Finished in {t2-t1} seconds')
```

>  é¡ºåºå¤„ç†çš„è€—æ—¶ï¼š22.5 s

**cpu bound :**

```python
import time
import concurrent.futures
from PIL import Image, ImageFilter

img_names = [
    'photo-1.jpg',
    'photo-2.jpg',
    'photo-3.jpg',
    'photo-4.jpg',
]

t1 = time.perf_counter()
size = (1200, 1200)

def process_image(img_name):
    img = Image.open(img_name)
    img = img.filter(ImageFilter.GaussianBlur(15))
    img.thumbnail(size)
    img.save(f'processed/{img_name}')
    print(f'{img_name} was processed...')

with concurrent.futures.ProcessPoolExecutor() as executor:
    executor.map(process_image, img_name)
    
t2 = time.perf_counter()
print(f'Finished in {t2-t1} seconds')
```

> å¤„ç†è€—æ—¶ï¼š7.77 s



```python
import time
import concurrent.futures
from PIL import Image, ImageFilter

img_names = [
    'photo-1.jpg',
    'photo-2.jpg',
    'photo-3.jpg',
    'photo-4.jpg',
]

t1 = time.perf_counter()
size = (1200, 1200)

def process_image(img_name):
    img = Image.open(img_name)
    img = img.filter(ImageFilter.GaussianBlur(15))
    img.thumbnail(size)
    img.save(f'processed/{img_name}')
    print(f'{img_name} was processed...')

with concurrent.futures.ThreadPoolExecutor() as executor:
    executor.map(process_image, img_name)
    
t2 = time.perf_counter()
print(f'Finished in {t2-t1} seconds')
```

> è€—æ—¶ï¼š7.289 s





## <span style='color:brown'>ä»£ç è¡¥å…¨çš„æ€§èƒ½æµ‹è¯•è„šæœ¬è®¾è®¡</span>



```python
import requests
import concurrent.futures
import json
import time
import threading

hints = ['def quicksort():', 'import seaborn', 'import numpy']
start = time.perf_counter()
base_url = 'http://10.17.68.105:7000/predictions/codegen'
headers = {'Content-Type': 'application/json'}

time_list = []

def do_request(name):
    dict = {}
    dict['data'] = 'def quicksort():'
    t1 = time.perf_counter()
    r = requests.post(base_url, data=json.dumps(dict), headers=headers)
    t2 = time.perf_counter()
    single_time = t2 - t1
    time_list.append(single_time)
    return r.text

i = 0

threads = []

while(i<100):
    i = i + 1
    time.sleep(0.01)
    t = threading.Thread(target=do_request, args=(str(i),))
    t.start()
    
    
for thread in threads:
    thread.join()
    
print('**** avg time: ',  sum(time_list)/len(time_list))
print('**** max - avg :', max(time_list) - sum(time_list)/len(time_list))
```


