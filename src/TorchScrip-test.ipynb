{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","background_execution":"on","mount_file_id":"1F-zXDllGrX3MkqnJhWynSYn_vwTFm1zY","authorship_tag":"ABX9TyNYHnwb6pJ0Qnqce3TOv3hZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8c59c2a67b31435d8e435ed1b0210558":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b202fd188ce14ec4834cc34c1544fcc5","IPY_MODEL_872980fc8b9a4c67ad8301abcdcdc0dd","IPY_MODEL_f72688febf8747e7adbd0bf98f636940"],"layout":"IPY_MODEL_a4b89b5de0464cd7ae3404886df4dc7f"}},"b202fd188ce14ec4834cc34c1544fcc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b523fe57d27945beb129d98c674828f5","placeholder":"​","style":"IPY_MODEL_85b69987ffa44f6badb248177b841fea","value":"Downloading vocab.txt: 100%"}},"872980fc8b9a4c67ad8301abcdcdc0dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dc0a556195040788707d0af863309ee","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7b871b9c22748cc95366457f045436c","value":231508}},"f72688febf8747e7adbd0bf98f636940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f03b0c0929bd416da6620e38407afd89","placeholder":"​","style":"IPY_MODEL_f64c666fee644a4392ef4a72ca7aba8e","value":" 226k/226k [00:00&lt;00:00, 562kB/s]"}},"a4b89b5de0464cd7ae3404886df4dc7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b523fe57d27945beb129d98c674828f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85b69987ffa44f6badb248177b841fea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4dc0a556195040788707d0af863309ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7b871b9c22748cc95366457f045436c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f03b0c0929bd416da6620e38407afd89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f64c666fee644a4392ef4a72ca7aba8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"238c8d5d66c34da8922429da0e517278":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f7b8455f7d945e4a72bdfead8f78fe1","IPY_MODEL_b565ea4cbb12455ab527760607754d79","IPY_MODEL_f822de3db2b848e98dbef46cbfd4d266"],"layout":"IPY_MODEL_a8466e9901554c5ca2c3533205c6dcf3"}},"4f7b8455f7d945e4a72bdfead8f78fe1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4edc566416c4fecb9dc0b4ab6ba155b","placeholder":"​","style":"IPY_MODEL_c7c61826996c4d0c9decb5ccfa785ef6","value":"Downloading tokenizer_config.json: 100%"}},"b565ea4cbb12455ab527760607754d79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b437f43ff32b41b4b90ea0e913b609ca","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58c0939e7eed46688f6a842c438c92f4","value":28}},"f822de3db2b848e98dbef46cbfd4d266":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bff01024c1b4499a6f0218c1e34dac8","placeholder":"​","style":"IPY_MODEL_a6e6aaa50cef4fbdb86b247d28e4e07a","value":" 28.0/28.0 [00:00&lt;00:00, 351B/s]"}},"a8466e9901554c5ca2c3533205c6dcf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4edc566416c4fecb9dc0b4ab6ba155b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7c61826996c4d0c9decb5ccfa785ef6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b437f43ff32b41b4b90ea0e913b609ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58c0939e7eed46688f6a842c438c92f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4bff01024c1b4499a6f0218c1e34dac8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6e6aaa50cef4fbdb86b247d28e4e07a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ef865e5b0664878ad3753f00aa5a981":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_718b1e5088554b1ea5ea56c972d4ca7c","IPY_MODEL_2db9b85a050e4d1e8578c4d4d72cb236","IPY_MODEL_e5150f6f93de46ebb268818e459c215c"],"layout":"IPY_MODEL_0cfe97ff91734d20bc1f873547a32dea"}},"718b1e5088554b1ea5ea56c972d4ca7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_131595f55c84495ba29647fc257db9d8","placeholder":"​","style":"IPY_MODEL_97f75efe45c34f9981080659431d87cb","value":"Downloading config.json: 100%"}},"2db9b85a050e4d1e8578c4d4d72cb236":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f85a86e1f211421c8bf4d5c7da3e63e1","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee51c871d0e2401c81befc8e5108af0b","value":570}},"e5150f6f93de46ebb268818e459c215c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af3f71fcbf824affb129d0e04c453f0f","placeholder":"​","style":"IPY_MODEL_f293e8cf5a2e43aaaad4a2b130ae972d","value":" 570/570 [00:00&lt;00:00, 3.89kB/s]"}},"0cfe97ff91734d20bc1f873547a32dea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"131595f55c84495ba29647fc257db9d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97f75efe45c34f9981080659431d87cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f85a86e1f211421c8bf4d5c7da3e63e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee51c871d0e2401c81befc8e5108af0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af3f71fcbf824affb129d0e04c453f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f293e8cf5a2e43aaaad4a2b130ae972d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7379c92aec574b5ab3d3ce6ab867e8d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ef1d889def04d1b813ef4e0aedf2643","IPY_MODEL_ce7975ab32ea41acb26c8a496e084a67","IPY_MODEL_f677a16d135a4e409f967150d895fc50"],"layout":"IPY_MODEL_6a215e313fc7481584c826300d014f95"}},"0ef1d889def04d1b813ef4e0aedf2643":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5b37a30f1f74ab790503e021d42ca2a","placeholder":"​","style":"IPY_MODEL_2e62f0520693405788aeed55eb9394b3","value":"Downloading pytorch_model.bin: 100%"}},"ce7975ab32ea41acb26c8a496e084a67":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a1ad33175cd4d34a7b7b637a845bc4f","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88f6a16525b243aa9a89eede0d8bf628","value":440473133}},"f677a16d135a4e409f967150d895fc50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3b9ffc02754419ca31577501e3f4a8b","placeholder":"​","style":"IPY_MODEL_a6687f9875b544039e43fcc9c61b6f8f","value":" 420M/420M [00:10&lt;00:00, 23.8MB/s]"}},"6a215e313fc7481584c826300d014f95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b37a30f1f74ab790503e021d42ca2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e62f0520693405788aeed55eb9394b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a1ad33175cd4d34a7b7b637a845bc4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88f6a16525b243aa9a89eede0d8bf628":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3b9ffc02754419ca31577501e3f4a8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6687f9875b544039e43fcc9c61b6f8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9de7aa3ac27947168abc621f4041cead":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc569aedb8da4e998f57b61b368047a8","IPY_MODEL_6a0ec669d2af42f4977fc0d0fe869416","IPY_MODEL_d366133341624ebc9cc87e23ba7215a0"],"layout":"IPY_MODEL_6cdc1e68bcb649b0a548460ffc53732b"}},"bc569aedb8da4e998f57b61b368047a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_704cec778b1546d78a064009c9b52fa2","placeholder":"​","style":"IPY_MODEL_2ef73f362e1c4c03a9a4818c301c96b4","value":"Downloading spiece.model: 100%"}},"6a0ec669d2af42f4977fc0d0fe869416":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3de55c06cd847f1b35fcba068362dab","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39c74fd0985b4761a1a1aebcd87d5a31","value":791656}},"d366133341624ebc9cc87e23ba7215a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_696617406e114edfba513da75f0ba222","placeholder":"​","style":"IPY_MODEL_19cb2ae10650463d97c38be11a67bc81","value":" 773k/773k [00:00&lt;00:00, 946kB/s]"}},"6cdc1e68bcb649b0a548460ffc53732b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"704cec778b1546d78a064009c9b52fa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ef73f362e1c4c03a9a4818c301c96b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3de55c06cd847f1b35fcba068362dab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39c74fd0985b4761a1a1aebcd87d5a31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"696617406e114edfba513da75f0ba222":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19cb2ae10650463d97c38be11a67bc81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99805e364c3b424f91dcc6ecf938337a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d9fe9d3b9d54ff4989040d7e74a7f6b","IPY_MODEL_b7c259c24a4a4f149a85161ef653d633","IPY_MODEL_e9464a4069154e278f695c226e0157af"],"layout":"IPY_MODEL_82bd4d696ef24e26a7c478edc959e6e8"}},"4d9fe9d3b9d54ff4989040d7e74a7f6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b37bd38371cf48b7a1bebc9f98be7816","placeholder":"​","style":"IPY_MODEL_2f6f18940fb447e3917474dbc8e3ee16","value":"Downloading config.json: 100%"}},"b7c259c24a4a4f149a85161ef653d633":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b27ff5cf02a49858fb4480a49bcbe9b","max":1197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f50e504fb86849769a82cb890abbbed4","value":1197}},"e9464a4069154e278f695c226e0157af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a622f2d90a3d407fbd6e5c6fa7f07087","placeholder":"​","style":"IPY_MODEL_1fcb15557cc3402faa9d429c0fc462d5","value":" 1.17k/1.17k [00:00&lt;00:00, 28.6kB/s]"}},"82bd4d696ef24e26a7c478edc959e6e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b37bd38371cf48b7a1bebc9f98be7816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f6f18940fb447e3917474dbc8e3ee16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b27ff5cf02a49858fb4480a49bcbe9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f50e504fb86849769a82cb890abbbed4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a622f2d90a3d407fbd6e5c6fa7f07087":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fcb15557cc3402faa9d429c0fc462d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d779c9a26f8340f99d8f7bc31cf42f3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8deb4d2a3d384571ba7a260a401cb472","IPY_MODEL_bd16e7fd4d20412bafda53e6eeebfc13","IPY_MODEL_e3333daef34843069c73898f996403c1"],"layout":"IPY_MODEL_3607d8556d14495aa26c087cd8a64954"}},"8deb4d2a3d384571ba7a260a401cb472":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5eaa5b610043430b80288727d94180bc","placeholder":"​","style":"IPY_MODEL_6e183f012fde41099ae87e95c436a81e","value":"Downloading pytorch_model.bin: 100%"}},"bd16e7fd4d20412bafda53e6eeebfc13":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c90a7a8ad85449db4b3f237f677dcc5","max":242065649,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bda6c39b24941aca2fa9e303b3764be","value":242065649}},"e3333daef34843069c73898f996403c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4123d173acd7494092d055d7b5390221","placeholder":"​","style":"IPY_MODEL_5322beb59344415086d781e1d1de963f","value":" 231M/231M [00:14&lt;00:00, 23.9MB/s]"}},"3607d8556d14495aa26c087cd8a64954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5eaa5b610043430b80288727d94180bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e183f012fde41099ae87e95c436a81e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c90a7a8ad85449db4b3f237f677dcc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bda6c39b24941aca2fa9e303b3764be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4123d173acd7494092d055d7b5390221":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5322beb59344415086d781e1d1de963f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9f5491d56464f28af2bff44cb5666eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5f943e44b594c4a8327b1269ea973ba","IPY_MODEL_bb039c4b3b9b49f69f2ebe71767bfa0d","IPY_MODEL_448cce89bc7e4756b5de1522b33a8f30"],"layout":"IPY_MODEL_b28cdd47957448bcbaecbeadfe753e7d"}},"d5f943e44b594c4a8327b1269ea973ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33f33e73ffe34e5c83071ea469885975","placeholder":"​","style":"IPY_MODEL_77ca0c757fb34af4a9aac2ca7dab2886","value":"Downloading spiece.model: 100%"}},"bb039c4b3b9b49f69f2ebe71767bfa0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99f2a7b9877a41d7ac562375351de113","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a63fccef94842b9a251af1d7f845fad","value":791656}},"448cce89bc7e4756b5de1522b33a8f30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_077db92dbd48461dace37afda033e21f","placeholder":"​","style":"IPY_MODEL_643a30ee26694d26bd86f58f16f922c7","value":" 773k/773k [00:00&lt;00:00, 1.50MB/s]"}},"b28cdd47957448bcbaecbeadfe753e7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33f33e73ffe34e5c83071ea469885975":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77ca0c757fb34af4a9aac2ca7dab2886":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99f2a7b9877a41d7ac562375351de113":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a63fccef94842b9a251af1d7f845fad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"077db92dbd48461dace37afda033e21f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643a30ee26694d26bd86f58f16f922c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d1452a528f438c953ac52142a3a197":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_647d05e42d634b599fb7657f6e31dd21","IPY_MODEL_bdfaf407d58149cfb267e47aace49f58","IPY_MODEL_863902e74fb14ea8a396de12063cb7e9"],"layout":"IPY_MODEL_108409ac1436427592f11c6642eab7db"}},"647d05e42d634b599fb7657f6e31dd21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78654f33f9ad46b1a62415e768d05504","placeholder":"​","style":"IPY_MODEL_87ff2c38cfb944f38e1c6f2ba0ce59de","value":"Downloading config.json: 100%"}},"bdfaf407d58149cfb267e47aace49f58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0f4f9e865fe4863b9a066ac79f14ef5","max":443,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7995640a3f2049b4858c92999d7f29a2","value":443}},"863902e74fb14ea8a396de12063cb7e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43a331fb85974ab48d748abc5a067c9d","placeholder":"​","style":"IPY_MODEL_781478346a7541458cb4e675f2b82941","value":" 443/443 [00:00&lt;00:00, 11.2kB/s]"}},"108409ac1436427592f11c6642eab7db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78654f33f9ad46b1a62415e768d05504":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87ff2c38cfb944f38e1c6f2ba0ce59de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0f4f9e865fe4863b9a066ac79f14ef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7995640a3f2049b4858c92999d7f29a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43a331fb85974ab48d748abc5a067c9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"781478346a7541458cb4e675f2b82941":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"765c2ba6377642d5876d2d9eee2892bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a0762ee215f413f9f23d8b55c0f18cf","IPY_MODEL_d0ebaeece8f64105989b4d320d1b4427","IPY_MODEL_abce69ffdc584d0c9342fdbef1e7e9da"],"layout":"IPY_MODEL_bdcb2be2ad1f4d9a8cde41184e19c4c2"}},"9a0762ee215f413f9f23d8b55c0f18cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b603e53908964cc88a4cd73755cd62f9","placeholder":"​","style":"IPY_MODEL_1f12cd450b344d33be7b748c614ea7ea","value":"Downloading pytorch_model.bin: 100%"}},"d0ebaeece8f64105989b4d320d1b4427":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_986efd87631f4ffc89be6257c35ac37b","max":1340675298,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0422aff32d9402ca430d0f383066650","value":1340675298}},"abce69ffdc584d0c9342fdbef1e7e9da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3212dc2a580f49c185dd0656f6ce064a","placeholder":"​","style":"IPY_MODEL_b8386e367a8c4541949cccc8c5d2709a","value":" 1.25G/1.25G [00:46&lt;00:00, 35.8MB/s]"}},"bdcb2be2ad1f4d9a8cde41184e19c4c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b603e53908964cc88a4cd73755cd62f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f12cd450b344d33be7b748c614ea7ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"986efd87631f4ffc89be6257c35ac37b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0422aff32d9402ca430d0f383066650":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3212dc2a580f49c185dd0656f6ce064a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8386e367a8c4541949cccc8c5d2709a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## HuggingFace Transformers \n","#### Export Transformers models\n","- TorchScript\n","  "],"metadata":{"id":"VBV4s_ut4f9x"}},{"cell_type":"markdown","source":["### 01、BERT Example test"],"metadata":{"id":"aaciV3TL68nb"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5BFydqu5ZBr","executionInfo":{"status":"ok","timestamp":1661244664456,"user_tz":-480,"elapsed":12036,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"211df0a1-9a7c-4c3a-937d-8a18c78c6729"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 7.2 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 36.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.8.1 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["8c59c2a67b31435d8e435ed1b0210558","b202fd188ce14ec4834cc34c1544fcc5","872980fc8b9a4c67ad8301abcdcdc0dd","f72688febf8747e7adbd0bf98f636940","a4b89b5de0464cd7ae3404886df4dc7f","b523fe57d27945beb129d98c674828f5","85b69987ffa44f6badb248177b841fea","4dc0a556195040788707d0af863309ee","d7b871b9c22748cc95366457f045436c","f03b0c0929bd416da6620e38407afd89","f64c666fee644a4392ef4a72ca7aba8e","238c8d5d66c34da8922429da0e517278","4f7b8455f7d945e4a72bdfead8f78fe1","b565ea4cbb12455ab527760607754d79","f822de3db2b848e98dbef46cbfd4d266","a8466e9901554c5ca2c3533205c6dcf3","f4edc566416c4fecb9dc0b4ab6ba155b","c7c61826996c4d0c9decb5ccfa785ef6","b437f43ff32b41b4b90ea0e913b609ca","58c0939e7eed46688f6a842c438c92f4","4bff01024c1b4499a6f0218c1e34dac8","a6e6aaa50cef4fbdb86b247d28e4e07a","1ef865e5b0664878ad3753f00aa5a981","718b1e5088554b1ea5ea56c972d4ca7c","2db9b85a050e4d1e8578c4d4d72cb236","e5150f6f93de46ebb268818e459c215c","0cfe97ff91734d20bc1f873547a32dea","131595f55c84495ba29647fc257db9d8","97f75efe45c34f9981080659431d87cb","f85a86e1f211421c8bf4d5c7da3e63e1","ee51c871d0e2401c81befc8e5108af0b","af3f71fcbf824affb129d0e04c453f0f","f293e8cf5a2e43aaaad4a2b130ae972d","7379c92aec574b5ab3d3ce6ab867e8d4","0ef1d889def04d1b813ef4e0aedf2643","ce7975ab32ea41acb26c8a496e084a67","f677a16d135a4e409f967150d895fc50","6a215e313fc7481584c826300d014f95","f5b37a30f1f74ab790503e021d42ca2a","2e62f0520693405788aeed55eb9394b3","8a1ad33175cd4d34a7b7b637a845bc4f","88f6a16525b243aa9a89eede0d8bf628","f3b9ffc02754419ca31577501e3f4a8b","a6687f9875b544039e43fcc9c61b6f8f"]},"id":"_4atSW0l4PYp","executionInfo":{"status":"ok","timestamp":1661244702713,"user_tz":-480,"elapsed":32665,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"86b5c7fa-08e4-4d78-c39b-c59743747998"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c59c2a67b31435d8e435ed1b0210558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"238c8d5d66c34da8922429da0e517278"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ef865e5b0664878ad3753f00aa5a981"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7379c92aec574b5ab3d3ce6ab867e8d4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import BertModel, BertTokenizer, BertConfig\n","import torch\n","\n","enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","\n","# Tokenizing input text\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = enc.tokenize(text)\n","\n","# Masking one of the input tokens\n","masked_index = 8\n","tokenized_text[masked_index] = \"[MASK]\"\n","indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n","segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n","\n","# Creating a dummy input\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])\n","\n","dummy_input = [tokens_tensor, segments_tensors]\n","\n","\n","# Initializing the model with the torchscript flag\n","# Flag set to True even though it is not necessary as this model does not have an LM Head.\n","# config = BertConfig(\n","#     vocab_size_or_config_json_file=32000,\n","#     hidden_size=768,\n","#     num_hidden_layers=12,\n","#     num_attention_heads=12,\n","#     intermediate_size=3072,\n","#     torchscript=True,\n","# )\n","\n","# # Instantiating the model\n","# model = BertModel(config)\n","\n","# The model needs to be in evaluation mode\n","model.eval()\n","\n","# If you are instantiating the model with *from_pretrained* you can also easily set the TorchScript flag\n","model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n","\n","# Creating the trace\n","traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n","torch.jit.save(traced_model, \"traced_bert.pt\")"]},{"cell_type":"code","source":["loaded_model = torch.jit.load(\"traced_bert.pt\")\n","loaded_model.eval()\n","\n","# Tokenizing input text\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = enc.tokenize(text)\n","\n","# Masking one of the input tokens\n","masked_index = 8\n","tokenized_text[masked_index] = \"[MASK]\"\n","indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n","segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n","\n","# Creating a dummy input\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])\n","\n","dummy_input = [tokens_tensor, segments_tensors]\n","\n","all_encoder_layers, pooled_output = loaded_model(*dummy_input)"],"metadata":{"id":"NrL7jMdk40Ph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pooled_output = loaded_model(*dummy_input)"],"metadata":{"id":"Xaim7L3XFDYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pooled_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HhAAunIdGhq_","executionInfo":{"status":"ok","timestamp":1662003083037,"user_tz":-480,"elapsed":327,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"803df6f9-fc90-4e3d-e993-bf773f24e83a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[[-2.5689e-01, -7.3599e-03, -8.9147e-02,  ..., -1.3546e-01,\n","           2.3597e-01,  2.4208e-01],\n","         [-5.8262e-01,  3.1923e-01, -2.8020e-01,  ...,  1.0413e-01,\n","           1.7953e-01, -4.7086e-01],\n","         [-3.0671e-01, -2.3213e-01, -1.5938e-01,  ...,  7.0993e-02,\n","           1.4761e-01,  2.7529e-01],\n","         ...,\n","         [ 2.0549e-01, -1.6317e-02, -7.1004e-05,  ..., -1.3032e-01,\n","           6.1008e-01,  4.2999e-01],\n","         [-4.9530e-01, -4.6195e-01, -2.9027e-01,  ...,  6.3559e-01,\n","           6.2100e-01,  1.0318e-01],\n","         [ 8.2051e-01,  1.8250e-01, -1.1302e-01,  ...,  1.5103e-01,\n","          -7.6513e-01, -1.9481e-02]]], grad_fn=<DifferentiableGraphBackward>), tensor([[-4.9859e-01, -1.6913e-01,  8.3044e-01,  7.2490e-02, -4.8807e-01,\n","         -9.1259e-02,  5.1964e-01,  1.2615e-01,  7.3988e-01, -9.9609e-01,\n","          3.7945e-01, -5.8106e-01,  9.5275e-01, -6.8154e-01,  7.0220e-01,\n","         -2.4374e-01,  9.2702e-02, -3.1205e-01,  2.3801e-01, -3.3289e-01,\n","          2.2093e-01, -3.1050e-01,  7.1334e-01,  6.8511e-02,  1.5540e-01,\n","         -7.6150e-01, -2.8993e-01,  7.5329e-01,  8.3334e-01,  5.7146e-01,\n","         -3.3142e-01,  1.4806e-01, -9.5029e-01, -9.6337e-02,  7.7407e-01,\n","         -9.3747e-01, -3.0847e-02, -4.7886e-01,  4.4816e-02,  1.1357e-02,\n","         -6.1463e-01,  2.0118e-01,  9.0852e-01, -6.6917e-01, -3.0572e-01,\n","         -2.4733e-01, -6.9975e-01,  9.1703e-02, -6.5932e-01, -8.4444e-01,\n","         -7.1574e-01, -8.7206e-01,  5.5364e-02,  1.0259e-01,  2.0758e-01,\n","          4.1869e-01, -2.2090e-01,  6.6650e-02,  3.9337e-02, -3.4385e-01,\n","         -4.0217e-01,  3.1609e-02,  6.8003e-01, -7.3265e-01, -7.0735e-01,\n","         -8.4914e-01, -3.4449e-02, -7.7896e-02,  1.1542e-01, -5.8604e-02,\n","          5.3955e-01,  7.7160e-02,  4.1768e-01, -4.7927e-01, -7.7228e-01,\n","          1.0024e-01, -1.9495e-01,  9.0035e-01,  2.1756e-01, -9.3141e-01,\n","         -6.6439e-01, -6.5286e-01,  1.0850e-01,  8.2425e-01, -8.0041e-01,\n","         -8.0010e-01,  1.9082e-01, -8.2846e-03, -9.5559e-01,  1.0529e-01,\n","          4.8709e-02, -2.7277e-02, -7.0070e-01,  1.2284e-01,  1.0367e-01,\n","          1.1624e-01, -3.6921e-02,  6.1928e-01,  3.4673e-02,  2.5419e-01,\n","         -1.0259e-01,  5.9038e-03,  2.2802e-01, -1.5938e-01, -9.4064e-02,\n","         -1.3483e-01,  9.1638e-02, -2.5277e-01, -4.0633e-01,  3.5905e-01,\n","          1.7583e-01, -5.4669e-02, -3.7656e-02, -8.2613e-01,  3.9060e-01,\n","         -7.5958e-02, -9.2011e-01, -1.5846e-01, -9.5379e-01,  4.7328e-01,\n","          2.2438e-01, -4.0782e-02,  8.4882e-01,  7.4372e-01,  6.8334e-02,\n","          1.2067e-01,  8.3558e-01, -9.3571e-01,  2.5638e-01,  2.7365e-01,\n","          5.1111e-01,  2.4959e-03, -9.1422e-01, -8.5609e-01,  2.6730e-01,\n","          8.2105e-01, -1.9208e-02,  9.0641e-01,  3.1729e-02,  8.1417e-01,\n","          5.3713e-01,  1.5256e-01, -6.5996e-01, -2.9205e-01, -2.6196e-01,\n","         -6.0163e-02, -1.6913e-01,  1.9751e-01,  4.2851e-01, -5.6606e-01,\n","          3.2405e-01, -1.4614e-01,  7.3622e-01, -7.3622e-01, -3.0769e-01,\n","          7.5544e-01,  5.2388e-01,  8.3670e-01,  7.7318e-01,  2.1111e-02,\n","         -1.0186e-01,  5.3786e-01, -1.1288e-01,  1.2010e-01,  2.8660e-01,\n","          1.5836e-01, -5.5910e-01,  1.3677e-01, -6.5858e-01,  4.6724e-01,\n","          1.8676e-01, -7.8814e-04,  8.0405e-01, -9.3026e-01, -6.9134e-02,\n","          2.2026e-01,  9.3376e-01,  4.8834e-01,  6.0626e-02, -5.2468e-01,\n","         -6.7205e-02, -2.8043e-01, -8.0448e-01,  9.1711e-01,  3.1231e-02,\n","          1.4967e-01,  5.4755e-01, -5.2422e-01, -6.1328e-01, -6.5674e-01,\n","          5.5004e-01,  3.5562e-01, -6.2681e-01,  1.7565e-01, -2.6099e-01,\n","         -1.2162e-01,  5.5805e-01,  1.7059e-01, -7.8489e-02, -2.6815e-01,\n","          1.2040e-01,  7.8531e-01,  6.7986e-01,  4.0405e-01, -7.0169e-01,\n","          1.0016e-01, -6.9205e-01,  3.5772e-02,  7.4413e-02,  1.4686e-01,\n","         -4.7862e-02,  9.5771e-01,  2.1660e-01,  6.9758e-04, -6.7157e-01,\n","         -9.2958e-01,  1.2179e-02, -6.3569e-01,  1.3246e-01, -3.6443e-01,\n","         -1.9593e-01,  6.1201e-01, -5.9816e-01,  7.9575e-02, -7.0562e-01,\n","         -5.6153e-01,  9.3639e-02, -1.2182e-01,  1.3971e-01, -5.4726e-02,\n","          3.1027e-01, -7.9235e-01, -2.9843e-01,  3.6523e-01,  7.2965e-01,\n","          8.2288e-01, -4.8346e-01,  3.6060e-01, -1.5700e-02,  6.6516e-01,\n","         -3.1768e-01,  8.6993e-01, -6.7448e-01, -7.0250e-02, -7.9002e-01,\n","          5.6488e-01, -6.6356e-01,  6.4933e-01, -4.8080e-03, -8.2526e-01,\n","         -6.7866e-01,  1.6267e-01,  5.3347e-02,  8.8357e-01, -7.1264e-02,\n","          8.2370e-01, -5.7167e-01, -8.5698e-01, -1.2295e-01,  2.3306e-01,\n","         -9.4883e-01, -6.4056e-01,  9.9413e-02, -6.6189e-01, -1.6533e-01,\n","          7.5128e-03, -8.3298e-01,  4.5723e-01,  8.1019e-02,  8.3341e-01,\n","          2.2406e-01, -5.3090e-01,  1.4762e-01, -7.6026e-01, -1.6274e-01,\n","          1.3930e-01,  8.2007e-01, -9.1361e-02, -8.5741e-01,  2.0810e-01,\n","          2.9116e-01,  1.5543e-01,  8.5719e-01,  8.7265e-01,  6.3798e-01,\n","          9.2237e-01,  7.0844e-01,  4.0798e-01,  3.7541e-01,  8.2557e-02,\n","          9.9737e-01,  6.1868e-01, -7.9913e-01, -8.2941e-01, -2.8434e-01,\n","          1.2858e-01, -9.2797e-01, -6.3592e-02,  4.6552e-02, -8.1194e-01,\n","         -7.1708e-01,  9.1365e-01,  7.2862e-01, -8.9509e-01,  7.3806e-01,\n","          7.2612e-01, -2.3452e-01, -6.6035e-01,  6.3779e-02,  9.3092e-01,\n","          1.6668e-02,  3.3495e-01, -1.8452e-02,  1.5112e-01,  4.9735e-01,\n","         -5.7902e-01,  6.5534e-01,  6.6720e-01, -6.5395e-01, -8.4177e-02,\n","         -1.6271e-01, -7.9912e-01, -3.1524e-01,  1.7052e-03, -3.4439e-01,\n","         -8.4678e-01, -2.0301e-02, -5.9327e-01,  1.5047e-01, -4.0945e-03,\n","          1.0240e-03, -5.2182e-01,  4.0745e-02, -8.2124e-01,  1.3655e-01,\n","          3.0421e-01, -7.6729e-01, -1.4364e-01,  3.7359e-01, -5.8641e-01,\n","          6.7145e-01, -8.4058e-01,  8.8928e-01, -4.8594e-02, -7.0527e-01,\n","          9.0982e-01, -1.3674e-01, -6.2551e-01, -1.2153e-01, -5.7317e-02,\n","          1.6933e-01,  8.5137e-01, -3.0268e-01, -9.2407e-01, -1.4311e-01,\n","         -2.2600e-01, -4.9942e-02,  7.3210e-02,  9.7865e-01,  3.2855e-02,\n","          6.2553e-01,  6.3310e-01,  9.3339e-01, -9.5555e-01, -6.6198e-01,\n","         -6.5063e-01, -8.4128e-01,  8.7723e-01,  7.9893e-01,  1.4459e-01,\n","         -1.9865e-01, -6.9513e-02,  6.3042e-01, -1.2870e-02, -7.2304e-01,\n","          2.7195e-01,  2.2727e-01, -2.9498e-02,  7.1309e-01, -4.8478e-01,\n","         -1.1718e-01,  2.0216e-01,  4.6508e-01,  4.6507e-01, -7.6713e-01,\n","          2.0409e-01, -5.9565e-03, -8.2280e-02, -8.4956e-02, -1.4858e-01,\n","         -8.5327e-01, -3.6672e-01,  8.7005e-01,  1.9555e-01, -6.6828e-01,\n","          1.5964e-01, -1.6004e-02, -3.9608e-01,  1.0805e-01,  9.5431e-02,\n","         -8.3893e-02, -5.9011e-01, -6.5418e-01, -5.9851e-01, -9.5626e-01,\n","          2.0579e-01,  2.3757e-02, -3.0543e-02,  5.7845e-01,  1.2862e-01,\n","         -8.2295e-03, -2.6664e-01, -6.8082e-01, -9.6271e-02,  6.9126e-02,\n","         -8.6602e-01,  8.7522e-01, -1.0679e-01,  1.2648e-01,  3.2427e-01,\n","          7.7688e-01, -9.3565e-02, -3.4144e-01, -4.7952e-02, -7.3323e-01,\n","          1.4223e-01, -8.2471e-01,  8.3261e-01, -8.1426e-01,  7.6197e-02,\n","         -5.7766e-02, -4.5483e-01,  9.0928e-01, -1.8027e-01,  2.0544e-01,\n","         -1.8068e-01,  4.2399e-01,  3.3363e-01, -2.0288e-01, -2.2413e-01,\n","          3.6761e-02,  8.0875e-01, -1.0996e-03,  3.5741e-02, -9.0296e-01,\n","         -7.9219e-01, -5.2211e-01, -6.7589e-01, -9.5255e-01,  7.0411e-01,\n","          2.6826e-01,  4.0882e-02,  5.4808e-01, -2.2253e-01, -2.8980e-01,\n","         -8.3246e-02,  1.0494e-01, -8.2818e-01,  7.8696e-01, -1.0552e-01,\n","          2.0068e-01, -1.1545e-01,  2.2196e-01, -8.5198e-01,  8.6098e-01,\n","          7.5903e-01,  2.5622e-01, -8.8536e-03, -4.7662e-01,  3.9720e-01,\n","         -3.4306e-01,  8.0380e-01, -7.8319e-02,  8.9613e-01, -1.4736e-01,\n","         -7.5046e-01,  3.7599e-01,  2.0120e-01,  6.4580e-02,  4.4332e-02,\n","         -8.3205e-01,  3.1302e-03,  7.8753e-01,  7.9850e-01, -4.4507e-01,\n","         -5.6260e-03, -3.3181e-02, -5.8860e-01, -7.9499e-01,  4.4164e-01,\n","         -3.1938e-01, -3.7808e-02,  6.6738e-02,  1.9533e-02,  8.4942e-01,\n","          5.3235e-03,  9.4798e-02, -1.2333e-01,  8.5869e-02, -1.0280e-01,\n","         -1.2946e-01,  8.5376e-01,  1.8801e-01, -3.2741e-01, -9.6287e-01,\n","          6.1638e-01, -6.9420e-01,  4.4450e-01,  6.0681e-01, -6.6629e-01,\n","          5.0973e-02,  3.4253e-02, -1.8121e-01,  2.2566e-01, -1.4444e-02,\n","         -1.3434e-01,  4.3035e-02,  1.1194e-01,  9.0154e-01, -2.0848e-01,\n","         -8.8703e-01, -3.1255e-01,  6.9419e-02, -8.3545e-01, -2.6751e-01,\n","         -2.3816e-01,  2.7348e-03, -1.5042e-01,  4.7942e-01,  3.3011e-01,\n","         -1.6503e-01, -9.0385e-01, -6.1607e-02, -1.1797e-01,  9.0846e-01,\n","          2.6325e-02, -1.3698e-01, -6.5338e-01, -7.4803e-01, -4.6147e-01,\n","          8.1519e-01, -8.4302e-01,  9.1290e-01, -8.3432e-01,  3.5692e-03,\n","          7.8573e-01,  2.6059e-01, -7.7205e-01, -3.1328e-03, -6.6097e-02,\n","          5.1946e-02,  3.9750e-01,  1.4424e-01, -8.5038e-01, -1.8162e-02,\n","         -1.0716e-02,  1.1313e-01,  8.5686e-04,  3.9124e-01,  4.4546e-01,\n","          9.0402e-02, -1.6985e-01, -3.3805e-01,  6.1812e-02,  2.2982e-01,\n","          2.3385e-01, -1.2379e-01,  4.5419e-02,  5.1026e-02, -7.1860e-04,\n","         -6.6718e-01, -1.3307e-01,  7.8950e-02, -2.0892e-02,  3.0005e-01,\n","         -9.1189e-01, -6.5355e-01, -7.6801e-01, -9.3507e-02,  5.3021e-01,\n","          2.1915e-02, -4.8867e-01, -3.5073e-01,  8.0068e-01,  8.4983e-01,\n","          3.5458e-01,  2.0711e-02,  5.9287e-01, -3.4995e-01, -7.2958e-02,\n","          3.9693e-02,  7.5798e-02,  6.1057e-01,  4.2597e-01, -2.0743e-02,\n","          9.1923e-01, -5.0433e-03,  5.8217e-02, -6.0209e-01,  1.3403e-01,\n","         -7.2890e-02,  6.6255e-01, -4.6876e-01, -8.6120e-01,  1.0894e-02,\n","          1.8972e-02, -4.4184e-01,  2.5289e-02, -1.1211e-01, -3.0922e-01,\n","          6.5002e-01,  7.4250e-01,  5.5601e-01, -1.8821e-01,  1.3612e-01,\n","         -9.7374e-02, -4.0479e-02, -2.4442e-02, -7.8018e-01,  9.5698e-01,\n","          1.7359e-01,  4.7505e-01,  3.3328e-01,  2.2359e-01,  8.7758e-01,\n","          1.3941e-02,  3.2011e-01, -1.0929e-02,  7.9241e-01,  6.8530e-02,\n","         -7.1604e-01,  5.0206e-01, -9.1000e-01, -3.8872e-02, -7.6048e-01,\n","          1.7364e-01, -1.7590e-01,  5.9545e-01, -1.0509e-01,  8.5677e-01,\n","          8.0183e-01, -1.7133e-02,  4.1293e-01,  8.1418e-01,  1.5888e-01,\n","         -7.5477e-01, -9.5126e-01, -9.6628e-01, -7.2032e-02, -2.3228e-01,\n","          4.7854e-02,  1.7156e-01, -2.8391e-02,  1.4297e-01,  3.4419e-02,\n","         -8.3534e-01,  7.9761e-01,  1.2672e-01, -8.1043e-01,  8.8525e-01,\n","         -3.8777e-01,  6.0806e-02,  2.3121e-01, -9.4670e-01, -5.4725e-01,\n","         -1.0510e-01, -1.3351e-01,  3.5533e-01,  1.4217e-01,  5.4140e-01,\n","          1.9415e-02, -3.2170e-01, -6.5439e-02,  7.8295e-01, -5.2289e-01,\n","         -9.5798e-01,  2.8194e-01,  6.3611e-01, -5.6436e-01,  8.3533e-01,\n","         -6.4246e-01, -1.0839e-01,  7.5424e-01,  7.2921e-01,  5.5158e-01,\n","          4.3062e-01,  2.0447e-01,  1.1434e-01,  3.8707e-01,  6.9555e-01,\n","          7.4856e-01,  9.5958e-01,  6.6706e-01,  2.7684e-01,  7.0061e-01,\n","          2.4441e-02,  4.2779e-01, -8.4437e-01, -5.7102e-02, -4.4115e-01,\n","          2.1374e-01,  1.0470e-01, -4.6251e-02, -6.4018e-01,  4.0994e-01,\n","          7.6299e-02,  1.8739e-01, -8.4008e-02,  2.8767e-01, -2.4358e-01,\n","          1.1020e-02, -5.1402e-01,  4.9222e-02,  2.6653e-01, -5.8301e-02,\n","          7.9280e-01, -2.4956e-01, -7.8913e-03, -1.1233e-01,  5.1617e-02,\n","          7.6497e-01, -8.3232e-01,  5.1334e-01,  5.9828e-02,  8.3035e-01,\n","         -5.8532e-01, -2.4030e-01,  6.1904e-01, -3.5076e-01, -1.3420e-01,\n","         -8.9157e-02, -4.9536e-01,  4.9910e-01, -4.5500e-02, -1.6105e-01,\n","         -3.7617e-02,  3.7182e-01,  1.6940e-01, -1.1236e-01,  5.3460e-01,\n","          7.2991e-01,  1.8875e-01,  4.1905e-02,  1.7980e-01,  6.0190e-02,\n","         -7.9329e-01,  1.4009e-01,  6.1139e-01, -6.1764e-01,  3.4262e-01,\n","         -6.7680e-01,  4.8117e-01, -7.8062e-01,  4.0878e-02, -3.7002e-01,\n","         -6.8798e-01, -3.8813e-01,  1.6272e-01,  1.2418e-01,  7.1285e-01,\n","         -7.0520e-01,  6.1055e-01,  3.9583e-01,  7.1228e-01,  1.4088e-01,\n","          5.9301e-01, -3.6854e-01,  5.7186e-01]],\n","       grad_fn=<DifferentiableGraphBackward>))\n"]}]},{"cell_type":"code","source":["traced_model(tokens_tensor, segments_tensors)"],"metadata":{"id":"oBcqLPoO5QPj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 02、Other test example"],"metadata":{"id":"kOoN4SXR7DJF"}},{"cell_type":"code","source":["import os\n","import torch\n","\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\")\n","model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-mono\", torchscript=True)\n","\n","max_length = 128\n","PAD = \"<pad>\"\n","tokenizer.pad_token = PAD\n","\n","dummy_input =  \"def hello_world():\"\n","\n","# Creating a dummy input\n","inputs = tokenizer.encode_plus(dummy_input,max_length = int(max_length), pad_to_max_length = True, truncation=True, return_tensors = 'pt')\n","input_ids = inputs[\"input_ids\"]\n","traced_model = torch.jit.trace(model, [input_ids])\n","\n","# Creating the trace\n","torch.jit.save(traced_model, \"traced_codegen-350M-mono.pt\")"],"metadata":{"id":"GgKHwumq3o-W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662001572148,"user_tz":-480,"elapsed":30433,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"662ef270-cacc-4578-926f-942c018e066b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py:166: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n","  mask_value = torch.tensor(mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\n","/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py:167: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n","  attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n"]}]},{"cell_type":"code","source":["loaded_model = torch.jit.load(\"traced_codegen-350M-mono.pt\")\n","loaded_model.eval()\n","\n","all_encoder_layers, pooled_output = loaded_model(*dummy_input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"7XllsxWgA4pS","executionInfo":{"status":"error","timestamp":1662002131105,"user_tz":-480,"elapsed":337,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"b941b041-5765-4e5f-e61b-dfe33884aa3b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-c69daf596a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: forward() expected at most 2 argument(s) but received 19 argument(s). Declaration: forward(__torch__.transformers.models.codegen.modeling_codegen.CodeGenForCausalLM self, Tensor input_ids) -> ((Tensor, ((Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor), (Tensor, Tensor))))"]}]},{"cell_type":"markdown","source":["### 03、T5-small  "],"metadata":{"id":"Mif8VRIS98Iq"}},{"cell_type":"code","source":["!pip install sentencepiece==0.1.91"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"632uJl83_jch","executionInfo":{"status":"ok","timestamp":1661246510360,"user_tz":-480,"elapsed":7475,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"cb210fdf-d562-4b45-eaad-70f554836bac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (0.1.91)\n"]}]},{"cell_type":"code","source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import torch\n","\n","tokenizer = T5Tokenizer.from_pretrained('t5-small')\n","model = T5ForConditionalGeneration.from_pretrained('t5-small', torchscript = True)\n","input_ids = tokenizer('The <extra_id_0> walks in <extra_id_1> park', return_tensors='pt').input_ids\n","attention_mask = input_ids.ne(model.config.pad_token_id).long()\n","decoder_input_ids = tokenizer('<pad> <extra_id_0> cute dog <extra_id_1> the <extra_id_2>', return_tensors='pt').input_ids\n","\n","traced_model = torch.jit.trace(model, (input_ids, attention_mask, decoder_input_ids))\n","torch.jit.save(traced_model, \"traced_t5.pt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272,"referenced_widgets":["9de7aa3ac27947168abc621f4041cead","bc569aedb8da4e998f57b61b368047a8","6a0ec669d2af42f4977fc0d0fe869416","d366133341624ebc9cc87e23ba7215a0","6cdc1e68bcb649b0a548460ffc53732b","704cec778b1546d78a064009c9b52fa2","2ef73f362e1c4c03a9a4818c301c96b4","e3de55c06cd847f1b35fcba068362dab","39c74fd0985b4761a1a1aebcd87d5a31","696617406e114edfba513da75f0ba222","19cb2ae10650463d97c38be11a67bc81","99805e364c3b424f91dcc6ecf938337a","4d9fe9d3b9d54ff4989040d7e74a7f6b","b7c259c24a4a4f149a85161ef653d633","e9464a4069154e278f695c226e0157af","82bd4d696ef24e26a7c478edc959e6e8","b37bd38371cf48b7a1bebc9f98be7816","2f6f18940fb447e3917474dbc8e3ee16","1b27ff5cf02a49858fb4480a49bcbe9b","f50e504fb86849769a82cb890abbbed4","a622f2d90a3d407fbd6e5c6fa7f07087","1fcb15557cc3402faa9d429c0fc462d5","d779c9a26f8340f99d8f7bc31cf42f3b","8deb4d2a3d384571ba7a260a401cb472","bd16e7fd4d20412bafda53e6eeebfc13","e3333daef34843069c73898f996403c1","3607d8556d14495aa26c087cd8a64954","5eaa5b610043430b80288727d94180bc","6e183f012fde41099ae87e95c436a81e","1c90a7a8ad85449db4b3f237f677dcc5","6bda6c39b24941aca2fa9e303b3764be","4123d173acd7494092d055d7b5390221","5322beb59344415086d781e1d1de963f"]},"id":"74h_HrxR97Up","executionInfo":{"status":"ok","timestamp":1661246540630,"user_tz":-480,"elapsed":26847,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"8f5a1099-a031-477e-d531-2f6fbcca37f9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading spiece.model:   0%|          | 0.00/773k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9de7aa3ac27947168abc621f4041cead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99805e364c3b424f91dcc6ecf938337a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  FutureWarning,\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/231M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d779c9a26f8340f99d8f7bc31cf42f3b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:679: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if causal_mask.shape[1] < attention_mask.shape[1]:\n"]}]},{"cell_type":"code","source":["input_ids = tokenizer('The <extra_id_0> walks in <extra_id_1> park', return_tensors='pt').input_ids\n","attention_mask = input_ids.ne(model.config.pad_token_id).long()\n","decoder_input_ids = tokenizer('<pad> <extra_id_0> cute dog <extra_id_1> the <extra_id_2>', return_tensors='pt').input_ids\n","\n","dummy_input = [input_ids, attention_mask]"],"metadata":{"id":"i6EYVFpHCVnD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model = torch.jit.load(\"traced_t5.pt\")\n","loaded_model.eval()\n","\n","all_encoder_layers, pooled_output = loaded_model(*dummy_input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"cji2uMMGB5ZF","executionInfo":{"status":"error","timestamp":1661252348830,"user_tz":-480,"elapsed":446,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"d2fcf39c-a1b2-46de-deea-d49076b899a9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-448a74ab6ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: forward() is missing value for argument 'decoder_input_ids'. Declaration: forward(__torch__.transformers.models.t5.modeling_t5.T5ForConditionalGeneration self, Tensor input_ids, Tensor attention_mask, Tensor decoder_input_ids) -> ((Tensor, ((Tensor, Tensor, Tensor, Tensor), (Tensor, Tensor, Tensor, Tensor), (Tensor, Tensor, Tensor, Tensor), (Tensor, Tensor, Tensor, Tensor), (Tensor, Tensor, Tensor, Tensor), (Tensor, Tensor, Tensor, Tensor)), Tensor))"]}]},{"cell_type":"markdown","source":["## TorchServe + MNIST 测试案例"],"metadata":{"id":"w0UbZV-RpsfG"}},{"cell_type":"code","source":["!curl http://127.0.0.1:7000/predictions/mnist -T ./drive/MyDrive/NLP/TorchScript/mnist/mnist/test_data/4.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rh7lLTrhpymy","executionInfo":{"status":"ok","timestamp":1661489578467,"user_tz":-480,"elapsed":347,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"7c6a839f-586d-40cf-bf53-ebfc7cdda293"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4"]}]},{"cell_type":"code","source":["!curl -X POST http://127.0.0.1:7000/predictions/codegen -H 'Content-Type: application/json' -d '{\"data\":\"import matplot\"}'"],"metadata":{"id":"w5208jwgiL7v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662111220319,"user_tz":-480,"elapsed":1528,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"2b10ac39-7174-4cc3-a670-117ab3418944"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas"]}]},{"cell_type":"code","source":["inferences = []\n","outputs = 'import pandas as pd'\n","\n","inferences = inferences.append(outputs)\n","print(inferences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIDu4OnQrp8Q","executionInfo":{"status":"ok","timestamp":1662096756517,"user_tz":-480,"elapsed":360,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"3d85d5f9-61ad-49de-e5a6-6af94acfc4ab"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":["!curl -X POST http://127.0.0.1:7000/predictions/codegen-350M -H 'Content-Type: application/json' -d '{\"data\":\"print hello world function\"}'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGHXhPOWfeQ6","executionInfo":{"status":"ok","timestamp":1662109936211,"user_tz":-480,"elapsed":555,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"814c608d-87a9-4362-f644-af91296e3a9e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"code\": 404,\n","  \"type\": \"ModelNotFoundException\",\n","  \"message\": \"Model not found: codegen-350M\"\n","}\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCeKQIB9eKJT","executionInfo":{"status":"ok","timestamp":1662111300167,"user_tz":-480,"elapsed":564,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"be5e677f-dfbf-40ea-c4a8-7ef6fcefd58b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Sep  2 09:34:58 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P0    36W / 250W |   2233MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["dic1 = {\"main\": \"this is a main\", \"categories\": \"this is a categories\"}\n","count = 2\n","input_data = [dic1 for i in range(count)]"],"metadata":{"id":"bHM18tDzOGTQ","executionInfo":{"status":"ok","timestamp":1662082794850,"user_tz":-480,"elapsed":387,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["print(input_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxWYaK8c2s4e","executionInfo":{"status":"ok","timestamp":1662082807783,"user_tz":-480,"elapsed":6,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"91280fba-bd8c-467e-e0b6-fc44bb440a56"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'main': 'this is a main', 'categories': 'this is a categories'}, {'main': 'this is a main', 'categories': 'this is a categories'}]\n"]}]},{"cell_type":"code","source":["!curl -X POST http://127.0.0.1:7000/predictions/Textgeneration  -T  sample_text.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jdmQP8Qcx-b","executionInfo":{"status":"ok","timestamp":1662084764171,"user_tz":-480,"elapsed":132155,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"5580839f-be69-40ec-cdef-c1f9bb50309d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["curl: (56) Recv failure: Connection reset by peer\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HicBPkmSc3PW","executionInfo":{"status":"ok","timestamp":1662025698226,"user_tz":-480,"elapsed":437,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"078d4b9a-605a-4bbb-deb0-1c27be823214"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"markdown","source":["## Generative models T5"],"metadata":{"id":"fIhRONtCwY1R"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install SentencePiece "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A35IImcLwfMb","executionInfo":{"status":"ok","timestamp":1661930321005,"user_tz":-480,"elapsed":11118,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"b82599c7-e1ec-485e-ee15-6eb6c19957d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting SentencePiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 7.7 MB/s \n","\u001b[?25hInstalling collected packages: SentencePiece\n","Successfully installed SentencePiece-0.1.97\n"]}]},{"cell_type":"code","source":["text = \"\"\"At a very high level, one of the most critical steps in any ML pipeline is called AI serving, a task usually performed by an AI inference engine. The AI inference engine is responsible for the model deployment and performance monitoring steps in the figure above, and represents a whole new world that will eventually determine whether applications can use AI technologies to improve operational efficiencies and solve real business problems. \"\"\"\n","\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n","inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","outputs = model.generate(\n","    inputs, \n","    max_length=150, \n","    min_length=40, \n","    length_penalty=2.0, \n","    num_beams=4, \n","    early_stopping=True)\n","# just for debugging\n","print(outputs)\n","print(tokenizer.decode(outputs[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323,"referenced_widgets":["b9f5491d56464f28af2bff44cb5666eb","d5f943e44b594c4a8327b1269ea973ba","bb039c4b3b9b49f69f2ebe71767bfa0d","448cce89bc7e4756b5de1522b33a8f30","b28cdd47957448bcbaecbeadfe753e7d","33f33e73ffe34e5c83071ea469885975","77ca0c757fb34af4a9aac2ca7dab2886","99f2a7b9877a41d7ac562375351de113","2a63fccef94842b9a251af1d7f845fad","077db92dbd48461dace37afda033e21f","643a30ee26694d26bd86f58f16f922c7"]},"id":"oHfG47PrwbNp","executionInfo":{"status":"ok","timestamp":1661930713322,"user_tz":-480,"elapsed":23957,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"81d5f789-56be-437b-f85c-afa08d4260aa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading spiece.model:   0%|          | 0.00/773k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f5491d56464f28af2bff44cb5666eb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[    0,    80,    13,     8,   167,  2404,  2245,    16,   136,     3,\n","          6858, 12045,    19,   718,  7833,  3122,     3,     5,     8,  7833,\n","            16, 11788,  1948,    19,  1966,    21,     8,   825, 12001,    11,\n","           821,  4891,     3,     5,    34,    56,  2082,   823,  1564,    54,\n","           169,  7833,  2896,    12,  1172,  7763,     3, 27752,     3,     5,\n","             1]])\n","<pad> one of the most critical steps in any ML pipeline is called AI serving. the AI inference engine is responsible for the model deployment and performance monitoring. it will determine whether applications can use AI technologies to improve operational efficiencies.</s>\n"]}]},{"cell_type":"code","source":["# 无法进行有效的运行，生成输出\n","\n","class MyModel(T5ForConditionalGeneration):\n","    def __init__(self, kwargs):\n","        super(MyModel, self).__init__(kwargs)\n","\n","    def forward(self, params):\n","        self.generate(params)\n","\n","newmodel = MyModel.from_pretrained(\"t5-base\", torchscript=True)\n","output = newmodel(inputs)"],"metadata":{"id":"buxcKhuxyoHr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 可以进行有效的输出，并使用束搜索进行文本生成\n","\n","t_input = \"translate English to French: The universe is a dark forest.\"\n","\n","token = tokenizer(t_input, return_tensors=\"pt\")\n","\n","input_ids = token[\"input_ids\"]\n","attention_mask = token[\"attention_mask\"]\n","# 'set num_beams = 1' for greedy search\n","tokens = model.generate(input_ids=input_ids, attention_mask=attention_mask, num_beams=2)\n","output = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n","\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qcy71MKuz4L4","executionInfo":{"status":"ok","timestamp":1661931075094,"user_tz":-480,"elapsed":2128,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"45740839-a467-453a-ff78-f955ddc7fa43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["L'univers est une forêt sombre.\n"]}]},{"cell_type":"code","source":["from transformers import T5Tokenizer, T5Model\n","\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n","model = T5Model.from_pretrained(\"t5-base\")\n","\n","input_ids = tokenizer(\n","    \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",").input_ids  # Batch size 1\n","decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n","\n","# forward pass\n","outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n","last_hidden_states = outputs.last_hidden_state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"zO4tn2ibyIYo","executionInfo":{"status":"error","timestamp":1661930609352,"user_tz":-480,"elapsed":377,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"666990b5-7a3a-4f40-fcde-2a8c8ab5a34b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-37d81705241a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t5-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t5-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"]}]},{"cell_type":"markdown","source":["## Using TorchScript in Python"],"metadata":{"id":"7aKMT1qRy2eW"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RS_qZ1OzZGD","executionInfo":{"status":"ok","timestamp":1661998068534,"user_tz":-480,"elapsed":11484,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"68b18f92-4d0a-425b-9056-a0e4188356ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 48.7 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 27.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"]}]},{"cell_type":"code","source":["from transformers import BertModel, BertTokenizer, BertConfig\n","import torch\n","\n","enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Tokenizing input text\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = enc.tokenize(text)\n","\n","# Masking one of the input tokens\n","masked_index = 8\n","tokenized_text[masked_index] = \"[MASK]\"\n","indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n","segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n","\n","# Creating a dummy input\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])\n","dummy_input = [tokens_tensor, segments_tensors]\n","\n","# Initializing the model with the torchscript flag\n","# Flag set to True even though it is not necessary as this model does not have an LM Head.\n","config = BertConfig(\n","    vocab_size_or_config_json_file=32000,\n","    hidden_size=768,\n","    num_hidden_layers=12,\n","    num_attention_heads=12,\n","    intermediate_size=3072,\n","    torchscript=True,\n",")\n","\n","# Instantiating the model\n","model = BertModel(config)\n","\n","# The model needs to be in evaluation mode\n","model.eval()\n","\n","# If you are instantiating the model with *from_pretrained* you can also easily set the TorchScript flag\n","model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n","\n","# Creating the trace\n","traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n","torch.jit.save(traced_model, \"traced_bert.pt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLAXG3l-yuiE","executionInfo":{"status":"ok","timestamp":1662000068831,"user_tz":-480,"elapsed":14266,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"f93e1a2c-7e1b-485e-fa5e-bfb9607c5170"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["# Tokenizing input text\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = enc.tokenize(text)\n","\n","# Masking one of the input tokens\n","masked_index = 8\n","tokenized_text[masked_index] = \"[MASK]\"\n","indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n","segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n","\n","# Creating a dummy input\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])\n","dummy_input = [tokens_tensor, segments_tensors]\n","\n","loaded_model = torch.jit.load(\"traced_bert.pt\")\n","loaded_model.eval()\n","\n","all_encoder_layers, pooled_output = loaded_model(*dummy_input)"],"metadata":{"id":"XhreHwHT0ADv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_encoder_layers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVVLMz6N9zeW","executionInfo":{"status":"ok","timestamp":1662000847506,"user_tz":-480,"elapsed":496,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"28f9e22c-53d0-4440-f196-d7bd205990a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-2.5689e-01, -7.3599e-03, -8.9147e-02,  ..., -1.3546e-01,\n","           2.3597e-01,  2.4208e-01],\n","         [-5.8262e-01,  3.1923e-01, -2.8020e-01,  ...,  1.0413e-01,\n","           1.7953e-01, -4.7086e-01],\n","         [-3.0671e-01, -2.3213e-01, -1.5938e-01,  ...,  7.0993e-02,\n","           1.4761e-01,  2.7529e-01],\n","         ...,\n","         [ 2.0549e-01, -1.6317e-02, -7.1004e-05,  ..., -1.3032e-01,\n","           6.1008e-01,  4.2999e-01],\n","         [-4.9530e-01, -4.6195e-01, -2.9027e-01,  ...,  6.3559e-01,\n","           6.2100e-01,  1.0318e-01],\n","         [ 8.2051e-01,  1.8250e-01, -1.1302e-01,  ...,  1.5103e-01,\n","          -7.6513e-01, -1.9481e-02]]], grad_fn=<NativeLayerNormBackward0>)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["pooled_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XARNyy4P-G_W","executionInfo":{"status":"ok","timestamp":1662000874631,"user_tz":-480,"elapsed":326,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"ea03cd1c-2531-4273-b31a-5b4f396595ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-4.9859e-01, -1.6913e-01,  8.3044e-01,  7.2490e-02, -4.8807e-01,\n","         -9.1259e-02,  5.1964e-01,  1.2615e-01,  7.3988e-01, -9.9609e-01,\n","          3.7945e-01, -5.8106e-01,  9.5275e-01, -6.8154e-01,  7.0220e-01,\n","         -2.4374e-01,  9.2702e-02, -3.1205e-01,  2.3801e-01, -3.3289e-01,\n","          2.2093e-01, -3.1050e-01,  7.1334e-01,  6.8511e-02,  1.5540e-01,\n","         -7.6150e-01, -2.8993e-01,  7.5329e-01,  8.3334e-01,  5.7146e-01,\n","         -3.3142e-01,  1.4806e-01, -9.5029e-01, -9.6337e-02,  7.7407e-01,\n","         -9.3747e-01, -3.0847e-02, -4.7886e-01,  4.4816e-02,  1.1357e-02,\n","         -6.1463e-01,  2.0118e-01,  9.0852e-01, -6.6917e-01, -3.0572e-01,\n","         -2.4733e-01, -6.9975e-01,  9.1703e-02, -6.5932e-01, -8.4444e-01,\n","         -7.1574e-01, -8.7206e-01,  5.5364e-02,  1.0259e-01,  2.0758e-01,\n","          4.1869e-01, -2.2090e-01,  6.6650e-02,  3.9337e-02, -3.4385e-01,\n","         -4.0217e-01,  3.1609e-02,  6.8003e-01, -7.3265e-01, -7.0735e-01,\n","         -8.4914e-01, -3.4449e-02, -7.7896e-02,  1.1542e-01, -5.8604e-02,\n","          5.3955e-01,  7.7160e-02,  4.1768e-01, -4.7927e-01, -7.7228e-01,\n","          1.0024e-01, -1.9495e-01,  9.0035e-01,  2.1756e-01, -9.3141e-01,\n","         -6.6439e-01, -6.5286e-01,  1.0850e-01,  8.2425e-01, -8.0041e-01,\n","         -8.0010e-01,  1.9082e-01, -8.2846e-03, -9.5559e-01,  1.0529e-01,\n","          4.8709e-02, -2.7277e-02, -7.0070e-01,  1.2284e-01,  1.0367e-01,\n","          1.1624e-01, -3.6921e-02,  6.1928e-01,  3.4673e-02,  2.5419e-01,\n","         -1.0259e-01,  5.9038e-03,  2.2802e-01, -1.5938e-01, -9.4064e-02,\n","         -1.3483e-01,  9.1638e-02, -2.5277e-01, -4.0633e-01,  3.5905e-01,\n","          1.7583e-01, -5.4669e-02, -3.7656e-02, -8.2613e-01,  3.9060e-01,\n","         -7.5958e-02, -9.2011e-01, -1.5846e-01, -9.5379e-01,  4.7328e-01,\n","          2.2438e-01, -4.0782e-02,  8.4882e-01,  7.4372e-01,  6.8334e-02,\n","          1.2067e-01,  8.3558e-01, -9.3571e-01,  2.5638e-01,  2.7365e-01,\n","          5.1111e-01,  2.4959e-03, -9.1422e-01, -8.5609e-01,  2.6730e-01,\n","          8.2105e-01, -1.9208e-02,  9.0641e-01,  3.1729e-02,  8.1417e-01,\n","          5.3713e-01,  1.5256e-01, -6.5996e-01, -2.9205e-01, -2.6196e-01,\n","         -6.0163e-02, -1.6913e-01,  1.9751e-01,  4.2851e-01, -5.6606e-01,\n","          3.2405e-01, -1.4614e-01,  7.3622e-01, -7.3622e-01, -3.0769e-01,\n","          7.5544e-01,  5.2388e-01,  8.3670e-01,  7.7318e-01,  2.1111e-02,\n","         -1.0186e-01,  5.3786e-01, -1.1288e-01,  1.2010e-01,  2.8660e-01,\n","          1.5836e-01, -5.5910e-01,  1.3677e-01, -6.5858e-01,  4.6724e-01,\n","          1.8676e-01, -7.8814e-04,  8.0405e-01, -9.3026e-01, -6.9134e-02,\n","          2.2026e-01,  9.3376e-01,  4.8834e-01,  6.0626e-02, -5.2468e-01,\n","         -6.7205e-02, -2.8043e-01, -8.0448e-01,  9.1711e-01,  3.1231e-02,\n","          1.4967e-01,  5.4755e-01, -5.2422e-01, -6.1328e-01, -6.5674e-01,\n","          5.5004e-01,  3.5562e-01, -6.2681e-01,  1.7565e-01, -2.6099e-01,\n","         -1.2162e-01,  5.5805e-01,  1.7059e-01, -7.8489e-02, -2.6815e-01,\n","          1.2040e-01,  7.8531e-01,  6.7986e-01,  4.0405e-01, -7.0169e-01,\n","          1.0016e-01, -6.9205e-01,  3.5772e-02,  7.4413e-02,  1.4686e-01,\n","         -4.7862e-02,  9.5771e-01,  2.1660e-01,  6.9758e-04, -6.7157e-01,\n","         -9.2958e-01,  1.2179e-02, -6.3569e-01,  1.3246e-01, -3.6443e-01,\n","         -1.9593e-01,  6.1201e-01, -5.9816e-01,  7.9575e-02, -7.0562e-01,\n","         -5.6153e-01,  9.3639e-02, -1.2182e-01,  1.3971e-01, -5.4726e-02,\n","          3.1027e-01, -7.9235e-01, -2.9843e-01,  3.6523e-01,  7.2965e-01,\n","          8.2288e-01, -4.8346e-01,  3.6060e-01, -1.5700e-02,  6.6516e-01,\n","         -3.1768e-01,  8.6993e-01, -6.7448e-01, -7.0250e-02, -7.9002e-01,\n","          5.6488e-01, -6.6356e-01,  6.4933e-01, -4.8080e-03, -8.2526e-01,\n","         -6.7866e-01,  1.6267e-01,  5.3347e-02,  8.8357e-01, -7.1264e-02,\n","          8.2370e-01, -5.7167e-01, -8.5698e-01, -1.2295e-01,  2.3306e-01,\n","         -9.4883e-01, -6.4056e-01,  9.9413e-02, -6.6189e-01, -1.6533e-01,\n","          7.5128e-03, -8.3298e-01,  4.5723e-01,  8.1019e-02,  8.3341e-01,\n","          2.2406e-01, -5.3090e-01,  1.4762e-01, -7.6026e-01, -1.6274e-01,\n","          1.3930e-01,  8.2007e-01, -9.1361e-02, -8.5741e-01,  2.0810e-01,\n","          2.9116e-01,  1.5543e-01,  8.5719e-01,  8.7265e-01,  6.3798e-01,\n","          9.2237e-01,  7.0844e-01,  4.0798e-01,  3.7541e-01,  8.2557e-02,\n","          9.9737e-01,  6.1868e-01, -7.9913e-01, -8.2941e-01, -2.8434e-01,\n","          1.2858e-01, -9.2797e-01, -6.3592e-02,  4.6552e-02, -8.1194e-01,\n","         -7.1708e-01,  9.1365e-01,  7.2862e-01, -8.9509e-01,  7.3806e-01,\n","          7.2612e-01, -2.3452e-01, -6.6035e-01,  6.3779e-02,  9.3092e-01,\n","          1.6668e-02,  3.3495e-01, -1.8452e-02,  1.5112e-01,  4.9735e-01,\n","         -5.7902e-01,  6.5534e-01,  6.6720e-01, -6.5395e-01, -8.4177e-02,\n","         -1.6271e-01, -7.9912e-01, -3.1524e-01,  1.7052e-03, -3.4439e-01,\n","         -8.4678e-01, -2.0301e-02, -5.9327e-01,  1.5047e-01, -4.0945e-03,\n","          1.0240e-03, -5.2182e-01,  4.0745e-02, -8.2124e-01,  1.3655e-01,\n","          3.0421e-01, -7.6729e-01, -1.4364e-01,  3.7359e-01, -5.8641e-01,\n","          6.7145e-01, -8.4058e-01,  8.8928e-01, -4.8594e-02, -7.0527e-01,\n","          9.0982e-01, -1.3674e-01, -6.2551e-01, -1.2153e-01, -5.7317e-02,\n","          1.6933e-01,  8.5137e-01, -3.0268e-01, -9.2407e-01, -1.4311e-01,\n","         -2.2600e-01, -4.9942e-02,  7.3210e-02,  9.7865e-01,  3.2855e-02,\n","          6.2553e-01,  6.3310e-01,  9.3339e-01, -9.5555e-01, -6.6198e-01,\n","         -6.5063e-01, -8.4128e-01,  8.7723e-01,  7.9893e-01,  1.4459e-01,\n","         -1.9865e-01, -6.9513e-02,  6.3042e-01, -1.2870e-02, -7.2304e-01,\n","          2.7195e-01,  2.2727e-01, -2.9498e-02,  7.1309e-01, -4.8478e-01,\n","         -1.1718e-01,  2.0216e-01,  4.6508e-01,  4.6507e-01, -7.6713e-01,\n","          2.0409e-01, -5.9565e-03, -8.2280e-02, -8.4956e-02, -1.4858e-01,\n","         -8.5327e-01, -3.6672e-01,  8.7005e-01,  1.9555e-01, -6.6828e-01,\n","          1.5964e-01, -1.6004e-02, -3.9608e-01,  1.0805e-01,  9.5431e-02,\n","         -8.3893e-02, -5.9011e-01, -6.5418e-01, -5.9851e-01, -9.5626e-01,\n","          2.0579e-01,  2.3757e-02, -3.0543e-02,  5.7845e-01,  1.2862e-01,\n","         -8.2295e-03, -2.6664e-01, -6.8082e-01, -9.6271e-02,  6.9126e-02,\n","         -8.6602e-01,  8.7522e-01, -1.0679e-01,  1.2648e-01,  3.2427e-01,\n","          7.7688e-01, -9.3565e-02, -3.4144e-01, -4.7952e-02, -7.3323e-01,\n","          1.4223e-01, -8.2471e-01,  8.3261e-01, -8.1426e-01,  7.6197e-02,\n","         -5.7766e-02, -4.5483e-01,  9.0928e-01, -1.8027e-01,  2.0544e-01,\n","         -1.8068e-01,  4.2399e-01,  3.3363e-01, -2.0288e-01, -2.2413e-01,\n","          3.6761e-02,  8.0875e-01, -1.0996e-03,  3.5741e-02, -9.0296e-01,\n","         -7.9219e-01, -5.2211e-01, -6.7589e-01, -9.5255e-01,  7.0411e-01,\n","          2.6826e-01,  4.0882e-02,  5.4808e-01, -2.2253e-01, -2.8980e-01,\n","         -8.3246e-02,  1.0494e-01, -8.2818e-01,  7.8696e-01, -1.0552e-01,\n","          2.0068e-01, -1.1545e-01,  2.2196e-01, -8.5198e-01,  8.6098e-01,\n","          7.5903e-01,  2.5622e-01, -8.8536e-03, -4.7662e-01,  3.9720e-01,\n","         -3.4306e-01,  8.0380e-01, -7.8319e-02,  8.9613e-01, -1.4736e-01,\n","         -7.5046e-01,  3.7599e-01,  2.0120e-01,  6.4580e-02,  4.4332e-02,\n","         -8.3205e-01,  3.1302e-03,  7.8753e-01,  7.9850e-01, -4.4507e-01,\n","         -5.6260e-03, -3.3181e-02, -5.8860e-01, -7.9499e-01,  4.4164e-01,\n","         -3.1938e-01, -3.7808e-02,  6.6738e-02,  1.9533e-02,  8.4942e-01,\n","          5.3235e-03,  9.4798e-02, -1.2333e-01,  8.5869e-02, -1.0280e-01,\n","         -1.2946e-01,  8.5376e-01,  1.8801e-01, -3.2741e-01, -9.6287e-01,\n","          6.1638e-01, -6.9420e-01,  4.4450e-01,  6.0681e-01, -6.6629e-01,\n","          5.0973e-02,  3.4253e-02, -1.8121e-01,  2.2566e-01, -1.4444e-02,\n","         -1.3434e-01,  4.3035e-02,  1.1194e-01,  9.0154e-01, -2.0848e-01,\n","         -8.8703e-01, -3.1255e-01,  6.9419e-02, -8.3545e-01, -2.6751e-01,\n","         -2.3816e-01,  2.7348e-03, -1.5042e-01,  4.7942e-01,  3.3011e-01,\n","         -1.6503e-01, -9.0385e-01, -6.1607e-02, -1.1797e-01,  9.0846e-01,\n","          2.6325e-02, -1.3698e-01, -6.5338e-01, -7.4803e-01, -4.6147e-01,\n","          8.1519e-01, -8.4302e-01,  9.1290e-01, -8.3432e-01,  3.5692e-03,\n","          7.8573e-01,  2.6059e-01, -7.7205e-01, -3.1328e-03, -6.6097e-02,\n","          5.1946e-02,  3.9750e-01,  1.4424e-01, -8.5038e-01, -1.8162e-02,\n","         -1.0716e-02,  1.1313e-01,  8.5686e-04,  3.9124e-01,  4.4546e-01,\n","          9.0402e-02, -1.6985e-01, -3.3805e-01,  6.1812e-02,  2.2982e-01,\n","          2.3385e-01, -1.2379e-01,  4.5419e-02,  5.1026e-02, -7.1860e-04,\n","         -6.6718e-01, -1.3307e-01,  7.8950e-02, -2.0892e-02,  3.0005e-01,\n","         -9.1189e-01, -6.5355e-01, -7.6801e-01, -9.3507e-02,  5.3021e-01,\n","          2.1915e-02, -4.8867e-01, -3.5073e-01,  8.0068e-01,  8.4983e-01,\n","          3.5458e-01,  2.0711e-02,  5.9287e-01, -3.4995e-01, -7.2958e-02,\n","          3.9693e-02,  7.5798e-02,  6.1057e-01,  4.2597e-01, -2.0743e-02,\n","          9.1923e-01, -5.0433e-03,  5.8217e-02, -6.0209e-01,  1.3403e-01,\n","         -7.2890e-02,  6.6255e-01, -4.6876e-01, -8.6120e-01,  1.0894e-02,\n","          1.8972e-02, -4.4184e-01,  2.5289e-02, -1.1211e-01, -3.0922e-01,\n","          6.5002e-01,  7.4250e-01,  5.5601e-01, -1.8821e-01,  1.3612e-01,\n","         -9.7374e-02, -4.0479e-02, -2.4442e-02, -7.8018e-01,  9.5698e-01,\n","          1.7359e-01,  4.7505e-01,  3.3328e-01,  2.2359e-01,  8.7758e-01,\n","          1.3941e-02,  3.2011e-01, -1.0929e-02,  7.9241e-01,  6.8530e-02,\n","         -7.1604e-01,  5.0206e-01, -9.1000e-01, -3.8872e-02, -7.6048e-01,\n","          1.7364e-01, -1.7590e-01,  5.9545e-01, -1.0509e-01,  8.5677e-01,\n","          8.0183e-01, -1.7133e-02,  4.1293e-01,  8.1418e-01,  1.5888e-01,\n","         -7.5477e-01, -9.5126e-01, -9.6628e-01, -7.2032e-02, -2.3228e-01,\n","          4.7854e-02,  1.7156e-01, -2.8391e-02,  1.4297e-01,  3.4419e-02,\n","         -8.3534e-01,  7.9761e-01,  1.2672e-01, -8.1043e-01,  8.8525e-01,\n","         -3.8777e-01,  6.0806e-02,  2.3121e-01, -9.4670e-01, -5.4725e-01,\n","         -1.0510e-01, -1.3351e-01,  3.5533e-01,  1.4217e-01,  5.4140e-01,\n","          1.9415e-02, -3.2170e-01, -6.5439e-02,  7.8295e-01, -5.2289e-01,\n","         -9.5798e-01,  2.8194e-01,  6.3611e-01, -5.6436e-01,  8.3533e-01,\n","         -6.4246e-01, -1.0839e-01,  7.5424e-01,  7.2921e-01,  5.5158e-01,\n","          4.3062e-01,  2.0447e-01,  1.1434e-01,  3.8707e-01,  6.9555e-01,\n","          7.4856e-01,  9.5958e-01,  6.6706e-01,  2.7684e-01,  7.0061e-01,\n","          2.4441e-02,  4.2779e-01, -8.4437e-01, -5.7102e-02, -4.4115e-01,\n","          2.1374e-01,  1.0470e-01, -4.6251e-02, -6.4018e-01,  4.0994e-01,\n","          7.6299e-02,  1.8739e-01, -8.4008e-02,  2.8767e-01, -2.4358e-01,\n","          1.1020e-02, -5.1402e-01,  4.9222e-02,  2.6653e-01, -5.8301e-02,\n","          7.9280e-01, -2.4956e-01, -7.8913e-03, -1.1233e-01,  5.1617e-02,\n","          7.6497e-01, -8.3232e-01,  5.1334e-01,  5.9828e-02,  8.3035e-01,\n","         -5.8532e-01, -2.4030e-01,  6.1904e-01, -3.5076e-01, -1.3420e-01,\n","         -8.9157e-02, -4.9536e-01,  4.9910e-01, -4.5500e-02, -1.6105e-01,\n","         -3.7617e-02,  3.7182e-01,  1.6940e-01, -1.1236e-01,  5.3460e-01,\n","          7.2991e-01,  1.8875e-01,  4.1905e-02,  1.7980e-01,  6.0190e-02,\n","         -7.9329e-01,  1.4009e-01,  6.1139e-01, -6.1764e-01,  3.4262e-01,\n","         -6.7680e-01,  4.8117e-01, -7.8062e-01,  4.0878e-02, -3.7002e-01,\n","         -6.8798e-01, -3.8813e-01,  1.6272e-01,  1.2418e-01,  7.1285e-01,\n","         -7.0520e-01,  6.1055e-01,  3.9583e-01,  7.1228e-01,  1.4088e-01,\n","          5.9301e-01, -3.6854e-01,  5.7186e-01]], grad_fn=<TanhBackward0>)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n","input_ids = enc.encode(question, text)\n","\n","all_tokens = enc.convert_ids_to_tokens(input_ids)\n","answer = ' '.join(all_tokens[torch.argmax(all_encoder_layers) : torch.argmax(pooled_output)+1])\n","\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfvDCdl96uel","executionInfo":{"status":"ok","timestamp":1662000312716,"user_tz":-480,"elapsed":331,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"3e434024-ced1-4c38-c1be-7af500d5c023"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["traced_model(tokens_tensor, segments_tensors)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"609Kr2be0D_r","executionInfo":{"status":"ok","timestamp":1661998224647,"user_tz":-480,"elapsed":1623,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"68cde2b2-9e48-4f95-9629-6675f00d7ea7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[-2.5689e-01, -7.3599e-03, -8.9147e-02,  ..., -1.3546e-01,\n","            2.3597e-01,  2.4208e-01],\n","          [-5.8262e-01,  3.1923e-01, -2.8020e-01,  ...,  1.0413e-01,\n","            1.7953e-01, -4.7086e-01],\n","          [-3.0671e-01, -2.3213e-01, -1.5938e-01,  ...,  7.0993e-02,\n","            1.4761e-01,  2.7529e-01],\n","          ...,\n","          [ 2.0549e-01, -1.6317e-02, -7.1004e-05,  ..., -1.3032e-01,\n","            6.1008e-01,  4.2999e-01],\n","          [-4.9530e-01, -4.6195e-01, -2.9027e-01,  ...,  6.3559e-01,\n","            6.2100e-01,  1.0318e-01],\n","          [ 8.2051e-01,  1.8250e-01, -1.1302e-01,  ...,  1.5103e-01,\n","           -7.6513e-01, -1.9481e-02]]], grad_fn=<NativeLayerNormBackward0>),\n"," tensor([[-4.9859e-01, -1.6913e-01,  8.3044e-01,  7.2490e-02, -4.8807e-01,\n","          -9.1259e-02,  5.1964e-01,  1.2615e-01,  7.3988e-01, -9.9609e-01,\n","           3.7945e-01, -5.8106e-01,  9.5275e-01, -6.8154e-01,  7.0220e-01,\n","          -2.4374e-01,  9.2702e-02, -3.1205e-01,  2.3801e-01, -3.3289e-01,\n","           2.2093e-01, -3.1050e-01,  7.1334e-01,  6.8511e-02,  1.5540e-01,\n","          -7.6150e-01, -2.8993e-01,  7.5329e-01,  8.3334e-01,  5.7146e-01,\n","          -3.3142e-01,  1.4806e-01, -9.5029e-01, -9.6337e-02,  7.7407e-01,\n","          -9.3747e-01, -3.0847e-02, -4.7886e-01,  4.4816e-02,  1.1357e-02,\n","          -6.1463e-01,  2.0118e-01,  9.0852e-01, -6.6917e-01, -3.0572e-01,\n","          -2.4733e-01, -6.9975e-01,  9.1703e-02, -6.5932e-01, -8.4444e-01,\n","          -7.1574e-01, -8.7206e-01,  5.5364e-02,  1.0259e-01,  2.0758e-01,\n","           4.1869e-01, -2.2090e-01,  6.6650e-02,  3.9337e-02, -3.4385e-01,\n","          -4.0217e-01,  3.1609e-02,  6.8003e-01, -7.3265e-01, -7.0735e-01,\n","          -8.4914e-01, -3.4449e-02, -7.7896e-02,  1.1542e-01, -5.8604e-02,\n","           5.3955e-01,  7.7160e-02,  4.1768e-01, -4.7927e-01, -7.7228e-01,\n","           1.0024e-01, -1.9495e-01,  9.0035e-01,  2.1756e-01, -9.3141e-01,\n","          -6.6439e-01, -6.5286e-01,  1.0850e-01,  8.2425e-01, -8.0041e-01,\n","          -8.0010e-01,  1.9082e-01, -8.2846e-03, -9.5559e-01,  1.0529e-01,\n","           4.8709e-02, -2.7277e-02, -7.0070e-01,  1.2284e-01,  1.0367e-01,\n","           1.1624e-01, -3.6921e-02,  6.1928e-01,  3.4673e-02,  2.5419e-01,\n","          -1.0259e-01,  5.9038e-03,  2.2802e-01, -1.5938e-01, -9.4064e-02,\n","          -1.3483e-01,  9.1638e-02, -2.5277e-01, -4.0633e-01,  3.5905e-01,\n","           1.7583e-01, -5.4669e-02, -3.7656e-02, -8.2613e-01,  3.9060e-01,\n","          -7.5958e-02, -9.2011e-01, -1.5846e-01, -9.5379e-01,  4.7328e-01,\n","           2.2438e-01, -4.0782e-02,  8.4882e-01,  7.4372e-01,  6.8334e-02,\n","           1.2067e-01,  8.3558e-01, -9.3571e-01,  2.5638e-01,  2.7365e-01,\n","           5.1111e-01,  2.4959e-03, -9.1422e-01, -8.5609e-01,  2.6730e-01,\n","           8.2105e-01, -1.9208e-02,  9.0641e-01,  3.1729e-02,  8.1417e-01,\n","           5.3713e-01,  1.5256e-01, -6.5996e-01, -2.9205e-01, -2.6196e-01,\n","          -6.0163e-02, -1.6913e-01,  1.9751e-01,  4.2851e-01, -5.6606e-01,\n","           3.2405e-01, -1.4614e-01,  7.3622e-01, -7.3622e-01, -3.0769e-01,\n","           7.5544e-01,  5.2388e-01,  8.3670e-01,  7.7318e-01,  2.1111e-02,\n","          -1.0186e-01,  5.3786e-01, -1.1288e-01,  1.2010e-01,  2.8660e-01,\n","           1.5836e-01, -5.5910e-01,  1.3677e-01, -6.5858e-01,  4.6724e-01,\n","           1.8676e-01, -7.8814e-04,  8.0405e-01, -9.3026e-01, -6.9134e-02,\n","           2.2026e-01,  9.3376e-01,  4.8834e-01,  6.0626e-02, -5.2468e-01,\n","          -6.7205e-02, -2.8043e-01, -8.0448e-01,  9.1711e-01,  3.1231e-02,\n","           1.4967e-01,  5.4755e-01, -5.2422e-01, -6.1328e-01, -6.5674e-01,\n","           5.5004e-01,  3.5562e-01, -6.2681e-01,  1.7565e-01, -2.6099e-01,\n","          -1.2162e-01,  5.5805e-01,  1.7059e-01, -7.8489e-02, -2.6815e-01,\n","           1.2040e-01,  7.8531e-01,  6.7986e-01,  4.0405e-01, -7.0169e-01,\n","           1.0016e-01, -6.9205e-01,  3.5772e-02,  7.4413e-02,  1.4686e-01,\n","          -4.7862e-02,  9.5771e-01,  2.1660e-01,  6.9758e-04, -6.7157e-01,\n","          -9.2958e-01,  1.2179e-02, -6.3569e-01,  1.3246e-01, -3.6443e-01,\n","          -1.9593e-01,  6.1201e-01, -5.9816e-01,  7.9575e-02, -7.0562e-01,\n","          -5.6153e-01,  9.3639e-02, -1.2182e-01,  1.3971e-01, -5.4726e-02,\n","           3.1027e-01, -7.9235e-01, -2.9843e-01,  3.6523e-01,  7.2965e-01,\n","           8.2288e-01, -4.8346e-01,  3.6060e-01, -1.5700e-02,  6.6516e-01,\n","          -3.1768e-01,  8.6993e-01, -6.7448e-01, -7.0250e-02, -7.9002e-01,\n","           5.6488e-01, -6.6356e-01,  6.4933e-01, -4.8080e-03, -8.2526e-01,\n","          -6.7866e-01,  1.6267e-01,  5.3347e-02,  8.8357e-01, -7.1264e-02,\n","           8.2370e-01, -5.7167e-01, -8.5698e-01, -1.2295e-01,  2.3306e-01,\n","          -9.4883e-01, -6.4056e-01,  9.9413e-02, -6.6189e-01, -1.6533e-01,\n","           7.5128e-03, -8.3298e-01,  4.5723e-01,  8.1019e-02,  8.3341e-01,\n","           2.2406e-01, -5.3090e-01,  1.4762e-01, -7.6026e-01, -1.6274e-01,\n","           1.3930e-01,  8.2007e-01, -9.1361e-02, -8.5741e-01,  2.0810e-01,\n","           2.9116e-01,  1.5543e-01,  8.5719e-01,  8.7265e-01,  6.3798e-01,\n","           9.2237e-01,  7.0844e-01,  4.0798e-01,  3.7541e-01,  8.2557e-02,\n","           9.9737e-01,  6.1868e-01, -7.9913e-01, -8.2941e-01, -2.8434e-01,\n","           1.2858e-01, -9.2797e-01, -6.3592e-02,  4.6552e-02, -8.1194e-01,\n","          -7.1708e-01,  9.1365e-01,  7.2862e-01, -8.9509e-01,  7.3806e-01,\n","           7.2612e-01, -2.3452e-01, -6.6035e-01,  6.3779e-02,  9.3092e-01,\n","           1.6668e-02,  3.3495e-01, -1.8452e-02,  1.5112e-01,  4.9735e-01,\n","          -5.7902e-01,  6.5534e-01,  6.6720e-01, -6.5395e-01, -8.4177e-02,\n","          -1.6271e-01, -7.9912e-01, -3.1524e-01,  1.7052e-03, -3.4439e-01,\n","          -8.4678e-01, -2.0301e-02, -5.9327e-01,  1.5047e-01, -4.0945e-03,\n","           1.0240e-03, -5.2182e-01,  4.0745e-02, -8.2124e-01,  1.3655e-01,\n","           3.0421e-01, -7.6729e-01, -1.4364e-01,  3.7359e-01, -5.8641e-01,\n","           6.7145e-01, -8.4058e-01,  8.8928e-01, -4.8594e-02, -7.0527e-01,\n","           9.0982e-01, -1.3674e-01, -6.2551e-01, -1.2153e-01, -5.7317e-02,\n","           1.6933e-01,  8.5137e-01, -3.0268e-01, -9.2407e-01, -1.4311e-01,\n","          -2.2600e-01, -4.9942e-02,  7.3210e-02,  9.7865e-01,  3.2855e-02,\n","           6.2553e-01,  6.3310e-01,  9.3339e-01, -9.5555e-01, -6.6198e-01,\n","          -6.5063e-01, -8.4128e-01,  8.7723e-01,  7.9893e-01,  1.4459e-01,\n","          -1.9865e-01, -6.9513e-02,  6.3042e-01, -1.2870e-02, -7.2304e-01,\n","           2.7195e-01,  2.2727e-01, -2.9498e-02,  7.1309e-01, -4.8478e-01,\n","          -1.1718e-01,  2.0216e-01,  4.6508e-01,  4.6507e-01, -7.6713e-01,\n","           2.0409e-01, -5.9565e-03, -8.2280e-02, -8.4956e-02, -1.4858e-01,\n","          -8.5327e-01, -3.6672e-01,  8.7005e-01,  1.9555e-01, -6.6828e-01,\n","           1.5964e-01, -1.6004e-02, -3.9608e-01,  1.0805e-01,  9.5431e-02,\n","          -8.3893e-02, -5.9011e-01, -6.5418e-01, -5.9851e-01, -9.5626e-01,\n","           2.0579e-01,  2.3757e-02, -3.0543e-02,  5.7845e-01,  1.2862e-01,\n","          -8.2295e-03, -2.6664e-01, -6.8082e-01, -9.6271e-02,  6.9126e-02,\n","          -8.6602e-01,  8.7522e-01, -1.0679e-01,  1.2648e-01,  3.2427e-01,\n","           7.7688e-01, -9.3565e-02, -3.4144e-01, -4.7952e-02, -7.3323e-01,\n","           1.4223e-01, -8.2471e-01,  8.3261e-01, -8.1426e-01,  7.6197e-02,\n","          -5.7766e-02, -4.5483e-01,  9.0928e-01, -1.8027e-01,  2.0544e-01,\n","          -1.8068e-01,  4.2399e-01,  3.3363e-01, -2.0288e-01, -2.2413e-01,\n","           3.6761e-02,  8.0875e-01, -1.0996e-03,  3.5741e-02, -9.0296e-01,\n","          -7.9219e-01, -5.2211e-01, -6.7589e-01, -9.5255e-01,  7.0411e-01,\n","           2.6826e-01,  4.0882e-02,  5.4808e-01, -2.2253e-01, -2.8980e-01,\n","          -8.3246e-02,  1.0494e-01, -8.2818e-01,  7.8696e-01, -1.0552e-01,\n","           2.0068e-01, -1.1545e-01,  2.2196e-01, -8.5198e-01,  8.6098e-01,\n","           7.5903e-01,  2.5622e-01, -8.8536e-03, -4.7662e-01,  3.9720e-01,\n","          -3.4306e-01,  8.0380e-01, -7.8319e-02,  8.9613e-01, -1.4736e-01,\n","          -7.5046e-01,  3.7599e-01,  2.0120e-01,  6.4580e-02,  4.4332e-02,\n","          -8.3205e-01,  3.1302e-03,  7.8753e-01,  7.9850e-01, -4.4507e-01,\n","          -5.6260e-03, -3.3181e-02, -5.8860e-01, -7.9499e-01,  4.4164e-01,\n","          -3.1938e-01, -3.7808e-02,  6.6738e-02,  1.9533e-02,  8.4942e-01,\n","           5.3235e-03,  9.4798e-02, -1.2333e-01,  8.5869e-02, -1.0280e-01,\n","          -1.2946e-01,  8.5376e-01,  1.8801e-01, -3.2741e-01, -9.6287e-01,\n","           6.1638e-01, -6.9420e-01,  4.4450e-01,  6.0681e-01, -6.6629e-01,\n","           5.0973e-02,  3.4253e-02, -1.8121e-01,  2.2566e-01, -1.4444e-02,\n","          -1.3434e-01,  4.3035e-02,  1.1194e-01,  9.0154e-01, -2.0848e-01,\n","          -8.8703e-01, -3.1255e-01,  6.9419e-02, -8.3545e-01, -2.6751e-01,\n","          -2.3816e-01,  2.7348e-03, -1.5042e-01,  4.7942e-01,  3.3011e-01,\n","          -1.6503e-01, -9.0385e-01, -6.1607e-02, -1.1797e-01,  9.0846e-01,\n","           2.6325e-02, -1.3698e-01, -6.5338e-01, -7.4803e-01, -4.6147e-01,\n","           8.1519e-01, -8.4302e-01,  9.1290e-01, -8.3432e-01,  3.5692e-03,\n","           7.8573e-01,  2.6059e-01, -7.7205e-01, -3.1328e-03, -6.6097e-02,\n","           5.1946e-02,  3.9750e-01,  1.4424e-01, -8.5038e-01, -1.8162e-02,\n","          -1.0716e-02,  1.1313e-01,  8.5686e-04,  3.9124e-01,  4.4546e-01,\n","           9.0402e-02, -1.6985e-01, -3.3805e-01,  6.1812e-02,  2.2982e-01,\n","           2.3385e-01, -1.2379e-01,  4.5419e-02,  5.1026e-02, -7.1860e-04,\n","          -6.6718e-01, -1.3307e-01,  7.8950e-02, -2.0892e-02,  3.0005e-01,\n","          -9.1189e-01, -6.5355e-01, -7.6801e-01, -9.3507e-02,  5.3021e-01,\n","           2.1915e-02, -4.8867e-01, -3.5073e-01,  8.0068e-01,  8.4983e-01,\n","           3.5458e-01,  2.0711e-02,  5.9287e-01, -3.4995e-01, -7.2958e-02,\n","           3.9693e-02,  7.5798e-02,  6.1057e-01,  4.2597e-01, -2.0743e-02,\n","           9.1923e-01, -5.0433e-03,  5.8217e-02, -6.0209e-01,  1.3403e-01,\n","          -7.2890e-02,  6.6255e-01, -4.6876e-01, -8.6120e-01,  1.0894e-02,\n","           1.8972e-02, -4.4184e-01,  2.5289e-02, -1.1211e-01, -3.0922e-01,\n","           6.5002e-01,  7.4250e-01,  5.5601e-01, -1.8821e-01,  1.3612e-01,\n","          -9.7374e-02, -4.0479e-02, -2.4442e-02, -7.8018e-01,  9.5698e-01,\n","           1.7359e-01,  4.7505e-01,  3.3328e-01,  2.2359e-01,  8.7758e-01,\n","           1.3941e-02,  3.2011e-01, -1.0929e-02,  7.9241e-01,  6.8530e-02,\n","          -7.1604e-01,  5.0206e-01, -9.1000e-01, -3.8872e-02, -7.6048e-01,\n","           1.7364e-01, -1.7590e-01,  5.9545e-01, -1.0509e-01,  8.5677e-01,\n","           8.0183e-01, -1.7133e-02,  4.1293e-01,  8.1418e-01,  1.5888e-01,\n","          -7.5477e-01, -9.5126e-01, -9.6628e-01, -7.2032e-02, -2.3228e-01,\n","           4.7854e-02,  1.7156e-01, -2.8391e-02,  1.4297e-01,  3.4419e-02,\n","          -8.3534e-01,  7.9761e-01,  1.2672e-01, -8.1043e-01,  8.8525e-01,\n","          -3.8777e-01,  6.0806e-02,  2.3121e-01, -9.4670e-01, -5.4725e-01,\n","          -1.0510e-01, -1.3351e-01,  3.5533e-01,  1.4217e-01,  5.4140e-01,\n","           1.9415e-02, -3.2170e-01, -6.5439e-02,  7.8295e-01, -5.2289e-01,\n","          -9.5798e-01,  2.8194e-01,  6.3611e-01, -5.6436e-01,  8.3533e-01,\n","          -6.4246e-01, -1.0839e-01,  7.5424e-01,  7.2921e-01,  5.5158e-01,\n","           4.3062e-01,  2.0447e-01,  1.1434e-01,  3.8707e-01,  6.9555e-01,\n","           7.4856e-01,  9.5958e-01,  6.6706e-01,  2.7684e-01,  7.0061e-01,\n","           2.4441e-02,  4.2779e-01, -8.4437e-01, -5.7102e-02, -4.4115e-01,\n","           2.1374e-01,  1.0470e-01, -4.6251e-02, -6.4018e-01,  4.0994e-01,\n","           7.6299e-02,  1.8739e-01, -8.4008e-02,  2.8767e-01, -2.4358e-01,\n","           1.1020e-02, -5.1402e-01,  4.9222e-02,  2.6653e-01, -5.8301e-02,\n","           7.9280e-01, -2.4956e-01, -7.8913e-03, -1.1233e-01,  5.1617e-02,\n","           7.6497e-01, -8.3232e-01,  5.1334e-01,  5.9828e-02,  8.3035e-01,\n","          -5.8532e-01, -2.4030e-01,  6.1904e-01, -3.5076e-01, -1.3420e-01,\n","          -8.9157e-02, -4.9536e-01,  4.9910e-01, -4.5500e-02, -1.6105e-01,\n","          -3.7617e-02,  3.7182e-01,  1.6940e-01, -1.1236e-01,  5.3460e-01,\n","           7.2991e-01,  1.8875e-01,  4.1905e-02,  1.7980e-01,  6.0190e-02,\n","          -7.9329e-01,  1.4009e-01,  6.1139e-01, -6.1764e-01,  3.4262e-01,\n","          -6.7680e-01,  4.8117e-01, -7.8062e-01,  4.0878e-02, -3.7002e-01,\n","          -6.8798e-01, -3.8813e-01,  1.6272e-01,  1.2418e-01,  7.1285e-01,\n","          -7.0520e-01,  6.1055e-01,  3.9583e-01,  7.1228e-01,  1.4088e-01,\n","           5.9301e-01, -3.6854e-01,  5.7186e-01]], grad_fn=<TanhBackward0>))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["torch.jit.trace(model, [tokens_tensor, segments_tensors])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ml-ciVN00ZeN","executionInfo":{"status":"ok","timestamp":1661998313419,"user_tz":-480,"elapsed":2460,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"13a77fee-a884-4367-ca8b-16a158bf2e5a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  original_name=BertModel\n","  (embeddings): BertEmbeddings(\n","    original_name=BertEmbeddings\n","    (word_embeddings): Embedding(original_name=Embedding)\n","    (position_embeddings): Embedding(original_name=Embedding)\n","    (token_type_embeddings): Embedding(original_name=Embedding)\n","    (LayerNorm): LayerNorm(original_name=LayerNorm)\n","    (dropout): Dropout(original_name=Dropout)\n","  )\n","  (encoder): BertEncoder(\n","    original_name=BertEncoder\n","    (layer): ModuleList(\n","      original_name=ModuleList\n","      (0): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (1): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (2): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (3): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (4): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (5): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (6): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (7): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (8): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (9): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (10): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","      (11): BertLayer(\n","        original_name=BertLayer\n","        (attention): BertAttention(\n","          original_name=BertAttention\n","          (self): BertSelfAttention(\n","            original_name=BertSelfAttention\n","            (query): Linear(original_name=Linear)\n","            (key): Linear(original_name=Linear)\n","            (value): Linear(original_name=Linear)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","          (output): BertSelfOutput(\n","            original_name=BertSelfOutput\n","            (dense): Linear(original_name=Linear)\n","            (LayerNorm): LayerNorm(original_name=LayerNorm)\n","            (dropout): Dropout(original_name=Dropout)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          original_name=BertIntermediate\n","          (dense): Linear(original_name=Linear)\n","          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n","        )\n","        (output): BertOutput(\n","          original_name=BertOutput\n","          (dense): Linear(original_name=Linear)\n","          (LayerNorm): LayerNorm(original_name=LayerNorm)\n","          (dropout): Dropout(original_name=Dropout)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    original_name=BertPooler\n","    (dense): Linear(original_name=Linear)\n","    (activation): Tanh(original_name=Tanh)\n","  )\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## 其他测试案例"],"metadata":{"id":"r9MeZEyT3vr4"}},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForQuestionAnswering\n","import torch\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', torchscript=True)\n","\n","question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n","input_ids = tokenizer.encode(question, text)\n","token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]\n","\n","input_tensor = torch.tensor([input_ids])\n","token_type_ids_tensor = torch.tensor([token_type_ids])\n","\n","# The way I traced the model could be wrong here\n","traced_model = torch.jit.trace(model, (input_tensor, token_type_ids_tensor))\n","traced_model.eval()\n","start_scores, end_scores = traced_model(input_tensor, token_type_ids_tensor)\n","\n","all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n","\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154,"referenced_widgets":["54d1452a528f438c953ac52142a3a197","647d05e42d634b599fb7657f6e31dd21","bdfaf407d58149cfb267e47aace49f58","863902e74fb14ea8a396de12063cb7e9","108409ac1436427592f11c6642eab7db","78654f33f9ad46b1a62415e768d05504","87ff2c38cfb944f38e1c6f2ba0ce59de","b0f4f9e865fe4863b9a066ac79f14ef5","7995640a3f2049b4858c92999d7f29a2","43a331fb85974ab48d748abc5a067c9d","781478346a7541458cb4e675f2b82941","765c2ba6377642d5876d2d9eee2892bb","9a0762ee215f413f9f23d8b55c0f18cf","d0ebaeece8f64105989b4d320d1b4427","abce69ffdc584d0c9342fdbef1e7e9da","bdcb2be2ad1f4d9a8cde41184e19c4c2","b603e53908964cc88a4cd73755cd62f9","1f12cd450b344d33be7b748c614ea7ea","986efd87631f4ffc89be6257c35ac37b","c0422aff32d9402ca430d0f383066650","3212dc2a580f49c185dd0656f6ce064a","b8386e367a8c4541949cccc8c5d2709a"]},"id":"Kl2SoqEF3vKA","executionInfo":{"status":"ok","timestamp":1661999271088,"user_tz":-480,"elapsed":61814,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"049899a3-e460-4920-ba11-ebf746b0e81e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54d1452a528f438c953ac52142a3a197"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"765c2ba6377642d5876d2d9eee2892bb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["jim henson was a nice puppet [SEP]\n"]}]},{"cell_type":"markdown","source":["## Torchserve  ONNX"],"metadata":{"id":"bPXMFEhTl-Z6"}},{"cell_type":"code","source":["!pip install transformers[onnx]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWntZHbxmLvW","executionInfo":{"status":"ok","timestamp":1662012124794,"user_tz":-480,"elapsed":19101,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"bba42cdd-b9dc-43bd-9199-ecce07e4e3d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers[onnx]\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[onnx]) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[onnx]) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 83.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[onnx]) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[onnx]) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[onnx]) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[onnx]) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[onnx]) (4.12.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 60.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[onnx]) (2.23.0)\n","Collecting onnxconverter-common\n","  Downloading onnxconverter_common-1.12.2-py2.py3-none-any.whl (83 kB)\n","\u001b[K     |████████████████████████████████| 83 kB 2.1 MB/s \n","\u001b[?25hCollecting onnxruntime-tools>=1.4.2\n","  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 91.0 MB/s \n","\u001b[?25hCollecting tf2onnx\n","  Downloading tf2onnx-1.12.0-py3-none-any.whl (442 kB)\n","\u001b[K     |████████████████████████████████| 442 kB 86.6 MB/s \n","\u001b[?25hCollecting onnxruntime>=1.4.0\n","  Downloading onnxruntime-1.12.1-cp37-cp37m-manylinux_2_27_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 74.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[onnx]) (4.1.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.4.0->transformers[onnx]) (2.0.7)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.4.0->transformers[onnx]) (1.7.1)\n","Collecting coloredlogs\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 3.3 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.4.0->transformers[onnx]) (3.17.3)\n","Collecting py3nvml\n","  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (5.4.8)\n","Collecting onnx\n","  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[K     |████████████████████████████████| 13.1 MB 25.9 MB/s \n","\u001b[?25hCollecting py-cpuinfo\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 10.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[onnx]) (3.0.9)\n","Collecting humanfriendly>=9.1\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.8 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[onnx]) (3.8.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime>=1.4.0->transformers[onnx]) (1.15.0)\n","Collecting xmltodict\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[onnx]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[onnx]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[onnx]) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[onnx]) (2.10)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime>=1.4.0->transformers[onnx]) (1.2.1)\n","Collecting flatbuffers\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Building wheels for collected packages: py-cpuinfo\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=ed29ca27167ef201bff70ef8564c56a5fb4bc3a6317ce27ebcd303fba446d884\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","Successfully built py-cpuinfo\n","Installing collected packages: xmltodict, humanfriendly, tokenizers, py3nvml, py-cpuinfo, onnx, huggingface-hub, flatbuffers, coloredlogs, transformers, tf2onnx, onnxruntime-tools, onnxruntime, onnxconverter-common\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0.7\n","    Uninstalling flatbuffers-2.0.7:\n","      Successfully uninstalled flatbuffers-2.0.7\n","Successfully installed coloredlogs-15.0.1 flatbuffers-1.12 huggingface-hub-0.9.1 humanfriendly-10.0 onnx-1.12.0 onnxconverter-common-1.12.2 onnxruntime-1.12.1 onnxruntime-tools-1.7.0 py-cpuinfo-8.0.0 py3nvml-0.2.7 tf2onnx-1.12.0 tokenizers-0.12.1 transformers-4.21.2 xmltodict-0.13.0\n"]}]},{"cell_type":"code","source":["!python -m transformers.onnx --model=Salesforce/codegen-350M-mono onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQEvbMrVnLJ5","executionInfo":{"status":"ok","timestamp":1662012332490,"user_tz":-480,"elapsed":200443,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"e55b1d1e-faf9-41b0-f29c-4e8ed0b107c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading tokenizer_config.json: 100% 239/239 [00:00<00:00, 210kB/s]\n","Downloading config.json: 100% 995/995 [00:00<00:00, 848kB/s]\n","Downloading vocab.json: 100% 779k/779k [00:00<00:00, 864kB/s]\n","Downloading merges.txt: 100% 446k/446k [00:00<00:00, 498kB/s]\n","Downloading tokenizer.json: 100% 2.02M/2.02M [00:01<00:00, 1.64MB/s]\n","Downloading added_tokens.json: 100% 0.98k/0.98k [00:00<00:00, 869kB/s]\n","Downloading special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 81.1kB/s]\n","Downloading pytorch_model.bin: 100% 760M/760M [00:41<00:00, 19.1MB/s]\n","Some weights of the model checkpoint at Salesforce/codegen-350M-mono were not used when initializing CodeGenModel: ['lm_head.weight', 'lm_head.bias']\n","- This IS expected if you are initializing CodeGenModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CodeGenModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Using framework PyTorch: 1.12.1+cu113\n","Overriding 1 configuration item(s)\n","\t- use_cache -> False\n","/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py:509: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if batch_size <= 0:\n","/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py:166: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n","  mask_value = torch.tensor(mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\n","/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py:167: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n","  attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n","tcmalloc: large alloc 1221820416 bytes == 0xa8a8e000 @  0x7fbfb7df5887 0x7fbfb66ebc29 0x7fbfb66ecafb 0x7fbfb66ecbb4 0x7fbfb66ecf9c 0x7fbf6bdd5154 0x7fbf6bdd5685 0x7fbf5b71b0ed 0x7fbf808696c4 0x7fbf803ccf61 0x593784 0x594731 0x548cc1 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x549576\n","tcmalloc: large alloc 1221820416 bytes == 0xf17c6000 @  0x7fbfb7df31e7 0x4a3940 0x5b438c 0x7fbf808696fb 0x7fbf803ccf61 0x593784 0x594731 0x548cc1 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7 0x5118f8 0x549576\n","Validating ONNX model...\n","\t-[✓] ONNX model output names match reference model ({'last_hidden_state'})\n","\t- Validating ONNX Model output \"last_hidden_state\":\n","\t\t-[✓] (2, 8, 1024) matches (2, 8, 1024)\n","\t\t-[✓] all values close (atol: 1e-05)\n","All good, model saved at: onnx/model.onnx\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqWXUeD7rDi2","executionInfo":{"status":"ok","timestamp":1662012651734,"user_tz":-480,"elapsed":2824,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"21681356-35e4-412d-af87-b1b19a0b5187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","from onnxruntime import InferenceSession\n","\n","tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-350M-mono')\n","session = InferenceSession(\"onnx/model.onnx\")\n","\n","inputs = tokenizer(\"def hello_world(): \", return_tensors='np')\n","outputs = session.run(output_names=[\"last_hidden_state\"], input_feed=dict(inputs))"],"metadata":{"id":"A5p5hZNoqHhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M30Pke9QrL-K","executionInfo":{"status":"ok","timestamp":1662012676823,"user_tz":-480,"elapsed":817,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"697323fd-b584-4280-ac1f-fc0a520a5277"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[[-0.04647821, -0.47843856, -0.14148879, ...,  2.0196798 ,\n","           8.413227  ,  0.64264494],\n","         [-1.9656425 ,  0.434402  ,  1.315953  , ..., -1.6776477 ,\n","           1.4410083 , -0.25056827],\n","         [-2.9962916 ,  0.72312593,  2.411325  , ..., -2.591769  ,\n","          -2.3318453 , -2.0183125 ],\n","         [-4.301694  ,  2.9909708 , -2.0072517 , ..., -2.4425151 ,\n","           0.22334492, -2.0477571 ],\n","         [ 2.0143027 ,  0.76100916,  0.02836862, ...,  3.8227057 ,\n","           1.1650985 , -4.368134  ],\n","         [-0.18233556, -5.520864  ,  0.6300617 , ..., -3.2548928 ,\n","           3.958061  , -3.568727  ]]], dtype=float32)]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["print(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOsi4zTlxN8y","executionInfo":{"status":"ok","timestamp":1662014263760,"user_tz":-480,"elapsed":6,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"046c5bab-ba8b-42f8-b336-e9c69b09f42f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': array([[ 4299, 23748,    62,  6894, 33529,   220]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1]])}\n"]}]},{"cell_type":"code","source":["tokenizer.decode()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"dY6FTkbPwuMu","executionInfo":{"status":"error","timestamp":1662014196377,"user_tz":-480,"elapsed":836,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"cc5d24cd-31e8-4900-f133-3df92bdd1e73"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-ff7beec22cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/tokenization_codegen_fast.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, truncate_before_pattern, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m             \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         )\n\u001b[1;32m   3373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"]}]},{"cell_type":"code","source":["import numpy as np\n","from scipy.special import softmax\n","for i in range(6):\n","    m = np.argmax(softmax(outputs[0][0][i], axis=0))\n","    print(m)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_eQ5ki0QrNLt","executionInfo":{"status":"ok","timestamp":1662013942715,"user_tz":-480,"elapsed":3,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"77131db7-5f7b-43a5-fd78-6c41c8180472"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["919\n","97\n","10\n","133\n","97\n","189\n"]}]},{"cell_type":"code","source":["np.shape(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18PY1Qucu7rw","executionInfo":{"status":"ok","timestamp":1662013742557,"user_tz":-480,"elapsed":828,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"7f6f3875-11b1-460d-b618-8374fa96b758"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 1, 6, 1024)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["print(tokenizer.convert_ids_to_tokens(919))\n","print(tokenizer.convert_ids_to_tokens(97))\n","print(tokenizer.convert_ids_to_tokens(189))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ru6XhIstt4O","executionInfo":{"status":"ok","timestamp":1662013952272,"user_tz":-480,"elapsed":521,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"28be07d2-bcce-4d62-d772-99b6f17aeb3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cess\n","¤\n","ā\n"]}]}]}